# 十、使用 Apache Hadoop 生态系统

Apache Hadoop 已经发展成为处理大量数据的事实框架。Apache Hadoop 生态系统由多个项目组成，包括 Apache Hive 和 Apache HBase。Docker 映像“svds/cdh”基于最新的 cdh 版本，包括 Apache Hadoop 生态系统中的所有主要框架。Apache Hadoop、Apache Hive 和 Apache HBase 等所有框架都安装在同一个 Docker 映像中，因此有助于开发利用 Apache Hadoop 生态系统中多个框架的应用。在本章中，我们将讨论使用 Kubernetes 集群管理器来管理基于 svds/cdh 映像的 pod 集群。

*   设置环境
*   以声明方式创建 Apache Hadoop 集群
*   创建 Apache Hadoop 集群势在必行

## 设置环境

本章需要安装以下软件，除 Docker 镜像外，其他章节使用的软件相同。

*   -Docker 引擎(最新版本)
*   -库服务器群集管理器 1.01 版
*   -Kubernetes(1.01 版)
*   -SVS/CDH 影像对接器(最新版本)

在 Amazon EC2 的 Ubuntu 实例上安装第 1 章中讨论的软件。SSH 登录到 Ubuntu 实例。

```
ssh -i "docker.pem" ubuntu@54.86.45.173

```

使用以下命令启动 Docker 引擎。

```
sudo service docker start

```

随后运行以下命令来验证 Docker 的状态。

```
sudo service docker status

```

如图 [10-1](#Fig1) 所示，Docker 应列为“正在运行”。

![A418863_1_En_10_Fig1_HTML.gif](A418863_1_En_10_Fig1_HTML.gif)

图 10-1。

Starting Docker

使用以下命令列出服务。

```
kubectl get services

```

`kubernetes`服务应该被列为正在运行，如图 [10-2](#Fig2) 所示。

![A418863_1_En_10_Fig2_HTML.gif](A418863_1_En_10_Fig2_HTML.gif)

图 10-2。

Listing the “kubernetes” Service

使用以下命令列出 pod。

```
kubectl get pods

```

使用以下命令列出节点。

```
kubectl get nodes

```

唯一列出的 Pod 是 Kubernetes，如图 [10-3](#Fig3) 所示。还会列出节点 127.0.0.1。

![A418863_1_En_10_Fig3_HTML.gif](A418863_1_En_10_Fig3_HTML.gif)

图 10-3。

Listing the Pod and Node for Kubernetes

## 以声明方式创建 Apache Hadoop 集群

在下面的小节中，我们将使用定义文件声明性地创建一个 Kubernetes 服务和一个 Kubernetes 复制控制器。服务是 pod 的外部接口，并将客户端请求路由到其中一个 pod。复制控制器管理 pod 的复制级别，并将副本的数量维持在定义文件中的指定值。复制控制器还用于扩展 pod 集群。

### 创建服务

要为 CDH pod 运行服务，请创建一个服务定义文件`cdh-service.yaml`并将以下(表 [10-1](#Tab1) )字段添加到定义文件中。

表 10-1。

Service Definition File Fields

<colgroup><col> <col> <col> <col></colgroup> 
| 田 | 描述 | 价值 | 必填字段(包括默认值) |
| --- | --- | --- | --- |
| apiVersion(堆叠版本) |   | 第五颅神经的眼支 | 是 |
| 种类 | 定义文件的种类。 | 服务 | 是 |
| 元数据 | 服务元数据。 |   | 是 |
| 元数据->标签 | 服务标签。 | app:HRC | 不 |
| 元数据->名称 | 服务名称。 | 鼎晖投资 | 是 |
| 投机 | 服务规范。 |   | 是 |
| 规格->端口 | 服务公开的端口。 |   | 是 |
| 规格->端口->端口 | 服务公开的端口。50010 端口用于 DataNode。 | Fifty thousand and ten |   |
| 规格->端口->端口 | 服务公开的另一个端口。8020 端口是用于 NameNode 的。 | Eight thousand and twenty |   |
| 规格->选择器 | 吊舱选择器。服务将流量路由到标签与选择器表达式匹配的 pod。 | app:HRC | 是 |
| 规格->选择器->类型 | 服务类型。 | LoadBalancer(负载均衡器) | 不 |

服务定义文件`cdh-service.yaml`被列出:

```
apiVersion: v1
kind: Service
metadata:
labels:
    app: cdh
  name: cdh
spec:
ports:
    -
      port: 50010
    -
      port: 8020
  selector:
    app: cdh
type: LoadBalancer

```

可以在 vi 编辑器中创建并保存服务定义文件，如图 [10-4](#Fig4) 所示。

![A418863_1_En_10_Fig4_HTML.gif](A418863_1_En_10_Fig4_HTML.gif)

图 10-4。

Service Definition File in vi Editor

使用以下命令从定义文件创建服务。

```
kubectl create -f cdh-service.yaml

```

随后列出服务。

```
kubectl get services

```

第一个命令的输出“services/cdh”表示服务已经创建，如图 [10-5](#Fig5) 所示。第二个命令列出了名为“cdh”的服务。服务选择器在选择器列中列为 app = cdh。

![A418863_1_En_10_Fig5_HTML.gif](A418863_1_En_10_Fig5_HTML.gif)

图 10-5。

Creating a Service from a Definition File

### 创建复制控制器

在本节中，我们将使用一个定义文件创建一个复制控制器。创建一个 cdh-rc.yaml 文件，并将以下(表 [10-2](#Tab2) )字段添加到该文件中。

表 10-2。

Replication Controller Definition File Fields

<colgroup><col> <col> <col></colgroup> 
| 田 | 描述 | 价值 |
| --- | --- | --- |
| apiVersion(堆叠版本) |   | 第五颅神经的眼支 |
| 种类 | 定义文件的种类。 | 复制控制器 |
| 元数据 | 复制控制器元数据。 |   |
| 元数据->标签 | 复制控制器标签。 | app:HRC |
| 元数据->名称 | 复制控制器的名称。 | 人权委员会 |
| 投机 | 复制控制器规范。 |   |
| 规格->副本 | Pod 副本的数量。 | Two |
| 规格->选择器 | 选择器键:用于选择要管理的窗格的值表达式。标签与选择器表达式相同的窗格由复制控制器管理。对于单个选择器表达式，选择器表达式必须与规范->模板->元数据->标签标签相同。如果没有指定，选择器默认为规范->模板->元数据->标签。 | 未设置。默认为与键相同的值:规范->模板->元数据->标签中的值对。 |
| 规格->模板 | Pod 模板。 |   |
| 规格->模板->元数据 | Pod 模板元数据。 |   |
| 规格->模板->元数据->标签 | Pod 模板标签。 | app: cdh 名称:cdh |
| 规格->模板->规格 | Pod 模板规范 |   |
| 规格->模板->规格->容器 | Pod 模板的容器配置 |   |
| 规格->模板->规格->容器->图像 | Docker工人形象 | svds/人权中心 |
| 规格->模板->规格->容器->名称 | 容器名称 | 鼎晖投资 |

列出了复制控制器的定义文件`cdh-rc.yaml`。

```
apiVersion: v1
kind: ReplicationController
metadata:
  labels:
    app: cdh
  name: cdh-rc
spec:
  replicas: 2
  template:
    metadata:
      labels:
      app: cdh
      name: cdh
    spec:
      containers:
      image: svds/cdh
      name: cdh

```

运行以下命令，从定义文件创建复制控制器。

```
kubectl create -f cdh-rc.yaml

```

列出复制控制器。

```
kubectl get rc

```

第一个命令输出“replicationcontrollers/cdh”，这意味着已经成功创建了一个 rc。第二个命令列出了复制控制器。复制控制器“cdh”被列出，如图 [10-6](#Fig6) 所示。复制控制器文件中没有指定`SELECTOR`，它被列为与模板标签相同的两个键:值对`app=cdh,name=cdh`。由复制控制器管理的 Pod 必须包括这两个标签，并且可以包括其他标签。副本的数量设置为 2。

![A418863_1_En_10_Fig6_HTML.gif](A418863_1_En_10_Fig6_HTML.gif)

图 10-6。

Creating a Replication Controller from a Definition File

### 列出POD

要列出窗格，请运行以下命令。

```
kubectl get pods

```

两个吊舱被列出，如图 [10-7](#Fig7) 所示。最初，pod 可能被列为未运行或/和未就绪。“未就绪”箱由“就绪”栏中的 0/1 值表示，这意味着箱中的 1 个容器中的 0 个已经就绪。

![A418863_1_En_10_Fig7_HTML.gif](A418863_1_En_10_Fig7_HTML.gif)

图 10-7。

Listing the Pods for CDH, created but not Ready

再次运行相同的命令以列出窗格。

```
kubectl get pods

```

如图 [10-8](#Fig8) 所示，两个 pod 应被列为状态->运行和就绪- > 1/1。

![A418863_1_En_10_Fig8_HTML.gif](A418863_1_En_10_Fig8_HTML.gif)

图 10-8。

Listing the Pods as Ready

### 列出日志

要列出特定 Pod 的日志，例如 cdh-612pr Pod，请运行以下命令。

```
kubectl logs cdh-612pr

```

该命令的输出列出了日志，表明 Hadoop datanode、namenode、secondarynamenode、resourcemanager 和 nodemanager 已经启动，如图 [10-9](#Fig9) 所示。

![A418863_1_En_10_Fig9_HTML.gif](A418863_1_En_10_Fig9_HTML.gif)

图 10-9。

Listing Pod Logs

HBase 等其他组件也会启动。

### 扩展集群

最初，CDH 群集有两个副本。要将复制副本扩展到 4，请运行以下命令。

```
kubectl scale rc cdh --replicas=4

```

随后列出集群中的单元。

```
kubectl get pods

```

向上扩展群集后，会列出 4 个 pod，而不是最初列出的 2 个。一些 pod 可能被列为未运行或未准备好。几秒钟后周期性地运行前面的命令，所有的吊舱都应该启动，如图 [10-10](#Fig10) 所示。

![A418863_1_En_10_Fig10_HTML.gif](A418863_1_En_10_Fig10_HTML.gif)

图 10-10。

Scaling the Pod Cluster

### 启动交互式 Shell

由于“svds/CDH”Docker 映像基于 Linux“Ubuntu”Docker 映像，因此可以启动一个交互式 bash shell 来访问基于 svds/cdh Docker 映像的 Docker 容器。为了启动 cdh 软件的交互式 bash shell，我们需要获取运行“cdh”映像的 Docker 容器的容器 id，如图 [10-11](#Fig11) 所示。

![A418863_1_En_10_Fig11_HTML.gif](A418863_1_En_10_Fig11_HTML.gif)

图 10-11。

Copying the Docker Container Id

随后使用容器 id 启动交互式 shell。

```
sudo docker exec -it f1efdb5937c6 bash

```

交互外壳启动，如图 [10-12](#Fig12) 所示。

![A418863_1_En_10_Fig12_HTML.gif](A418863_1_En_10_Fig12_HTML.gif)

图 10-12。

Starting an Interactive Shell

### 运行 MapReduce 应用

在本节中，我们将在交互式 shell 中运行一个示例 MapReduce 应用。`hdfs`命令用于运行 MapReduce 应用。在交互式 shell 中调用`hdfs`命令。

```
hdfs

```

命令用法应如图 [10-13](#Fig13) 所示。

![A418863_1_En_10_Fig13_HTML.gif](A418863_1_En_10_Fig13_HTML.gif)

图 10-13。

Command Usage for hdfs Command

要将用户更改为“hdfs ”,请运行以下命令。

```
su –l hdfs

```

用户变成“hdfs”，如图 [10-14](#Fig14) 所示。

![A418863_1_En_10_Fig14_HTML.gif](A418863_1_En_10_Fig14_HTML.gif)

图 10-14。

Setting User as hdfs

接下来，我们将运行一个`wordcount`应用。我们将从`/input`目录文件中获取输入，并在`/output`目录中输出。创建`/input`目录并将其权限设置为全局(777)。

```
hdfs dfs -mkdir /input
hdfs dfs -chmod -R 777 /input

```

如图 [10-15](#Fig15) 所示，`/input`目录被创建，其权限被设置为全局权限。

![A418863_1_En_10_Fig15_HTML.gif](A418863_1_En_10_Fig15_HTML.gif)

图 10-15。

Creating the Input Directory

在 vi 编辑器中创建一个输入文件`input.1.txt`。

```
sudo vi input1.txt

```

将以下文本添加到 input1.txt 中。

```
Hello World Application for Apache Hadoop
Hello World and Hello Apache Hadoop

```

图 [10-16](#Fig16) 中的 vi 编辑器显示了`input1.txt`。

![A418863_1_En_10_Fig16_HTML.gif](A418863_1_En_10_Fig16_HTML.gif)

图 10-16。

Creating an Input Text File

用下面的命令将`input1.txt`放到 HDFS 目录`/input`中，如果以`root`用户的身份运行，应该用`sudo –u hdfs`运行。如果用户已经设置为“hdfs ”,则在命令中省略“sudo–u HDFS”。

```
sudo -u hdfs hdfs dfs -put input1.txt /input

```

`input1.txt`文件被添加到`/input`目录中，命令没有产生输出，如图 [10-17](#Fig17) 所示。

![A418863_1_En_10_Fig17_HTML.gif](A418863_1_En_10_Fig17_HTML.gif)

图 10-17。

Putting the Input Text File in HDFS

类似地，创建另一个文件 input2.txt。

```
sudo vi input2.txt

```

将以下文本添加到 input2.txt。

```
Hello World
Hello Apache Hadoop

```

在 vi 编辑器中用:wq 命令保存`input2.txt`，如图 [10-18](#Fig18) 所示。

![A418863_1_En_10_Fig18_HTML.gif](A418863_1_En_10_Fig18_HTML.gif)

图 10-18。

Creating another Text File input2.txt

将`input2.txt`放入`/input`目录。

```
sudo -u hdfs hdfs dfs -put input2.txt /input

```

`input2.txt`也被添加到`/input`目录中，如图 [10-19](#Fig19) 所示。

![A418863_1_En_10_Fig19_HTML.gif](A418863_1_En_10_Fig19_HTML.gif)

图 10-19。

Putting the input2.txt File into HDFS

可以用下面的命令列出 HDFS 中`/input`目录下的文件。

```
 hdfs dfs -ls /input

```

增加的两个文件`input1.txt`和`input2.txt`被列出，如图 [10-20](#Fig20) 所示。

![A418863_1_En_10_Fig20_HTML.gif](A418863_1_En_10_Fig20_HTML.gif)

图 10-20。

Listing the Files in HDFS

接下来，使用下面的命令运行`wordcount`示例应用，其中包含示例应用的 jar 文件由 jar 参数指定，并且`/input`和`/output`目录分别被设置为输入目录和输出目录的最后两个命令参数。

```
sudo -u hdfs hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.4.7.jar wordcount /input /output

```

一个 MapReduce 作业开始，如图 [10-21](#Fig21) 所示。

![A418863_1_En_10_Fig21_HTML.gif](A418863_1_En_10_Fig21_HTML.gif)

图 10-21。

Starting a YARN Application for Word Count Example

MapReduce 作业完成后运行`wordcount`应用。图 [10-22](#Fig22) 中显示的是`wordcount` MapReduce 作业的输出，而不是字数统计结果。

![A418863_1_En_10_Fig22_HTML.gif](A418863_1_En_10_Fig22_HTML.gif)

图 10-22。

Output from the MapReduce Job

下面列出了 MapReduce 应用的更详细的输出:

```
root@cdh-6l2pr:/# sudo -u hdfs hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.4.7.jar wordcount /input /output
15/12/21 16:39:52 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/12/21 16:39:53 INFO input.FileInputFormat: Total input paths to process : 2
15/12/21 16:39:53 INFO mapreduce.JobSubmitter: number of splits:2
15/12/21 16:39:53 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1450714825612_0002
15/12/21 16:39:53 INFO impl.YarnClientImpl: Submitted application application_1450714825612_0002
15/12/21 16:39:53 INFO mapreduce.Job: The url to track the job: http://cdh-6l2pr:8088/proxy/application_1450714825612_0002/
15/12/21 16:39:53 INFO mapreduce.Job: Running job: job_1450714825612_0002
15/12/21 16:39:59 INFO mapreduce.Job: Job job_1450714825612_0002 running in uber mode : false
15/12/21 16:39:59 INFO mapreduce.Job: map 0 % reduce 0 %
15/12/21 16:40:04 INFO mapreduce.Job: map 100 % reduce 0 %
15/12/21 16:40:10 INFO mapreduce.Job: map 100 % reduce 100 %
15/12/21 16:40:10 INFO mapreduce.Job: Job job_1450714825612_0002 completed successfully
15/12/21 16:40:10 INFO mapreduce.Job: Counters: 49
       File System Counters
           FILE: Number of bytes read=144
           FILE: Number of bytes written=332672
           FILE: Number of read operations=0
           FILE: Number of large read operations=0
           FILE: Number of write operations=0
           HDFS: Number of bytes read=317
           HDFS: Number of bytes written=60
           HDFS: Number of read operations=9
           HDFS: Number of large read operations=0
           HDFS: Number of write operations=2
       Job Counters
           Launched map tasks=2
           Launched reduce tasks=1
           Data-local map tasks=2
           Total time spent by all maps in occupied slots (ms)=4939
           Total time spent by all reduces in occupied slots (ms)=2615
           Total time spent by all map tasks (ms)=4939
           Total time spent by all reduce tasks (ms)=2615
           Total vcore-seconds taken by all map tasks=4939
           Total vcore-seconds taken by all reduce tasks=2615
           Total megabyte-seconds taken by all map tasks=5057536
           Total megabyte-seconds taken by all reduce tasks=2677760
       Map-Reduce Framework
           Map input records=5
           Map output records=17
           Map output bytes=178
           Map output materialized bytes=150
           Input split bytes=206
           Combine input records=17
           Combine output records=11
           Reduce input groups=7
           Reduce shuffle bytes=150
           Reduce input records=11
           Reduce output records=7
           Spilled Records=22
           Shuffled Maps =2
           Failed Shuffles=0
           Merged Map outputs=2
           GC time elapsed (ms)=158
           CPU time spent (ms)=2880
           Physical memory (bytes) snapshot=1148145664
           Virtual memory (bytes) snapshot=5006991360
           Total committed heap usage (bytes)=2472542208
Shuffle Errors
           BAD_ID=0
           CONNECTION=0
           IO_ERROR=0
           WRONG_LENGTH=0
           WRONG_MAP=0
           WRONG_REDUCE=0
File Input Format Counters
           Bytes Read=111
File Output Format Counters
           Bytes Written=60
root@cdh-6l2pr:/#

```

随后，列出`/output`目录中的文件。

```
bin/hdfs dfs -ls /output

```

列出两个文件:`_SUCCESS`和`part-r-00000`，如图 [10-23](#Fig23) 所示。`_SUCCESS`文件表示 MapReduce 命令成功完成，`part-r-00000`命令包含字数统计的结果。

![A418863_1_En_10_Fig23_HTML.gif](A418863_1_En_10_Fig23_HTML.gif)

图 10-23。

Listing the Files generated by the MapReduce Job

要列出 wordcount 应用的结果，请运行以下命令。

```
hdfs dfs -cat /output/part-r-00000

```

如图 [10-24](#Fig24) 所示，列出了输入中每个单词的字数。

![A418863_1_En_10_Fig24_HTML.gif](A418863_1_En_10_Fig24_HTML.gif)

图 10-24。

The Word Count for the Input Files

## 运行蜂箱

Apache Hive 是一个数据仓库框架，用于存储、管理和查询 HDFS 的大型数据集。如前所述，CDH 的所有/大部分组件都是在运行`svds/cdh`映像时安装的。在这一节中，我们将测试 Apache Hive 框架。配置单元配置目录在配置单元`conf`目录中，在`/etc/hive`目录中。将目录(cd)更改为`/etc/hive`目录。

```
cd /etc/hive

```

`conf`目录被列出，如图 [10-25](#Fig25) 所示。

![A418863_1_En_10_Fig25_HTML.gif](A418863_1_En_10_Fig25_HTML.gif)

图 10-25。

Listing the Files and Directories in the Hive Root Directory

配置单元 metastore 保存在`/var/lib/hive`目录中。Cd 到`/var/lib/hive`目录。

```
cd /var/lib/hive

```

`metastore`目录被列出，如图 [10-26](#Fig26) 所示。

![A418863_1_En_10_Fig26_HTML.gif](A418863_1_En_10_Fig26_HTML.gif)

图 10-26。

Listing the Hive Metastore Directory

配置单元主目录是`/usr/lib/hive`。Cd 到`/usr/lib/hive`目录。随后列出文件和目录。

```
cd /usr/lib/hive
ls –l

```

Apache Hive 的`bin`、`conf,`和`lib`目录如图 [10-27](#Fig27) 所示。`bin`目录包含可执行文件，`conf`目录包含配置文件，`lib`目录包含 jar 文件。

![A418863_1_En_10_Fig27_HTML.gif](A418863_1_En_10_Fig27_HTML.gif)

图 10-27。

The Hive Home Directory

所有的环境变量都是预先配置的。运行以下命令启动直线 CLI。

```
beeline

```

直线版本 1.1.0-cdh5.4.7 启动，如图 [10-28](#Fig28) 所示。

![A418863_1_En_10_Fig28_HTML.gif](A418863_1_En_10_Fig28_HTML.gif)

图 10-28。

Starting Beeline CLI

最初，没有到 Apache Hive 服务器的连接。为了进行演示，运行以下命令将数据库设置为默认数据库并显示表。

```
use default;
show tables;

```

显示如图 [10-29](#Fig29) 所示的“无电流连接”信息。

![A418863_1_En_10_Fig29_HTML.gif](A418863_1_En_10_Fig29_HTML.gif)

图 10-29。

No Current Connection

使用驱动程序、用户名和密码的默认设置与 Hive2 服务器连接，如三个空""所示。

```
!connect jdbc:hive2://localhost:10000/default "" "" ""

```

Apache Hive2 服务器使用 Apache Hive JDBC 驱动程序进行连接，如图 [10-30](#Fig30) 所示。

![A418863_1_En_10_Fig30_HTML.gif](A418863_1_En_10_Fig30_HTML.gif)

图 10-30。

Connecting with Hive Server

运行命令将数据库设置为默认值并显示表格。

```
use default;
show tables;

```

连接到的数据库已经是默认的，第一个命令基本上是多余的，但是需要注意的是，前面生成的错误没有生成。第二个命令列出了表，因为默认数据库最初没有任何表，所以没有列出任何表。前面命令的输出如图 [10-31](#Fig31) 所示。

![A418863_1_En_10_Fig31_HTML.gif](A418863_1_En_10_Fig31_HTML.gif)

图 10-31。

Setting the database to Use and the listing to the Hive Tables

在创建配置单元表之前，我们需要将`/user/hive/warehouse`目录的权限设置为全局(777)。

```
sudo –u hdfs hdfs dfs –chmod –R 777 /user/hive/warehouse

```

配置单元仓库目录的权限设置如图 [10-32](#Fig32) 所示。

![A418863_1_En_10_Fig32_HTML.gif](A418863_1_En_10_Fig32_HTML.gif)

图 10-32。

Setting Permissions on the Hive Warehouse Directory

用下面的 HiveQL 命令创建一个名为`wlslog`的表。

```
CREATE TABLE wlslog(time_stamp STRING,category STRING,type STRING,servername STRING,code STRING,msg STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n';

```

在默认数据库中创建`wlslog`表，如图 [10-33](#Fig33) 所示。

![A418863_1_En_10_Fig33_HTML.gif](A418863_1_En_10_Fig33_HTML.gif)

图 10-33。

Creating a Hive Table called wlslog

使用以下命令描述 wlslog 表。

```
desc wlslog;

```

表格列(名称和数据类型)如图 [10-34](#Fig34) 所示。

![A418863_1_En_10_Fig34_HTML.gif](A418863_1_En_10_Fig34_HTML.gif)

图 10-34。

Describing the Hive Table wlslog

向`wlslog`表添加 7 行数据。

```
INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:16-PM-PDT','Notice','WebLogicServer','AdminServer,BEA-000365','Server state changed to STANDBY');
INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:17-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000365','Server state changed to STARTING');
INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:18-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000365','Server state changed to ADMIN');
INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:19-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000365','Server state changed to RESUMING');
INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:20-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000331','Started WebLogic AdminServer');
INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:21-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000365','Server state changed to RUNNING');
INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:22-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000360','Server started in RUNNING mode');

```

针对每个`INSERT`语句运行一个 MapReduce 作业，将数据添加到配置单元表`wlslog`中，如图 [10-35](#Fig35) 所示。

![A418863_1_En_10_Fig35_HTML.gif](A418863_1_En_10_Fig35_HTML.gif)

图 10-35。

Adding Data to Hive Table wlslog

随后查询`wlslog`表。

```
select * from wlslog;

```

添加的 7 行数据被列出，如图 [10-36](#Fig36) 所示。

![A418863_1_En_10_Fig36_HTML.gif](A418863_1_En_10_Fig36_HTML.gif)

图 10-36。

Querying the Hive Table

要退出 Beeline CLI，请运行以下命令。

```
!q

```

如图 [10-37](#Fig37) 所示，蜂箱直线 CLI 退出。将显示交互式 shell 命令提示符。

![A418863_1_En_10_Fig37_HTML.gif](A418863_1_En_10_Fig37_HTML.gif)

图 10-37。

Exiting the Beeline CLI

从交互式 shell 中，可以运行 CDH 的任何框架。接下来，我们将运行 Apache HBase。

## 运行 HBase

Apache HBase 是 Apache Hadoop 数据库，默认情况下，它也将数据存储在 HDFS。要启动 HBase shell，请在 bash shell 中运行以下命令，用于基于 svds/cdh Docker 映像的 Docker 容器。

```
hbase shell

```

HBase shell 启动，如图 [10-38](#Fig38) 所示。

![A418863_1_En_10_Fig38_HTML.gif](A418863_1_En_10_Fig38_HTML.gif)

图 10-38。

Starting HBase Shell

使用列族“log”创建一个名为“wlslog”的表。

```
create 'wlslog' , 'log'

```

`wlslog`表被创建，如图 [10-39](#Fig39) 所示。

![A418863_1_En_10_Fig39_HTML.gif](A418863_1_En_10_Fig39_HTML.gif)

图 10-39。

Creating a HBase Table

将 7 行数据放入`wlslog`表中。

```
put 'wlslog', 'log1', 'log:time_stamp', 'Apr-8-2014-7:06:16-PM-PDT'
put 'wlslog', 'log1', 'log:category', 'Notice'
put 'wlslog', 'log1', 'log:type', 'WeblogicServer'
put 'wlslog', 'log1', 'log:servername', 'AdminServer'
put 'wlslog', 'log1', 'log:code', 'BEA-000365'
put 'wlslog', 'log1', 'log:msg', 'Server state changed to STANDBY'

put 'wlslog', 'log2', 'log:time_stamp', 'Apr-8-2014-7:06:17-PM-PDT'
put 'wlslog', 'log2', 'log:category', 'Notice'
put 'wlslog', 'log2', 'log:type', 'WeblogicServer'
put 'wlslog', 'log2', 'log:servername', 'AdminServer'
put 'wlslog', 'log2', 'log:code', 'BEA-000365'
put 'wlslog', 'log2', 'log:msg', 'Server state changed to STARTING'
put 'wlslog', 'log3', 'log:time_stamp', 'Apr-8-2014-7:06:18-PM-PDT'
put 'wlslog', 'log3', 'log:category', 'Notice'
put 'wlslog', 'log3', 'log:type', 'WeblogicServer'
put 'wlslog', 'log3', 'log:servername', 'AdminServer'
put 'wlslog', 'log3', 'log:code', 'BEA-000365'
put 'wlslog', 'log3', 'log:msg', 'Server state changed to ADMIN'
put 'wlslog', 'log4', 'log:time_stamp', 'Apr-8-2014-7:06:19-PM-PDT'
put 'wlslog', 'log4', 'log:category', 'Notice'
put 'wlslog', 'log4', 'log:type', 'WeblogicServer'
put 'wlslog', 'log4', 'log:servername', 'AdminServer'
put 'wlslog', 'log4', 'log:code', 'BEA-000365'
put 'wlslog', 'log4', 'log:msg', 'Server state changed to RESUMING'
put 'wlslog', 'log5', 'log:time_stamp', 'Apr-8-2014-7:06:20-PM-PDT'
put 'wlslog', 'log5', 'log:category', 'Notice'
put 'wlslog', 'log5', 'log:type', 'WeblogicServer'
put 'wlslog', 'log5', 'log:servername', 'AdminServer'
put 'wlslog', 'log5', 'log:code', 'BEA-000331'
put 'wlslog', 'log5', 'log:msg', 'Started Weblogic AdminServer'
put 'wlslog', 'log6', 'log:time_stamp', 'Apr-8-2014-7:06:21-PM-PDT'
put 'wlslog', 'log6', 'log:category', 'Notice'
put 'wlslog', 'log6', 'log:type', 'WeblogicServer'
put 'wlslog', 'log6', 'log:servername', 'AdminServer'
put 'wlslog', 'log6', 'log:code', 'BEA-000365'
put 'wlslog', 'log6', 'log:msg', 'Server state changed to RUNNING'
put 'wlslog', 'log7', 'log:time_stamp', 'Apr-8-2014-7:06:22-PM-PDT'
put 'wlslog', 'log7', 'log:category', 'Notice'
put 'wlslog', 'log7', 'log:type', 'WeblogicServer'
put 'wlslog', 'log7', 'log:servername', 'AdminServer'
put 'wlslog', 'log7', 'log:code', 'BEA-000360'
put 'wlslog', 'log7', 'log:msg', 'Server started in RUNNING mode'

```

put 命令的输出如图 [10-40](#Fig40) 所示。

![A418863_1_En_10_Fig40_HTML.gif](A418863_1_En_10_Fig40_HTML.gif)

图 10-40。

Putting Data into HBase Table

要列出这些表，请运行以下命令。

```
list

```

`wlslog`表被列出，如图 [10-41](#Fig41) 所示。

![A418863_1_En_10_Fig41_HTML.gif](A418863_1_En_10_Fig41_HTML.gif)

图 10-41。

Listing HBase Tables

要获取行关键字为“log1”的行中的数据，请运行以下命令。

```
get 'wlslog', 'log1'

```

单列数据被列出，如图 [10-42](#Fig42) 所示。

![A418863_1_En_10_Fig42_HTML.gif](A418863_1_En_10_Fig42_HTML.gif)

图 10-42。

Getting a Single Row of Data

从具有行关键字`log7`的行中获取单个列`log.msg`中的数据。使用列族:列格式指定列。

```
get 'wlslog', 'log7', {COLUMNS=>['log:msg']}

```

单列数据输出如图 [10-43](#Fig43) 所示。

![A418863_1_En_10_Fig43_HTML.gif](A418863_1_En_10_Fig43_HTML.gif)

图 10-43。

Getting a Single Column Value in a Row

用`scan`命令扫描`wlslog`工作台。

```
scan 'wlslog'

```

扫描命令如图 [10-44](#Fig44) 所示。

![A418863_1_En_10_Fig44_HTML.gif](A418863_1_En_10_Fig44_HTML.gif)

图 10-44。

Scanning a HBase Table

来自`wlslog`表的所有数据被列出，如图 [10-45](#Fig45) 所示。

![A418863_1_En_10_Fig45_HTML.gif](A418863_1_En_10_Fig45_HTML.gif)

图 10-45。

The scan Command outputs 7 Rows of Data

## 删除复制控制器和服务

在下一节中，我们将在命令行上强制为`svds/cdh`图像创建一个集群。删除复制控制器和以声明方式创建的服务。

```
kubectl delete rc cdh
kubectl delete service cdh

```

## 创建 Apache Hadoop 集群势在必行

在下面的小节中，我们将从命令行上的`svds/cdh` Docker 映像创建一个 CDH 集群。首先，我们将创建一个复制控制器。

### 创建复制控制器

运行以下命令创建一个名为`cdh`的复制控制器，包含两个副本。

```
kubectl run cdh --image=svds/cdh --replicas=2

```

`cdh`控制器创建完成，如图 [10-46](#Fig46) 所示。选择器默认设置为`run=cdh`。

![A418863_1_En_10_Fig46_HTML.gif](A418863_1_En_10_Fig46_HTML.gif)

图 10-46。

Creating a Replication Controller Imperatively

列出复制控制器。

```
kubectl get rc

```

`cdh`复制控制器列表如图 [10-47](#Fig47) 所示。

![A418863_1_En_10_Fig47_HTML.gif](A418863_1_En_10_Fig47_HTML.gif)

图 10-47。

Getting the Replication Controller

### 列出POD

要列出集群中的 pod，请运行以下命令。

```
kubectl get pods

```

这两个 pod 会被列出。如图 [10-48](#Fig48) 所示，最初一些或所有的吊舱可能不“运行”或不处于就绪状态 1/1。

![A418863_1_En_10_Fig48_HTML.gif](A418863_1_En_10_Fig48_HTML.gif)

图 10-48。

Listing the Pods with some Pod/s not READY yet

几秒钟后再次运行前面的命令。

```
kubectl get pods

```

如图 [10-49](#Fig49) 所示，所有的吊舱应列出状态“运行”和就绪状态 1/1。

![A418863_1_En_10_Fig49_HTML.gif](A418863_1_En_10_Fig49_HTML.gif)

图 10-49。

Listing all Pods as Running and Ready

### 扩展集群

要将群集扩展到 4 个副本，请运行以下命令。

```
kubectl scale rc cdh --replicas=4

```

随后列出POD。

```
kubectl get pods

```

第一个命令的输出“scaled”表示集群已被缩放。第二个命令列出了 4 个 pod，而不是最初创建的 2 个，如图 [10-50](#Fig50) 所示。第二个命令可能需要运行多次才能列出所有状态为“正在运行”和就绪状态为 1/1 的 pod。

![A418863_1_En_10_Fig50_HTML.gif](A418863_1_En_10_Fig50_HTML.gif)

图 10-50。

Scaling the CDH Cluster

### 创建服务

服务在服务端点公开由复制控制器管理的 pod，服务端点只是外部客户机可以调用应用的主机:端口设置。运行以下命令创建服务。

```
kubectl expose rc cdh --type=LoadBalancer

```

随后列出服务。

```
kubectl get services

```

“cdh”服务列出选择器和端口的默认设置，如图 [10-51](#Fig51) 所示。默认的服务选择器是`run=cdh`，它的默认格式是 run = <servicename>。默认端口是 8020。</servicename>

![A418863_1_En_10_Fig51_HTML.gif](A418863_1_En_10_Fig51_HTML.gif)

图 10-51。

Creating a Service

### 启动交互式 Shell

交互式外壳可以像以声明方式启动的 CDH 集群一样启动。复制运行 CDH 映像的 Docker 容器的容器 id，并运行以下命令(包括容器 id)来启动交互式 bash shell。

```
sudo docker exec -it 42f2d8f40f17 bash

```

交互外壳启动，如图 [10-52](#Fig52) 所示。

![A418863_1_En_10_Fig52_HTML.gif](A418863_1_En_10_Fig52_HTML.gif)

图 10-52。

Starting an Interactive Shell

运行`hdfs`命令。

```
hdfs

```

`hdfs`命令用法得到如图 [10-53](#Fig53) 所示的输出。

![A418863_1_En_10_Fig53_HTML.gif](A418863_1_En_10_Fig53_HTML.gif)

图 10-53。

Command Usage for hdfs Command

## 摘要

在本章中，我们使用 Kubernetes 集群管理器根据 Docker 映像`svds/cdh`创建了一个 Pods 集群。我们使用声明式和命令式方法来创建集群。我们使用 kubectl scale 命令来扩展集群。我们还演示了如何使用打包在`cdh`映像中的一些 Apache Hadoop 框架。我们运行了一个 MapReduce `wordcount`示例应用。我们还运行了 Apache Hive 和 Apache HBase 工具。在下一章，我们将讨论在索引和存储框架 Apache Solr 中使用 Kubernetes。