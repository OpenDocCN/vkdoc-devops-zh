# 十二、使用 ApacheKafka

Apache Kafka 是一个发布-订阅、高吞吐量、分布式消息传递系统。Kafka 中的一个代理可以处理来自多个客户端的每秒 100 兆字节的读写。消息在整个集群中复制，并保存到磁盘上。Kafka 可用于流处理、网站活动跟踪、指标收集、监控和日志聚合。

Kafka 架构的主要组件是生产者、代理、主题和消费者。Kafka 在主题中保存信息的提要。生产者向主题发送(或编写)消息，消费者从主题中消费(或读取)消息。消息是数据的字节数组，可以是任何格式，最常见的是 String、JSON 和 Avro。邮件会保留指定的时间。一个动物园管理员协调 Kafka 集群。在单个生产者-消费者架构中，单个生产者向主题发送消息，单个消费者从主题中消费消息。

Kafka 类似于 Flume，因为它流式传输消息，但 Kafka 是为不同的目的而设计的。虽然 Flume 是为将消息流式传输到 HDFS 或 HBase 等接收器而设计的，但 Kafka 是为供多个应用使用的消息而设计的。

在本章中，我们将讨论使用 Kubernetes 集群管理器和 Apache Kafka。

*   设置环境
*   修改 Docker 映像
*   创建服务
*   创建复制控制器
*   列出 POD
*   描述一个 Pod
*   启动交互式 Shell
*   启动 Kafka 服务器
*   创建主题
*   创建 Kafka 制作人
*   启动 Kafka 消费者
*   生产和消费消息
*   扩展集群
*   删除复制控制器和服务

## 设置环境

我们使用了从 AMI Ubuntu Server 14.04 LTS (HVM)创建的 Amazon EC2 实例，SSD 卷类型- ami-d05e75b8。本章需要以下软件。

*   -Docker 引擎(最新版本)
*   -库服务器群集管理器 1.01 版
*   -Kubernetes(1.01 版)
*   -Docker 映像 dockerkafka/kafka(最新版本)

我们在本章中使用了 Docker 映像`dockerkafka/kafka`。`dockerkafka/kafka`映像 docker 文件的默认设置不适合与 Kubernetes 进行编排。在下一节中，我们修改并重建了默认的 Docker 映像。首先，使用 Amazon EC2 实例的公共 IP 地址连接 Ubuntu 实例。

```
ssh -i "docker.pem" ubuntu@54.146.140.160

```

Ubuntu 实例如图 [12-1](#Fig1) 所示连接。

![A418863_1_En_12_Fig1_HTML.gif](A418863_1_En_12_Fig1_HTML.gif)

图 12-1。

Connecting to an Ubuntu Instance on Amazon EC2

按照第 [1](01.html) 章所述安装所需软件。启动 Docker 服务并查找其状态。

```
sudo service docker start
sudo service docker status

```

如图 [12-2](#Fig2) 所示，Docker 应被列为正在运行。

![A418863_1_En_12_Fig2_HTML.gif](A418863_1_En_12_Fig2_HTML.gif)

图 12-2。

Starting Docker

列出永恒的服务。

```
kubectl get services

```

应列出“kubernetes”服务，如图 [12-3](#Fig3) 所示。

![A418863_1_En_12_Fig3_HTML.gif](A418863_1_En_12_Fig3_HTML.gif)

图 12-3。

Listing the “kubernetes” Service

## 修改 Docker 映像

启动 Apache Kafka 的过程包括以下序列。

Start Zookeeper Server   Start Apache Kafka Server  

Apache Kafka 服务器依赖于 Zookeeper 服务器，因此需要在 Kafka 服务器启动之前运行 Zookeeper 服务器。Kafka 服务器在启动时使用`server.properties`配置文件。`server.properties`文件中的默认设置不适合 Kafka 服务器基于运行在`localhost:2181`的 Zookeeper 服务器启动。我们需要在`server.properties`文件中修改 Zookeeper 的连接 url。

在本节中，我们将下载`dockerkafka/kafka`映像，修改`server.properties`并重建 Docker 映像。用下面的命令下载`dockerkafka/kafka`映像的源代码。

```
git clone https://github.com/DockerKafka/kafka-docker.git

```

`dockerkafka/kafka`映像的源代码被下载，如图 [12-4](#Fig4) 所示。

![A418863_1_En_12_Fig4_HTML.gif](A418863_1_En_12_Fig4_HTML.gif)

图 12-4。

Downloading the kafka-docker Docker Image Source Code

将目录(cd)更改为`kafka-docker`目录，并列出文件/目录。

```
cd kafka-docker
ls –l

```

Docker 镜像中的文件/目录被列出，如图 [12-5](#Fig5) 所示。

![A418863_1_En_12_Fig5_HTML.gif](A418863_1_En_12_Fig5_HTML.gif)

图 12-5。

Listing the Dockerfile and Image Directory for the kafka-source Docker Image

我们需要修改位于`image/conf`目录下的`server.properties`文件中的设置。Cd 到`image/conf`目录，并列出该目录的文件/目录。

```
cd image/conf
ls –l

```

`server.properties`文件被列出，如图 [12-6](#Fig6) 所示。

![A418863_1_En_12_Fig6_HTML.gif](A418863_1_En_12_Fig6_HTML.gif)

图 12-6。

Listing the Configuration Files for the Docker Image

在 vi 编辑器中打开`server.properties`文件。

```
sudo vi server.properties

```

`server.properties`文件如图 [12-7](#Fig7) 所示。取消带有`host.name=localhost`设置的行的注释。

![A418863_1_En_12_Fig7_HTML.gif](A418863_1_En_12_Fig7_HTML.gif)

图 12-7。

Uncommenting the host.name Property

如图 [12-8](#Fig8) 所示`zookeeper.connect`的默认设置为`zookeeper:2181`。

![A418863_1_En_12_Fig8_HTML.gif](A418863_1_En_12_Fig8_HTML.gif)

图 12-8。

The default setting for the zookeeper.connect Property

将`zookeeper.connect`设置修改为`localhost:2181`，如图 [12-9](#Fig9) 所示。用:wq 保存修改后的文件。我们需要修改设置，因为默认情况下不存在“zookeeper”这样的主机。

![A418863_1_En_12_Fig9_HTML.gif](A418863_1_En_12_Fig9_HTML.gif)

图 12-9。

Setting zookeeper.connect to localhost: 2181

随后，cd 回到 Docker 映像的根目录，即`kafka-docker`目录，并运行以下命令来重建 Docker 映像。

```
sudo docker build -t dockerkafka/kafka:v2.

```

该命令的输出如图 [12-10](#Fig10) 所示。

![A418863_1_En_12_Fig10_HTML.gif](A418863_1_En_12_Fig10_HTML.gif)

图 12-10。

Rebuilding the Docker Image for Kafka

Docker 映像得到重建，如图 [12-11](#Fig11) 所示。

![A418863_1_En_12_Fig11_HTML.gif](A418863_1_En_12_Fig11_HTML.gif)

图 12-11。

Completing the Rebuild of the Docker Image

我们随后将使用的 Docker 映像不是`dockerkafka/kafka`而是`dockerkafka/kafka:v2`。

## 创建服务

创建一个名为`kafka-service.yaml`的服务定义文件，并将以下(表 [12-1](#Tab1) )字段添加到该文件中。

表 12-1。

The Fields in the Service Definition File

<colgroup><col> <col> <col></colgroup> 
| 田 | 描述 | 价值 |
| --- | --- | --- |
| apiVersion(堆叠版本) |   | 第五颅神经的眼支 |
| 种类 | 定义文件的种类。 | 服务 |
| 元数据 | 服务元数据。 |   |
| 元数据->标签 | 服务标签。不需要。 | 应用程式:Kafka |
| 元数据->名称 | 服务名称。必选。 | Kafka |
| 投机 | 服务规范。 |   |
| 规格->端口 | 服务公开的端口。 |   |
| 规格->端口->端口 | 服务公开的端口。9092 端口用于 Kafka 服务器。 | 端口:9092 目标端口:9092 |
| 规格->端口->端口 | 服务公开的另一个端口。2181 端口是给动物园管理员的。 | 端口:2181 目标端口:2181 |
| 规格->选择器 | 吊舱选择器。服务将流量路由到标签与选择器表达式匹配的 pod。 | 应用程式:Kafka |
| 规格->选择器->类型 | 服务类型。 | LoadBalancer(负载均衡器) |

`kafka-service.yaml`已列出。

```
apiVersion: v1
kind: Service
metadata:
  labels:
    app: kafkaApp
  name: kafka
spec:
  ports:
    -
      port: 9092
      targetPort: 9092
    -
      port: 2181
      targetPort: 2181
  selector:
    app: kafkaApp
  type: LoadBalancer

```

可以在 vi 编辑器中创建`kafka-service.yaml`并用:wq 保存，如图 [12-12](#Fig12) 所示。

![A418863_1_En_12_Fig12_HTML.gif](A418863_1_En_12_Fig12_HTML.gif)

图 12-12。

Service Definition File in vi Editor

从定义文件创建服务。

```
kubectl create -f kafka-service.yaml

```

随后列出服务。

```
kubectl get services

```

“kafka”服务被列出，如图 [12-13](#Fig13) 所示。服务选择器是 app = kafkaApp。

![A418863_1_En_12_Fig13_HTML.gif](A418863_1_En_12_Fig13_HTML.gif)

图 12-13。

Creating a Service from the Definition File

## 创建复制控制器

为复制控制器创建一个名为`kafka-rc.yaml`的定义文件，并添加以下字段(表 [12-2](#Tab2) )。

表 12-2。

Fields in the Replication Controller Definition File

<colgroup><col> <col> <col></colgroup> 
| 田 | 描述 | 价值 |
| --- | --- | --- |
| apiVersion(堆叠版本) |   | 第五颅神经的眼支 |
| 种类 | 定义文件的种类。 | 复制控制器 |
| 元数据 | 复制控制器元数据。 |   |
| 元数据->标签 | 复制控制器标签。 | app:kafcapp 名称:kafca-RC |
| 投机 | 复制控制器规范。 |   |
| 规格->副本 | Pod 副本的数量。 | Two |
| 规格->选择器 | key:用于选择要管理的窗格的值表达式。标签与选择器表达式相同的窗格由复制控制器管理。选择器表达式必须与规范->模板->元数据->标签表达式相同。如果没有指定，选择器默认为规范->模板->元数据->标签键:值表达式。 | 应用程式:Kafka |
| 规格->模板 | Pod 模板。 |   |
| 规格->模板->元数据 | Pod 模板元数据。 |   |
| 规格->模板->元数据->标签 | Pod 模板标签。 | 应用程式:Kafka |
| 规格->模板->规格 | Pod 模板规范。 |   |
| 规格->模板->规格->容器 | Pod 模板的容器配置。 |   |
| 规格->模板->规格->容器->命令 | 为 Docker 映像运行的命令。Dockerfile 中的默认命令是 CMD ["kafka-server-start.sh "，"/opt/Kafka _ 2.10-0 . 8 . 2 . 1/config/server . properties "]。默认命令启动 Kakfa 服务器，但是我们希望 Zookeeper 服务器在 Kafka 服务器之前，因为 Kafka 服务器不会启动，除非 Zookeeper 服务器正在运行。修改后的命令只启动 Zookeeper 服务器。我们将单独启动 Kafka 服务器。 | -zookeeper-server-start . sh-/opt/Kafka _ 2.10-0 . 8 . 2 . 1/config/zookeeper . properties |
| 规格->模板->规格->容器->映像 | Docker 的形象。 | dock fk/Kaka:v2 |
| 规格->模板->规格->容器->名称 | 容器名称。 | 动物园管理员 |
| 港口 | 指定容器端口。 | 容器港口:2181 |

`kafka-rc.yaml`已列出。

```
---
apiVersion: v1
kind: ReplicationController
metadata:
  labels:
    app: kafkaApp
  name: kafka-rc
spec:
  replicas: 1
  selector:
    app: kafkaApp
  template:
    metadata:
      labels:
        app: kafkaApp
    spec:
      containers:
        -
          command:
            - zookeeper-server-start.sh
            - /opt/kafka_2.10-0.8.2.1/config/zookeeper.properties
          image: "dockerkafka/kafka:v2"
          name: zookeeper
          ports:
            -
              containerPort: 2181

```

可以在 vi 编辑器中创建并保存`kafka-rc.yaml`文件，如图 [12-14](#Fig14) 所示。

![A418863_1_En_12_Fig14_HTML.gif](A418863_1_En_12_Fig14_HTML.gif)

图 12-14。

Replication Controller Definition File in vi Editor

从定义文件创建复制控制器。

```
kubectl create -f kafka-rc.yaml  

```

随后列出复制控制器。

```
kubectl get rc

```

复制控制器被创建并列出，如图 [12-15](#Fig15) 所示。

![A418863_1_En_12_Fig15_HTML.gif](A418863_1_En_12_Fig15_HTML.gif)

图 12-15。

Creating the Replication Controller from the Definition File

要描述`kafka-rc`,运行以下命令。

```
kubectl describe rc kafka-rc

```

复制控制器描述被列出，如图 [12-16](#Fig16) 所示。

![A418863_1_En_12_Fig16_HTML.gif](A418863_1_En_12_Fig16_HTML.gif)

图 12-16。

Describing the Replication Controller

## 列出 POD

要列出窗格，请运行以下命令。

```
kubectl get pods

```

吊舱被列出，如图 [12-17](#Fig17) 所示。

![A418863_1_En_12_Fig17_HTML.gif](A418863_1_En_12_Fig17_HTML.gif)

图 12-17。

Listing the pods for Kafka

## 描述一个 Pod

仅创建一个 Pod，因为定义文件`kafka-rc.yaml`中的“副本”设置为 1。要描述 Pod，请运行以下命令。

```
kubectl describe pod kafka-rc-k8as1

```

吊舱描述被列出，如图 [12-18](#Fig18) 所示。Pod 标签`app=kafkaApp`与服务选择器和复制控制器选择器相同，这使得服务和复制控制器可以管理 Pod。

![A418863_1_En_12_Fig18_HTML.gif](A418863_1_En_12_Fig18_HTML.gif)

图 12-18。

Describing a pod for Kafka

当 Pod 被创建和启动时，Zookeeper 服务器开始启动，因为用于修改的 Docker 映像的命令是启动 Zookeeper 服务器。接下来，我们将从 Docker 容器的交互式 shell 中启动 Kafka 服务器，用于修改后的 Docker 映像。

## 启动交互式 Shell

为了能够启动交互式 bash shell 来访问安装的 Kafka 软件，我们需要知道运行修改后的 Docker 映像的 Docker 容器的容器 id。用下面的命令列出 Docker 容器。

```
sudo docker ps

```

Docker 容器如图 [12-19](#Fig19) 所示。

![A418863_1_En_12_Fig19_HTML.gif](A418863_1_En_12_Fig19_HTML.gif)

图 12-19。

Obtaining the Docker Container Id

复制容器 id 并启动交互式 bash shell。

```
sudo docker exec -it 939ae2cb4f86 bash

```

交互外壳启动，如图 [12-20](#Fig20) 所示。

![A418863_1_En_12_Fig20_HTML.gif](A418863_1_En_12_Fig20_HTML.gif)

图 12-20。

Starting the Interactive TTY for the Docker Container

## 启动 Kafka 服务器

Kafka 服务器的配置属性在`config/server.properties`文件中设置，我们在重建 Docker 映像时修改了这个文件。因为 Zookeeper 已经在运行，所以用下面的命令启动 Kafka 服务器。

```
kafka-server-start.sh /opt/kafka_2.10-0.8.2.1/config/server.properties

```

前面的命令如图 [12-21](#Fig21) 所示。

![A418863_1_En_12_Fig21_HTML.gif](A418863_1_En_12_Fig21_HTML.gif)

图 12-21。

Starting the Kafka Server

Kafka 服务器启动，如图 [12-22](#Fig22) 所示。

![A418863_1_En_12_Fig22_HTML.gif](A418863_1_En_12_Fig22_HTML.gif)

图 12-22。

Kafka Server started at localhost:9092

## 创建主题

接下来，用下面的命令创建一个名为“kafka-on-kubernetes”的主题。将分区数量设置为 1，将复制因子设置为 1。动物园管理员设置为`localhost:2181`。

```
kafka-topics.sh --create --topic kafka-on-kubernetes --zookeeper localhost:2181 --replication-factor 1 --partitions 1

```

如图 [12-23](#Fig23) 所示，`kafka-on-kubernetes`主题被创建。

![A418863_1_En_12_Fig23_HTML.gif](A418863_1_En_12_Fig23_HTML.gif)

图 12-23。

Creating a Kafka Topic

## 创建 Kafka 制作人

Kafka 生产者是用来生产信息的。启动 ZooKeeper 和 Kafka 服务器后，启动 Kafka producer。使用`–topic`选项将主题指定为“kafka-on-kubernetes”。`--broker-list`指定 Kafka 服务器为`localhost:9092`，这是在`server.properties`文件中配置的设置。

```
kafka-console-producer.sh --topic kafka-on-kubernetes --broker-list localhost:9092

```

如图 [12-24](#Fig24) 所示，Kafka 制作人开始了。

![A418863_1_En_12_Fig24_HTML.gif](A418863_1_En_12_Fig24_HTML.gif)

图 12-24。

Starting a Kafka Producer

## 启动 Kafka 消费者

Kafka 式的消费者消费信息。使用以下命令启动 Kafka 消费程序。使用`–topic`选项将主题指定为“kafka-on-kubernetes”。`--zookeeper`指定 Zookeeper 服务器为`localhost:2181`，这是在`server.properties`文件中配置的设置。`--from-beginning`选项指定从一开始就要消费消息，而不仅仅是消费者启动后消费的消息。

```
kafka-console-consumer.sh --topic kafka-on-kubernetes --from-beginning --zookeeper localhost:2181

```

如图 [12-25](#Fig25) 所示，Kafka 制作人开始了。

![A418863_1_En_12_Fig25_HTML.jpg](A418863_1_En_12_Fig25_HTML.jpg)

图 12-25。

Starting a Kafka Consumer

## 生产和消费消息

启动了生产者和消费者之后，我们将在生产者处产生消息，在消费者处消费消息。如图 [12-26](#Fig26) 所示，在生产者处添加一条消息，例如“来自 Kafka 生产者的消息”,并点击输入按钮。信息被发送出去。

![A418863_1_En_12_Fig26_HTML.jpg](A418863_1_En_12_Fig26_HTML.jpg)

图 12-26。

Producing a Message at the Kafka Producer

在消费者处，消息被消费，如图 [12-27](#Fig27) 所示。

![A418863_1_En_12_Fig27_HTML.gif](A418863_1_En_12_Fig27_HTML.gif)

图 12-27。

Consuming a Message at the Kafka Consumer

在生产者处发送更多消息，如图 [12-28](#Fig28) 所示。

![A418863_1_En_12_Fig28_HTML.gif](A418863_1_En_12_Fig28_HTML.gif)

图 12-28。

Producing More Messages at the Kafka Producer

并且消息在消费者处被消费，如图 [12-29](#Fig29) 所示。

![A418863_1_En_12_Fig29_HTML.gif](A418863_1_En_12_Fig29_HTML.gif)

图 12-29。

Consuming More Messages at the Kafka Consumer

## 扩展集群

要将群集从 1 个单元扩展到 4 个单元，请运行以下命令。

```
kubectl scale rc kafka-rc --replicas=4

```

随后列出 POD。

```
kubectl get pods

```

输出“scaled”表示集群已被缩放，如图 [12-30](#Fig30) 所示。随后吊舱被列出，也如图 [12-30](#Fig30) 所示。

![A418863_1_En_12_Fig30_HTML.gif](A418863_1_En_12_Fig30_HTML.gif)

图 12-30。

Scaling the Kafka Cluster

当 pod 的数量增加到 4 时，服务端点也增加到 4。描述服务`kafka`。

```
kubectl describe svc kafka

```

如图 [12-31](#Fig31) 所示，这两个服务都列出了 4 个端点，一个用于 Zookeeper 服务器，另一个用于 Kafka 服务器。

![A418863_1_En_12_Fig31_HTML.gif](A418863_1_En_12_Fig31_HTML.gif)

图 12-31。

Describing the Kafka Service with 4 Endpoints

## 删除复制控制器和服务

要删除复制控制器和服务，请运行以下命令。

```
kubectl delete rc kafka-rc
kubectl delete service kafka

```

如图 [12-32](#Fig32) 所示，复制控制器和服务被删除。

![A418863_1_En_12_Fig32_HTML.gif](A418863_1_En_12_Fig32_HTML.gif)

图 12-32。

Deleting the Kafka Replication Controller and Service

## 摘要

Apache Kafka 是一个基于生产者和消费者的信息系统。在本章中，我们讨论了使用 Kubernetes 管理 Kafka 集群。管理 Kafka 不同于其他一些应用，因为必须启动两个服务器:Zookeeper 服务器和 Kafka 服务器。Kafka 服务器依赖于 Zookeeper 服务器，这意味着 Zookeeper 必须在 Kafka 服务器之前启动。我们需要修改 zookeeper 连接 url 的默认映像`dockerkafka/kafka`。在复制控制器定义文件中，我们使用一个定制命令来运行修改后的 Docker 映像，以启动 Zookeeper 服务器，Docker 映像中的默认设置是启动 Kafka 服务器。到目前为止，我们运行的所有应用都是基于单个容器 Pod 的。在下一章中，我们将开发一个多容器 Pod。