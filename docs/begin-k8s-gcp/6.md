# 六、作业

批处理与持久性应用程序(如 web 服务器)的不同之处在于，一旦程序达到目标，它们就会完成并终止。批处理的典型示例包括数据库迁移脚本、视频编码作业和提取-加载-转换(ETL)操作手册。与 ReplicaSet 控制器类似，Kubernetes 有一个专用的 *Job* 控制器，用于管理 pod 以运行面向批处理的工作负载。

使用作业来检测批处理过程相对简单，我们将在这一简短的章节中很快了解到这一点。在第一部分，我们将学习*完成*和*并行*的概念，这是决定作业动态的两个基本变量。然后，我们将探索可以使用作业控制器实现的三种基本批处理类型:*单个批处理*、*基于完成计数的批处理*和*外部协调批处理。*最后，在接近尾声时，我们将看看与作业处理相关的典型管理任务:确定作业何时完成，用适当的超时阈值配置作业，以及在不处理作业结果的情况下删除作业。

## 完成和并行

Kubernetes 依靠标准的 Unix 退出代码来判断一个 Pod 是否成功地完成了它的任务。如果一个 Pod 的容器进入过程通过返回退出代码`0`而结束，则认为该 Pod 已经*成功地完成了*它的目标。否则，如果代码不为零，则认为 Pod 出现故障。

作业控制器使用两个关键概念来编排作业:*完成*和*并行*。使用`job.spec.completions`属性指定的完成决定了作业必须运行的次数，并以成功退出代码退出—换句话说，`0`。相反，使用`job.spec.parallelism`属性指定的并行性设置了可以并行运行的作业数量——换句话说，就是并发运行。

这两个属性值的组合将决定为实现给定完成数而创建的*个唯一 pod*的数量，以及可能加速旋转的*个并行 pod*(并行运行的 pod)的数量。表 [6-1](#Tab1) 提供了一组样本组合的结果。

表 6-1

各种完成和平行排列的效果

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"></colgroup> 
| 

`completions`

 | 

`parallelism`

 | 

独特的豆荚

 | 

平行吊舱

 |
| --- | --- | --- | --- |
| 未设置 | 未设置 | one | one |
| one | 未设置 | one | one |
| one | one | one | one |
| three | one | three | one |
| three | three | three | three |
| one | three | one | one |
| 未设置 | three | three | three |

现在没有必要花费太多的精力来计算出表 [6-1](#Tab1) 中给出的组合。在接下来的章节中，我们将学习`completions`和`parallelism`在实际用例中的正确用法。

## 批处理类型概述

批处理可以分为三种类型:单个批处理、基于完成计数的批处理和外部协调的批处理:

*   **单一批处理:**成功运行一次 Pod 就足以完成工作。

*   **基于完成计数的批处理:**一个 *n* 数量的 pod 必须成功完成才能完成任务——并行、顺序或两者结合。

*   **外部协调批处理:**一群工人在一个集中协调的任务上工作。所需完成的数量事先并不知道。

如前一节所述，*成功*的定义是 Pod 的容器流程终止，产生值为`0`的退出状态代码。

## 单批次过程

使用计划成功运行一次的 Pod 来实现单个批处理过程。这种作业可以以命令和声明的方式运行。使用`kubectl create job <NAME> --image=<IMAGE>`命令创建一个任务。让我们考虑一个计算两个时间表的 Bash 脚本:

```
for i in $(seq 10)
  do echo $(($i*2))
done

```

我们可以将这个脚本作为一个作业以命令的方式运行，或者通过将它作为参数传递给`alpine`的`sh`命令:

```
$ kubectl create job two-times --image=alpine \
    -- sh -c \
    "for i in \$(seq 10);do echo \$((\$i*2));done"
job.batch/two-times created

```

### 注意

也可以使用`traditional kubectl run <NAME> --image=<IMAGE> --restart=OnFailure`命令创建作业。这种传统形式现在已被否决；使用`kubectl run`创建作业时，添加标志`--restart=OnFailure`必不可少；如果省略，将改为创建部署。

可以通过运行`kubectl logs -l job-name=<NAME>`命令来获得结果，该命令会将窗格(本例中只有一个)与作业名称的标签进行匹配。作业控制器将添加值`job-name`并将其设置为自己的名称，以便于识别作业和 pod 之间的父子关系:

```
$ kubectl logs -l job-name=two-times
2
4
6
8
10
12
14
16
18
20

```

我们刚刚运行了我们的第一个任务。尽管这一偶数序列可能看起来很简单，但应该理解，作为作业装备的工作负载可以像该示例一样简单，也可以像针对 SQL 数据库运行查询或训练机器学习算法的代码一样复杂。

需要记住的一个方面是，单批次过程不是“一劳永逸”的；它们将资源留在周围，必须手动清理，我们将在后面看到。事实上，同一个作业名不能使用两次，除非我们先删除第一个实例。

### 注意

我们可能需要添加`--tail=-1`标志来显示所有结果，只要我们看起来缺少行。当使用标签选择器时，如`two-times.yaml`的情况，行数限制为 10。

使用`kubectl get jobs`命令列出可用的作业，当考虑`COMPLETIONS`列下的值`1/1`时，将会发现一个预期完成，而一个实际上已存档:

```
$ kubectl get jobs
NAME        COMPLETIONS   DURATION   AGE
two-times   1/1           3s         9m6sm

```

当我们键入`kubectl get pods`时，作业控制的单元可以通过作业的前缀来识别，在本例中为`two-times`:

```
$ kubectl get pods
NAME             READY   STATUS      RESTARTS   AGE
two-times-4lrp8  0/1     Completed   0          8m45s

```

接下来显示了该作业的声明性等效项，它是通过使用`kubectl apply -f two-times.yaml`命令运行的:

```
# two-times.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: two-times
spec:
  template:
    spec:
      containers:
      - command:
        - /bin/sh
        - -c
        - for i in $(seq 10);do echo $(($i*2));done
        image: alpine
        name: two-times
      restartPolicy: Never

```

请注意，`job.spec.completions`和`job.spec.paralellism`属性不存在；它们都将被赋予默认值`1`。

还要记住，除非我们使用`kubectl delete job/<NAME>`命令明确删除，否则作业控制器及其完成的 Pod 都不会被删除。如果我们想在尝试了具有相同作业名称的命令式表单后立即运行该清单，记住这一点很重要。

`two-times.yaml`作业是一个保证成功的简单脚本的例子。如果工作失败了怎么办？例如，考虑下面的脚本，它明确地打印主机名和日期，并带有一个不成功的退出代码`1`:

```
echo $HOSTNAME failed on $(date) ; exit 1

```

作业控制器对运行该脚本的反应方式主要取决于两个方面:

*   `job.spec.backoffLimit`属性(默认设置为 6)将决定作业控制器在放弃之前尝试运行 Pod 的次数。

*   `job.spec.template.spec.restartPolicy`属性可以是`Never`或`OnFailure`，它将决定每次重试是否会启动新的 pod。如果设置为前者，作业控制器将在每次尝试时旋转一个新的 Pod，而不处理失败的 Pod。相反，如果设置为后者，作业控制器将重新启动同一个 Pod，直到成功；然而，因为失效的吊舱被重新利用——通过*重启*它们——它们因失效而产生的输出丢失了。

在`Never`和`OnFailure`的`restartPolicy`值之间做出决定，取决于我们更能接受什么样的妥协。`Never`通常是最明智的选择，因为它不处理故障吊舱的输出，并允许我们排除故障；然而；将失效的Pods留在周围会占用更多的资源。理想情况下，工业作业解决方案应该将有价值的数据保存到永久存储介质中，例如第 [2](2.html) 章中演示的附件。

现在让我们看看每一个用例，以便更直观地了解每一个用例的副作用。接下来呈现的`unlucky-never.yaml`清单将`backoffLimit`属性设置为`3`，将`restartPolicy`属性设置为`Never`:

```
# unlucky-never.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: unlucky
spec:
  backoffLimit: 3
  template:
    spec:
      restartPolicy: Never
      containers:
        - command:
        - /bin/sh
        - -c
        - echo $HOSTNAME failed on $(date) ; exit 1
        name: unlucky
        image: alpine

```

我们将通过发出`kubectl apply -f unlucky-never.yaml`命令来运行`unlucky-never.yaml`，但是首先，我们将打开一个单独的窗口，在该窗口中我们将运行`kubectl get pods -w`来查看作业控制器创建了什么 Pods，因为它对`exit 1`产生的故障做出反应:

```
$ kubectl get pods -w
unlucky-6qm98 0/1   Pending             0        0s
unlucky-6qm98 0/1   ContainerCreating   0        0s
unlucky-6qm98 0/1   Error               0        1s
unlucky-sxj97 0/1   Pending             0        0s
unlucky-sxj97 0/1   ContainerCreating   0        0s
unlucky-sxj97 1/1   Running             0        0s
unlucky-sxj97 0/1   Error               0        1s
unlucky-f5h9c 0/1   Pending             0        0s
unlucky-f5h9c 0/1   ContainerCreating   0        0s
unlucky-f5h9c 0/1   Error               0        0s

```

可以理解，创建了三个新的吊舱:`unlucky-6qm98`、`unlucky-sxj97`和`unlucky-f5h9c`。一切都以错误告终，但为什么呢？让我们检查他们的日志:

```
$ kubectl logs -l job-name=unlucky
unlucky-6qm98 failed on Sun Jul 14 15:45:18 UTC 2019
unlucky-f5h9c failed on Sun Jul 14 15:45:30 UTC 2019
unlucky-sxj97 failed on Sun Jul 14 15:45:20 UTC 2019

```

这就是将`restartPolicy`属性设置为`Never`的好处。如前所述，失败 pod 的日志被保留，这允许我们诊断错误的性质。最后一个有用的检查是通过`kubectl describe job/<NAME>`命令。接下来，我们看到当前没有 pod 在运行，零个成功，三个失败:

```
$ kubectl describe job/unlucky | grep Statuses
Pods Statuses:  0 Running / 0 Succeeded / 3 Failed

```

将`restartPolicy`属性设置为`OnFailure`会导致完全不同的行为。让我们再次进行同样的练习，但是使用一个名为`unlucky-onFailure.yaml`的新清单，其中唯一的变化是前面提到的属性:

```
# unlucky-onFailure.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: unlucky
spec:
  backoffLimit: 3
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - command:
        - /bin/sh
        - -c
        - echo $HOSTNAME failed on $(date) ; exit 1
        name: unlucky
        image: alpine

```

在通过发出`kubectl apply -f unlucky-onFailure.yaml`命令来应用清单之前，我们将在一个单独的终端窗口中跟踪`kubectl get pods -w`的结果，就像我们之前所做的那样。

```
$ kubectl get pods -w
NAME          READY STATUS             RESTARTS AGE
unlucky-fgtq4 0/1   Pending            0        0s
unlucky-fgtq4 0/1   ContainerCreating  0        0s
unlucky-fgtq4 0/1   Error              0        0s
unlucky-fgtq4 0/1   Error              1        1s
unlucky-fgtq4 0/1   CrashLoopBackOff   1        2s
unlucky-fgtq4 0/1   Error              2        17s
unlucky-fgtq4 0/1   CrashLoopBackOff   2        30s
unlucky-fgtq4 1/1   Running            3        41s
unlucky-fgtq4 1/1   Terminating        3        41s
unlucky-fgtq4 0/1   Terminating        3        42s

```

与`unlucky-never.yaml`的`restartPolicy`是`Never`相比，我们在这里看到两个关键的不同:只有一个 Pod，`unlucky-fgtq4`，它被重启三次，而不是三个不同的 Pod，并且 Pod 在结束时终止，而不是以`Error`状态结束。最根本的副作用是日志被删除，因此我们无法诊断问题:

```
$ kubectl logs -l job-name=unlucky
# nothing

```

另一个值得注意的区别是`kubectl describe job/unlucky`命令会声称只有一个吊舱发生了故障。这是真的；只有一个吊舱确实发生了故障——尽管它根据`backoffLimit`设置重启了三次:

```
$ kubectl describe job/unlucky | grep Statuses
Pods Statuses:  0 Running / 0 Succeeded / 1 Failed

```

## 基于完成计数的批处理

运行一个 Pod 一次、两次或更多次，并以成功退出代码结束的概念被称为*完成*。在单个批处理过程的情况下，如前一节所示，`job.spec.completions`的值默认为`1`；相反，基于完成计数的批处理过程通常将`completions`属性设置为大于或等于 2 的值。

在这个用例中，pod 独立运行*和*，彼此没有意识。换句话说，每个 Pod 相对于其他 Pod 的结果和成果是孤立运行的。Pods 中运行的代码如何决定处理哪些数据，如何避免重复工作，以及将结果保存在哪里，这些都是作业控制能力无法解决的实现问题。实现共享状态的典型解决方案是外部队列、数据库或共享文件系统。由于进程是独立的，它们可以并行运行；可以并行运行的进程数量是使用`job.spec.parallelism`属性指定的。

通过组合使用`job.spec.completions`和`job.spec.parallelism`，我们可以控制一个流程必须运行多少次，以及有多少次将并行运行，以加快总体批处理时间。

为了内部化多个独立过程的工具，我们需要一个独立于其他实例的过程的例子，但是同时，原则上收集不同的结果。为此，我们设计了一个 Bash 脚本，它检查当前时间，如果当前秒是偶数则报告成功，如果是奇数则报告失败:

```
n=$(date +%S)
if [ $((n%2)) -eq 0 ]
then
  echo SUCCESS: $n
  exit 0
else
  echo FAILURE: $n
  exit 1
fi

```

作为一个首要目标，我们开始收集六个偶数秒的样本；这意味着我们将`job.spec.completions`设置为`6`。我们还想通过并行运行两个 pod 来加速这个过程，所以我们将`job.spec.parallelism`设置为`2`。最终的结果是下面的清单，命名为`even-seconds.yaml`:

```
# even-seconds.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: even-seconds
spec:
  completions: 6
  parallelism: 2
  template:
    spec:
      restartPolicy: Never
      containers:
     - command:
       - /bin/sh
       - -c
       - >
          n=$(date +%S);
          if [ $((n%2)) -eq 0 ];
          then
            echo SUCCESS: $n;
            exit 0;
          else
            echo FAILURE: $n;
            exit 1;
          fi
        name: even-seconds
        image: alpine

```

为了理解这个例子的动态性，设置如下三个终端窗口(或标签/面板)是很方便的:

*   **终端窗口 1** :通过运行`kubectl get job -w`观察作业活动

*   **终端窗口 2** :通过运行`kubectl get pods -w`观察 Pod 活动

*   **终端窗口 3** :发出`apply -f even-seconds.yaml`命令运行`even-seconds.yaml`。

通过在前缀为`Pod Statuses`的行中运行`kubectl describe job/even-seconds`命令，可以获得一个有趣的摘要，该行是从运行时填充的`job.status`下的值获得的。

让我们应用`even-seconds.yaml`,并根据其编排的 pod 来观察作业的行为:

```
# Keep this running before running `kubectl apply`
$ while true; do kubectl describe job/even-seconds \
    | grep Statuses ; sleep 1 ; done
Pods Statuses:  2 Running / 0 Succeeded / 0 Failed
Pods Statuses:  2 Running / 0 Succeeded / 1 Failed
Pods Statuses:  2 Running / 0 Succeeded / 2 Failed
Pods Statuses:  2 Running / 1 Succeeded / 3 Failed
Pods Statuses:  2 Running / 3 Succeeded / 3 Failed
Pods Statuses:  1 Running / 5 Succeeded / 3 Failed
Pods Statuses:  0 Running / 6 Succeeded / 3 Failed

```

结果输出是不确定的；失败和重启的次数，以及实际收集的结果，将取决于无数的因素:容器的启动时间、当前时间、CPU 速度等。

已经说明了读者可能会获得不同的结果，让我们分析输出。一开始，作业控制器启动了两个 pod，其中没有一个既没有成功也没有失败。然后，在第二行中，一个 Pod 发生故障，但是由于`parallelism`被设置为`2`，另一个 Pod 被启动，因此总是有两个并行运行。过程进行到一半时，作业控制器开始注册更多成功的 pod。在倒数第二行中，只有一个 Pod 正在运行，因为五个已经成功，只剩下一个。最后，在最后一行中，最后一个 Pod 成功完成了我们预期的完成数量:6。

我们跳过`kubectl get pods -w`的输出，留给读者作为练习(它将与显示不同状态的多个 pod 的早期输出一致:`ContainerCreating`、`Error`、`Completed`等)。).我们的首要目标是获得 6 个偶数秒的样本，看看这个目标是否已经实现，这很有意思。让我们检查日志，看看:

```
$ kubectl logs -l job-name=even-seconds \
    | grep SUCCESS
SUCCESS: 34
SUCCESS: 32
SUCCESS: 34
SUCCESS: 30
SUCCESS: 32
SUCCESS: 36

```

这正是我们要实现的目标。失败的豆荚怎么办？如果我们将`restartPolicy`属性设置为`OnFailure,`的话，可能很难发现，但是因为我们特意选择了`Never`，我们可以从失败的作业中检索输出，并确认失败是由于奇数秒的采样造成的:

```
$ kubectl logs -l job-name=even-seconds \
    | grep FAILURE
FAILURE: 27
FAILURE: 27
FAILURE: 29

```

在进入第三个用例之前，当设置`job.spec.completions`和`job.spec.paralellism`属性时，值得注意的一个方面是，作业控制器永远不会实例化多于预期(和/或剩余)完成数的并行 pod。例如，如果我们定义`completions: 2`和`parallelism: 5`，就好像我们已经将`parallelism`设置为`2`。同样，并行运行的 pod 的数量永远不会大于待完成的数量。

## 外部协调批处理

当有一个控制机制告诉每个 Pod 是否还有工作单元要完成时，就说批处理是外部协调的。在最基本的形式中，这被实现为一个队列:控制进程(生产者)将任务插入到一个队列中，然后由一个或多个工作进程(消费者)进行检索。

在这种情况下，作业控制器假设多个 Pod 针对相同的目标工作，并且无论何时 Pod 报告成功完成，总体批次目标完成，并且不需要进一步的 Pod 运行。想象一个由三个人组成的团队——Mary、Jane 和 Joe——为搬家公司工作，正在将家具装入货车。当简把最后一件家具搬进货车时，比如一把椅子，不仅简的工作完成了，玛丽和乔的工作也完成了；他们都会报告工作完成了。

配置一个作业来满足这个用例需要将`job.spec.parallelism`属性设置为期望的并行工作线程数，但是不设置`job.spec.completions`属性。本质上，我们只定义了池中工作进程的数量。这是将外部协调批处理过程与基于单个和完成计数的批处理过程区分开来的关键方面。

为了演示这个用例，我们首先需要建立某种形式的控制队列机制。为了确保我们专注于手头的学习目标——如何配置外部协调的作业——我们将避免引入大型队列或发布/订阅解决方案，如 RabbitMQ 相反，我们将定义一个简单的进程，它监听端口 1080，并为每个网络请求提供一个新的整数(从 1 开始):

```
i=1
while true; do
  echo -n $i | nc -l -p 1080
  i=$(($i+1))
done

```

这个脚本的工作方式与医院和邮局中的红色售票机完全一样，第一个客户得到票 1，第二个客户得到票 2，依此类推。不同之处在于，在我们基于 shell 的版本中，客户通过使用`nc`命令打开端口 1080 获得一个新的号码，而不是从分发器中取出一张票。还请注意，我们使用 Alpine 发布的 Netcat ( `nc`)命令来设置一个虚拟 TCP 服务器；值得注意的是，就可用标志的数量和类型而言，Netcat 的实现在不同的操作系统之间往往是相当分散的。

在我们创建一个作业来使用队列中的票证之前，让我们先看看运行中的脚本，以便熟悉它的操作。使用`kubectl run`命令将提供的 shell 脚本作为 Pod 启动，并使用`--expose`标志将其公开为服务，这样就可以从其他 Pod 使用`queue`主机名对其进行访问:

```
$ kubectl run queue --image=alpine \
    --restart=Never \
    --port=1080 \
    --expose \
    -- sh -c \
      "i=1;while true;do echo -n \$i \
      | nc -l -p 1080; i=\$((\$i+1));done"
service/queue created
pod/queue created

```

我们可以手动测试`queue` Pod，如下例所示，但是我们必须记住在运行其余示例之前重启部署的 Pod，以便计数器再次从`1`开始计数。或者，在章节的源文件夹中提供了一个名为`startQueue.sh`的脚本，它删除任何现有的运行队列并启动一个新队列:

```
$ kubectl run test --rm -ti --image=alpine \
    --restart=Never -- sh
If you don't see a command prompt, try pressing enter.
/ # nc -w 1 queue 1080
1
/ # nc -w 1 queue 1080
2
/ # nc -w 1 queue 1080
3
/ # nc -w 1 queue 1080
...

```

请注意，`nc`命令引用的名为`queue`的主机是服务控制器创建的 DNS 条目，这是在前面的示例中启动队列 Pod 时添加标志`--expose`的结果。现在我们有一个中央程序来协调多个 pod 的工作。尽管可能很简单，但队列服务为每个消费者提供了一个独特的任务——由一个新的整数表示。现在让我们定义一个消费者流程，它的工作只是从队列服务中取出一个整数，然后乘以 2。当数字为 101 或更大时，总体目标被认为已经实现，脚本可以通过返回`0`——成功退出状态代码来宣告胜利:

```
while true
do n=$(nc -w 1 queue 1080)
   if [ $(($n+0)) -ge 101 ]
   then
     exit 0
   else r=$(($n*2))
     echo -en "$r\n"
     sleep 1
   fi
done

```

如果这个脚本独立运行，它将产生一个数字序列`2, 4, 6, ...`，直到到达`200`。比如说，在 1080 端口访问`queue`的任何失败都会导致一个非零的退出代码。现在让我们将 shell 脚本嵌入到容器的隔间中，这样我们就可以使用`alpine`图像来运行它:

```
# multiplier.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: multiplier
spec:
  parallelism: 3
  template:
    spec:
      restartPolicy: Never
      containers:
      - command:
        - /bin/sh
        - -c
        - >
          while true;
          do n=$(nc -w 1 queue 1080);
            if [ $(($n+0)) -ge 101 ];
            then
              exit 0;
            else r=$(($n*2))
              echo -en "$r\n";
              sleep 1;
            fi;
          done
        name: multiplier
        image: alpine

```

我们现在通过执行`kubectl apply -f <FILE>`命令来运行作业:

```
$ kubectl apply -f multiplier.yaml
job "multiplier" created

```

我们可以通过在单独的窗口或选项卡上运行`kubectl get pods -w`和`kubectl get jobs -w`命令来观察作业的行为，如本章前面所建议的。我们将看到三个 pod 将被实例化，几秒钟后，它们的状态将从`Running`转变为`Complete`。这几乎是同时发生的，因为它们几乎同时开始获得一个等于或大于 101 的数:

```
$ kubectl get pods
NAME               READY   STATUS    RESTARTS   AGE
multiplier-7zdm7   1/1     Running   0          7s
multiplier-gdjn2   1/1     Running   0          7s
multiplier-k9fz8   1/1     Running   0          7s
queue              1/1     Running   0          50s

# A few seconds later...
$ kubectl get pods
NAME               READY   STATUS      RESTARTS   AGE
multiplier-7zdm7   0/1     Completed   0          36s
multiplier-gdjn2   0/1     Completed   0          36s
multiplier-k9fz8   0/1     Completed   0          36s
queue              1/1     Running     0          79s

```

所有三个 pod 的组合结果应该是从 2 到 200 的总共 100 个数字。我们可以通过计算已经生成的行数和检查整个列表本身来检查作业是否完全成功:

```
$ kubectl logs -l job-name=multiplier --tail=-1 | wc
    100     100     347

$ kubectl logs -l job-name=multiplier --tail=-1 \
   | sort -g
2
4
6
...
196
198
200

```

### 注意

`--tail=-1`标志是必要的，因为标签选择器`-l`的使用将尾部限制设置为 10。

如果我们想要一个更正式的成功证明，我们还可以对 2 到 200 之间的偶数列表求和，并证明合并后的对数之和是相同的:

```
$ n=0;for i in $(seq 100);do \
    n=$(($n+($i*2)));done;echo $n
10100

$ n=0; \
  list=$(kubectl logs -l job-name=multiplier \
    --tail=-1); \
    for i in $list;do n=$(($n+$i));done;echo $n
10100

```

在端口 1080 上运行的`queue`服务产生一系列整数，再加上`multiplier`作业读取这些数字并将它们乘以 2，这两者的结合展示了使用作业控制器如何实现高度可伸缩、可并行的批处理过程。每个 Pod 实例工作于乘以一个整数，这是相当随机的，取决于哪个 Pod 首先命中`queue`服务；但是所有独立计算的聚合结果会产生一个介于 2 和 200 之间的偶数的完整列表。

### 注意

如果`multiplier`作业在尝试访问`queue` TCP 服务器时发现一些错误，那么`wc`提供的计数可能会大于 100，因为它也会包含错误。

## 等待作业完成

有多种方法可以检查作业是否以特定方式完成。我们可以使用`kubectl get jobs`来查看成功完成的数量，或者使用`kubectl get pod`来查看作业的状态。但是，如果我们想将这种检查集成到编程场景中，我们需要直接询问作业对象。判断作业是否已经完成的一个简单方法是查询`job.status.completionTime`属性，该属性只填充相关作业完成的时间。

例如，以下 shell 表达式通过重复检查直到`job.status.completionTime`属性变为非空，一直等到`multiplier`作业完成:

```
$ until [ ! -z $(kubectl get job/multiplier \
    -o jsonpath \
    --template="{.status.completionTime}") ]; \
    do sleep 1 ; echo waiting ... ; done ; echo done

```

## 暂停卡住的作业

一般来说，只要失败是因为依赖项不可用，让失败的作业继续运行是一个好主意。例如，在我们用来演示外部协调批处理的用例的`multiplier`作业的情况下，Pod 控制器将保持重启 Pod，直到`queue`服务变得可用——假设重试次数不大于`backoffLimit`。这种行为提高了去耦性和可靠性。

但是，在某些情况下，我们对作业在中止之前可能保持失败、未完成状态的最长时间有精确的预期。实现这一点的方法是将`job.spec.activeDeadlineSeconds`属性设置为所需的秒数。

例如，让我们采用之前使用过的相同的`multiplier`作业，并将`job.spec.activeDeadlineSeconds`值设置为 10:

```
# multiplier-timeout.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: multiplier
spec:
  activeDeadlineSeconds: 10
...

```

如果我们运行作业，假设我们没有启动*队列*服务——我们可以通过运行`kubectl delete all --all`来清理环境——并且我们观察`job.status`的值，我们将看到作业最终会被取消:

```
$ kubectl apply -f multiplier-timeout.yaml
job "multiplier" created

$ kubectl get job/multiplier -o yaml -w \
    | grep -e   "^status:" -A 10
status:
  active: 3
  failed: 1
  startTime: "2019-07-17T22:49:37Z"
--
status:
  conditions:
 - lastProbeTime: "2019-07-17T22:49:47Z"
    lastTransitionTime: "2019-07-17T22:49:47Z"
    message: Job was active longer
             than specified deadline
    reason: DeadlineExceeded
    status: "True"
    type: Failed
  failed: 4
  startTime: "2019-07-17T22:49:37Z"

```

正如在显示的输出中可以看到的，在由`.status.startTime`属性指示的时间之后十秒钟，由于`DeadlineExceeded`条件，作业结束。

另一种超时作业的方法是设置`job.spec.backoffLimit`属性，默认情况下是`6`。该属性定义了作业控制器在因终端错误而结束时应该创建新 Pod 的次数。但是，我们必须记住，默认情况下，每次重试的等待时间都比前一次(10 秒、20 秒、40 秒等)要长。)

最后，`activeDeadlineSeconds`属性为整个作业的持续时间设置一个超时，不管它是否处于失败状态。如果到达设定的截止日期，正在经历各种成功完成而没有一个失败的 Pod 的作业也将被中止。

## 管理摘要

与任何其他常规 Kubernetes 对象一样，可以使用`kubectl get jobs`命令列出作业对象，并使用`kubectl delete job/<NAME>`命令删除作业对象。类似于其他控制器，如 ReplicaSet one，`delete`命令有一个*级联*效果，在某种意义上，它也将删除作业标签选择器引用的窗格。如果我们只想删除作业本身，我们需要使用`--cascade=false`标志。例如，在接下来给出的命令序列中，我们运行了用于演示基于完成计数的批处理过程的`two-times.yaml`作业，我们删除了该作业，然后，最后，我们得到了由 pod 生成的结果:

```
# Create a Job
$ kubectl apply -f two-times.yaml
job.batch/two-times created

# Delete the Job with but not its Pods
$ kubectl delete job/two-times --cascade=false
job.batch "two-times" deleted

# Confirm that the Job is effectively deleted
$ kubectl get jobs
No resources found.

# Extract logs from the two-times Pods
$ kubectl logs -l job-name=two-times | wc
     10      10      26

```

## 摘要

在本章中，我们了解到作业是一个 Pod 控制器，类似于 ReplicaSet 控制器，不同之处在于作业预计会在某个时间点终止。我们看到，作业中的基本工作单元是完成，它发生在一个状态代码为`0`的 Pod 存在时，并行性允许通过增加并发工作 Pod 的数量来扩展批处理吞吐量。

我们探讨了批处理用例的三种基本类型:单个批处理、基于完成计数的批处理和外部协调的批处理。我们强调了外部协调的批处理过程与基于单个和完成计数的批处理过程之间的关键区别在于，前者的成功标准取决于作业控制器外部的机制，通常是队列。

最后，我们研究了常规的管理任务，比如监视一个作业直到它完成，暂停停滞的作业，删除它们同时保留它们的结果。