# 八、DaemonSet

DaemonSet 控制器确保每个节点运行一个 Pod 实例。这对于需要在节点级别部署的统一、水平的服务非常有用，例如日志收集器、缓存代理、代理或任何其他类型的系统级功能。但是，为什么像 Kubernetes 这样的分布式系统会把 pod 和“盒子”之间的“紧密耦合”作为一个特性来推广呢？因为性能优势——有时是完全必要的。部署在同一节点内的 pod 可以共享本地网络接口以及本地文件系统；其好处是，与“非机载”网络交互的情况相比，延迟损失要低得多。

在某种程度上，DaemonSet 以 pod 处理容器的方式处理节点:虽然 pod 确保两个或更多容器并置在一起，但 daemon set 保证守护程序(也作为 pod 实现)在每个节点上始终本地可用，以便消费者 Pods a 可以访问它们。

这一简短的章节组织如下:首先，我们将探索 DaemonSets 的两个广泛的连接性用例(TCP 和文件系统)。然后，我们将学习如何使用标签来定位特定的节点。最后，我们将描述部署和 DaemonSets 之间更新策略的差异，以及为什么在后者中不能使用`maxSurge`属性。

## 基于 TCP 的守护程序

基于 TCP 的守护程序是由 DaemonSet 控制器管理的常规 Pod，通过它可以通过 TCP 访问服务。不同之处在于，因为每个守护程序控制的 Pod 都保证部署在每个节点中，所以不需要服务发现机制，因为客户端 Pod 可以简单地建立到运行它们的本地节点的连接。我们稍后会看到所有这些是如何工作的。

首先，让我们使用 Netcat `nc`命令定义一个简单的节点级服务:一个监听端口`6666`并将所有日志请求附加到一个名为`/var/node_log`的文件的日志收集器:

```
nc -lk -p 6666 -e sh -c "cat >> /var/node_log"

```

下一步是将我们基于 shell 的日志收集器包装在一个 Pod 模板中，该模板又嵌入到一个 DaemonSet 清单中。与部署类似，标签和标签选择器必须匹配:

```
# logDaemon.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: logd
spec:
  selector:
    matchLabels:
      name: logd
  template:
    metadata:
      labels:
        name: logd
    spec:
     containers:
      - name: logd
        image: alpine
        args:
        - /bin/sh
        - -c
        - >-
          nc -lk -p 6666 -e
          sh -c "cat >> /var/node_log"
        ports:
        - containerPort: 6666
          hostPort: 6666

```

在应用了`logDaemon.yaml`清单之后，我们将在每个 Kubernetes 节点上部署一个廉价的自制日志收集服务:

```
$ kubectl apply -f logDaemon.yaml
daemonset.apps/logd created

```

由于 DaemonSet 应该为每个 worker 节点创建一个 Pod，因此 Kubernetes 集群中的 Pod 数量和 DaemonSet 控制的 Pod 数量应该匹配:

```
$ kubectl get nodes
NAME                  STATUS  AGE
gke-*-ab1848a0-ngbp   Ready   20m
gke-*-ab1848a0-pv2g   Ready   20m
gke-*-ab1848a0-s9z7   Ready   20m

$ kubectl get pods -l name=logd -o wide
NAME       STATUS   AGE  NODE
logd-95vnl Running  11m  gke-*-s9z7
logd-ck495 Running  11m  gke-*-pv2g
logd-zttf4 Running  11m  gke-*-ngbp

```

既然日志收集器 DaemonSet 控制的 pod 在每个节点上都可用，我们将创建一个示例客户机来测试它。以下 shell 脚本每隔 15 秒生成一个问候，并将其发送到在端口`6666`上运行的 TCP 服务:

```
while true
do echo $(date) - Greetings from $HOSTNAME |
   nc $HOST_IP 6666
   sleep 15
done

```

这个脚本中有三个不同的参数:端口号，`6666,`，这是硬编码的；由 Pod 控制器自动填充的`$HOSTNAME`变量——可从容器内访问——和用户定义的`$HOST_IP`变量。Pod 不会明确知道运行 Pod 的节点的主机名或 IP 地址。这就产生了一个需要使用*向下 API* 来解决的新问题。

Downward API 允许查询 Pod 对象中的字段，并使它们作为环境变量可用于同一 Pod 的容器。在这个特例中，我们感兴趣的是`pod.status.hostIP`属性。为了将该属性的值“注入”到`HOST_IP`环境变量中，我们首先使用`name`属性声明变量的名称，然后使用`valueFrom.fieldRef.fieldPath`属性从 Pod 的对象中引用所需的属性——所有这些都在`pod.spec.containers.env`区间下:

```
...
env:
  - name: HOST_IP
    valueFrom:
      fieldRef:
        fieldPath: status.hostIP
...

```

定义了示例客户机和注入节点 IP 所需的额外配置后，我们现在将示例客户机的 shell 脚本和向下 API 查询结合起来，在名为`logDaemonClient.yaml`的单个部署清单中填充`HOST_IP`:

```
# logDaemonClient.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: client
spec:
  replicas: 7
  selector:
    matchLabels:
      name: client
  template:
    metadata:
      labels:
        name: client
    spec:
      containers:
      - name: client
        image: alpine
        env:
          - name: HOST_IP
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
        args:
        - /bin/sh
        - -c
        - >-
          while true;
          do echo $(date) -
          Greetings from $HOSTNAME |
          nc $HOST_IP 6666;
          sleep 15;
          done

```

应用`logDaemonClient.yaml`将导致创建多个副本(总共七个),这些副本将位于不同的分类节点上，这可以通过使用`-o wide`标志运行`kubectl get pods`命令来观察到:

```
$ kubectl apply -f logDaemonClient.yaml
deployment.apps/client created

$ kubectl get pods -l name=client -o wide
NAME            IP          NODE
client-*-5hn9p  10.28.2.15  gke-*-ngbp
client-*-74ssw  10.28.0.14  gke-*-pv2g
client-*-h5fmm  10.28.2.16  gke-*-ngbp
client-*-rjgz8  10.28.1.14  gke-*-s9z7
client-*-tgk7r  10.28.0.13  gke-*-pv2g
client-*-twk5p  10.28.2.14  gke-*-ngbp
client-*-wg6th  10.28.1.15  gke-*-s9z7

```

如果我们随机选择一个由 DaemonSet 控制的 Pod 并查询其日志，我们将看到它们与由部署控制的客户端 Pod 来自同一个节点:

```
$ kubectl exec logd-8cgrb -- cat /var/node_log
08:58:56 - Greetings from client-*-tgk7r
08:58:57 - Greetings from client-*-74ssw
08:59:11 - Greetings from client-*-tgk7r
08:59:12 - Greetings from client-*-74ssw
08:59:26 - Greetings from client-*-tgk7r
08:59:27 - Greetings from client-*-74ssw
...

```

作为参考，这些是 DaemonSet 控制的吊舱已经着陆的节点:

```
$ kubectl get pods -l name=logd -o wide
NAME       IP         NODE
logd-8cgrb 10.28.0.12 gke-*-pv2g
logd-m5z4m 10.28.1.13 gke-*-s9z7
logd-zd9z9 10.28.2.13 gke-*-ngbp

```

注意，pod`logd-8cgrb`、`client-*-tgk7r`和`client-*-74ssw`都部署在同一个名为`gke-*-pv2g`的节点上:

```
$ kubectl get pod/logd-8cgrb -o jsonpath \
    --template="{.spec.nodeName}"
gke-*-pv2g

$ kubectl get pod/client-5cbbb8f78-tgk7r \
    -o jsonpath --template="{.spec.nodeName}"
gke-*-pv2g

$ kubectl get pod/client-5cbbb8f78-74ssw \
    -o jsonpath --template="{.spec.nodeName}"
gke-*-pv2g

```

概括地说，要设置一个通用的基于 TCP 的 DaemonSet 解决方案，我们需要定义一个 DaemonSet 清单来部署守护进程本身，然后，为了使用 Pod，我们需要使用 Downward API 来注入 Pod 运行的节点的地址。向下 API 的使用包括查询特定 Pod 的对象属性，并通过环境变量使它们对 Pod 可用。

## 基于文件系统的守护程序

在上一节中，我们考虑了基于 TCP 的 DaemonSet 的情况，其特征在于客户端使用节点的 IP 地址(通过向下 API 注入)直接访问它，而不是使用服务对象。当部署在同一个节点上时，使用 DaemonSet 控制器部署的 pod 还有另一种相互通信的方式:文件系统。

让我们考虑一个守护进程的情况，它使用下面的 shell 脚本每 60 秒从在`/var/log`中找到的所有日志中创建一个 *tarball* :

```
while true
do tar czf \
   /var/log/all-logs-`date +%F`.tar.gz /var/log/*.log
   sleep 60
done

```

基于文件系统的 DaemonSet 的清单要求我们指定一个卷(对 Pod 中可用的驱动程序和目录的描述)和一个卷挂载(将卷绑定到适用容器内的文件路径)。

对于卷，我们指定了一个名为`logdir`的卷，它在`pod.spec.volumes`属性下指向节点的`/var/log`:

```
# at pod.spec
volumes:
- name: logdir
  hostPath:
    path: /var/log

```

然后，我们参考`pod.spec.containers.volumeMounts`隔间下的`logdir`卷，并确定它将被安装在我们的容器内的`/var/log`路径下:

```
# at pod.spec.containers

volumeMounts:
- name: logdir
  mountPath: /var/log

```

最后，我们将给出的两个定义组合成一个名为`logCompressor.yaml`的 DaemonSet 清单:

```
# logCompressor.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: logcd
spec:
  selector:
    matchLabels:
      name: logcd
  template:
    metadata:
      labels:
        name: logcd
    spec:
      volumes:
      - name: logdir
        hostPath:
          path: /var/log
      containers:
      - name: logcd
        image: alpine
        volumeMounts:
        - name: logdir
          mountPath: /var/log
        args:
        - /bin/sh
        - -c
        - >-
          while true;
          do tar czf
          /var/log/all-logs-`date +%F`.tar.gz
          /var/log/*.log;
          sleep 60;
          done

```

在应用了`logCompressor.yaml`之后，我们可以查询一个随机的 Pod 来判断一个 tarball 文件是否已经在它所分配的节点中被创建:

```
# clean up the environment first
$ kubectl apply -f logCompressor.yaml
daemonset.apps/logcd created

$ kubectl get pods
NAME          READY     STATUS    RESTARTS   AGE
logcd-gdxc7   1/1       Running   0          0s
logcd-krf2r   1/1       Running   0          0s
logcd-rd9mb   1/1       Running   0          0s

$ kubectl exec logcd-gdxc7 \
    -- find /var/log -name "*.gz"
/var/log/all-logs-2019-04-26.tar.gz

```

既然我们基于文件系统的 DaemonSet 已经启动并运行，让我们继续修改客户端，以便它将输出发送到`/var/log/$HOSTNAME.log`而不是 TCP 端口 6666:

```
# logCompressorClient.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: client2
spec:
  replicas: 7
  selector:
    matchLabels:
      app: client2
  template:
    metadata:
      labels:
        app: client2
    spec:
      volumes:
      - name: logdir
        hostPath:
          path: /var/log
      containers:
      - name: client2
        image: alpine
        volumeMounts:
         - name: logdir
           mountPath: /var/log
        args:
        - /bin/sh
        - -c
        - >
          while true;
          do echo $(date) -
          Greetings from $HOSTNAME >> \
          /var/log/$HOSTNAME.log;
          sleep 15;
          done

```

如果我们仔细观察，我们会发现`logCompressorClient.yaml`包含与`logCompressor.yaml`相同的`volumes`和`volumeMounts`区间。这是因为 DaemonSet 及其客户端都需要它们共享的文件系统的详细信息。

一旦应用了`logCompressorClient.yaml`,我们可以等待几分钟，并证明每个主机中生成的 tarball(由 DaemonSet 创建)是否包含部署生成的日志文件:

```
$ kubectl apply -f logCompressorClient.yaml
deployment.apps/client2 created

# after a few minutes...

$ kubectl exec logcd-gdxc7 -- \
    tar -tf /var/log/all-logs-2019-04-26.tar.gz

var/log/cloud-init.log
var/log/kube-proxy.log
var/log/client2-5549f6854-c9mz2.log
var/log/client2-5549f6854-dvs4f.log
var/log/client2-5549f6854-lhgxx.log
var/log/client2-5549f6854-m29gb.log
var/log/client2-5549f6854-nl6nx.log
var/log/client2-5549f6854-trcgz.log

```

遵循`$HOSTNAME.log`命名约定的文件，如`client2-5549f6854-c9mz2.log`，确实是由`logCompressorClient.yaml`生成的。

### 注意

真实世界的日志解决方案很少依赖于节点的文件系统，而是依赖于云支持的外部驱动器(如 Google Cloud Platform Persistent Disk)。相反，CronJob(参见第 [7 章](7.html))与 shell `sleep`语句相反，通常比 DaemonSet 更合适，因为它提供了全局调度功能。

## 仅在特定节点上运行的守护程序

在一些高级场景中，并非 Kubernetes 集群中的所有节点都是由商用硬件支持的同构、可任意使用的虚拟机。一些服务器可能具有图形处理单元(GPU)和快速固态硬盘(SSD)等特殊功能，甚至使用不同的操作系统。或者，我们可能想要在环境之间建立一个硬的而不是逻辑的隔离；换句话说，我们可能希望在节点级别而不是对象级别隔离环境——就像我们在使用名称空间时通常做的那样。这是我们将在本节中考虑的用例。

分离 DaemonSets，使它们落在特定的节点上，这要求我们对每个节点应用一个标签，以便能够区分。让我们首先列出我们目前拥有的节点:

```
$ kubectl get nodes
NAME         STATUS   AGE
gke-*-809q   Ready    1h
gke-*-dvzf   Ready    1h
gke-*-v0v7   Ready    1h

```

现在，我们可以将标签应用于每个列出的节点。标记方法依赖于我们在第 [2](2.html) 章中探讨过的`kubectl label <RESOURCE-TYPE>/<OBJECT-IDENTIFIER>`命令。我们将第一个节点`gke-*-809q`指定为`prod`(生产)，将`gke-*-dvzf`、`gke-*-v0v7`指定为`dev`(开发):

```
$ kubectl label node/gke-*-809q env=prod
node "gke-*-809q" labeled

$ kubectl label node/gke-*-dvzf env=dev
node "gke-*-dvzf" labeled

$ kubectl label node/gke-*-v0v7 env=dev
node "gke-*-v0v7" labeled

```

然后，我们可以使用`kubectl get nodes`命令和`-L env`标志检查每个节点标签的值，该标志显示一个名为`ENV`的额外列:

```
$ kubectl get nodes -L env
NAME         STATUS  AGE ENV
gke-*-809q   Ready   1h  prod
gke-*-dvzf   Ready   1h  dev
gke-*-v0v7   Ready   1h  dev

```

现在，我们要做的就是获取上一节中显示的`logCompressor.yaml`清单，并将`pod.spec.nodeSelector`属性添加到 Pod 模板中:

```
# at spec.template.spec
spec:
  nodeselector:
    env: prod

```

如果我们将新清单另存为`logCompressorProd.yaml`并应用它，结果将是 DaemonSet 的 Pod 将只部署到标签为`prod`的节点:

```
# clean up the environment first
$ kubectl apply -f logCompressorProd.yaml
daemonset.apps/logcd configured

$ kubectl get pods -o wide
NAME        READY  STATUS    NODE
logcd-4rps8 1/1    Running   gke-*-809q

```

### 注意

请注意，选择标记为`prod`(生产)和`dev`(开发)的节点仅仅是为了说明。分离 SDLC 阶段的实际环境通常是使用名称空间来实现的，有时甚至是完全不同的 Kubernetes 集群实例。

## 更新策略

当目标是产生零停机更新时，更新现有的 DaemonSet 与更新部署的工作方式并不完全相同。在典型的零停机部署更新中，会增加一个或多个额外的 Pod(使用`deployment.spec.strategy.rollingUpdate.maxSurge`属性进行控制),目的是在终止旧的 Pod 之前，始终至少有一个额外的 Pod 可用。该过程由服务控制器辅助，服务控制器可以随着迁移的进行将 pod 移入和移出负载均衡器。在 DaemonSet 的情况下，`maxSurge`属性不可用；我们会看到原因。

虽然由常规部署控制器控制的吊舱的位置(确切的着陆节点)是相当不合理的，但 DaemonSet 控制器的合同目标是确保每个节点正好有一个吊舱可用。因此，最小和最大“副本”的数量就是集群中的节点总数，不包括使用特殊节点选择器的情况，如上一节所示。此外，DaemonSet 控制器部署的 pod 通常使用文件系统或节点级 TCP 端口进行本地访问，而不是通过服务控制器管理的代理和 DNS 条目进行访问。简而言之，DaemonSet 的 Pod 是节点级的单例，而不是可伸缩对象群中的匿名成员。DaemonSets 实现系统级工作负载，与其他更短暂的应用(例如 web 服务器)相比，它承担着更基础的角色和更高的优先级。

让我们想象一下，假设将 DaemonSet 的`maxSurge`属性设置为 1 会有什么后果。如果可能的话，在 DaemonSet 更新过程中，可能会有数量超过集群中节点总数的 pod 存在一段时间。例如，在三个节点的 Kubernetes 集群中，1 的`maxSurge`将允许在 DaemonSet 更新期间存在四个节点。逻辑结果是额外的吊舱将落在已经有一个现有吊舱在运行的节点上；这违反了 DaemonSet 旨在保证的原则:每个节点只存在一个 Pod。结论是更新 DaemonSet(例如，选择新的映像)将涉及一些自然的停机时间，至少在本地节点级别。

DaemonSet 清单允许两种类型的更新策略:`OnDelete`和`RollingUpdate`。第一个命令指示 DaemonSet 控制器等待，直到每个 Pod 被手动删除*之后，控制器才可以基于新清单中包含的模板用新 Pod 替换它。第二个操作类似于部署控制器的滚动更新声明，除了没有`maxSurge`属性，只有`maxUnavailable`。默认的更新策略实际上是`RollingUpdate`，其`maxUnavailablity`值为 1:*

```
# at daemonset.spec (default)
updateStrategy:
 type: RollingUpdate
 rollingUpdate:
   maxUnavailable: 1

```

这种默认配置导致每当产生更新时，一次更新一个节点。例如，如果我们再次运行本章前面介绍的`logCompressor.yaml`清单，并将其默认映像更改为`busybox`——我们默认使用`alpine`——我们将看到 DaemonSet 控制器将一次处理一个节点，终止其正在运行的 Pod，部署新的 Pod，然后再移动到下一个节点:

```
$ kubectl get pods -o wide
NAME        READY STATUS  IP         NODE
logcd-k6kb4 1/1   Running 10.28.0.10 gke-*-h7b4
logcd-mtpnp 1/1   Running 10.28.2.12 gke-*-10gx
logcd-pgztn 1/1   Running 10.28.1.10 gke-*-lnxh

$ kubectl set image ds/logcd logcd=busybox
daemonset.extensions/logcd image updated

$ kubectl get pods -o wide -w
NAME        READY STATUS      IP         NODE
logcd-k6kb4 1/1   Running     10.28.0.10 gke-*-h7b4
logcd-mtpnp 1/1   Running     10.28.2.12 gke-*-10gx
logcd-pgztn 1/1   Running     10.28.1.10 gke-*-lnxh
logcd-pgztn 1/1   Terminating 10.28.1.10 gke-*-lnxh
logcd-57tzz 0/1   Pending     <none>     gke-*-lnxh
logcd-57tzz 1/1   Running     10.28.1.11 gke-*-lnxh
logcd-k6kb4 1/1   Terminating 10.28.0.10 gke-*-h7b4
...

```

在来自`kubectl get pods`的输出中，我们可以看到，最初有三个节点，在发出`kubectl set image`命令后，节点`gke-*-lnxh`中的 Pod 被终止，并且在 DaemonSet 控制器选择不同的节点`gke-*-h7b4`以再次应用更新过程之前，创建一个新的 Pod。

## 管理摘要

使用`kubectl get daemonsets`命令列出活动 DaemonSet 控制器的数量。例如，在应用本章中用作示例的`logCompressor.yaml`清单后，结果将如下所示:

```
$ kubectl get daemonsets
NAME  DESIRED CURRENT READY UP-TO-DATE AVAILABLE
logcd 3       3       3     3          3

```

如果没有指定特定的节点选择器——在所示的输出中就是这种情况——`DESIRED`列下的数字应该与 Kubernetes 集群中的节点总数相匹配。还请注意，显示了一个名为`NODE SELECTOR`的列(由于空间限制，在显示的输出中省略了该列),该列指示 DaemonSet 是否绑定到特定节点。

对于特定 DaemonSet 的进一步询问，可使用`kubectl get daemonset/<NAME>`或`kubectl describe daemonset/<NAME>`命令。

删除操作与任何其他 Kubernetes 工作负载控制器一样。默认的删除命令`kubectl delete daemonset/<NAME>`将删除 DaemonSet 的所有相关窗格，除非应用了标志`--cascade=false`:

```
$ kubectl delete ds/logcd

daemonset.extensions "logcd" deleted

$ kubectl get pods
NAME         READY  STATUS
logcd-xgvm9  1/1    Terminating
logcd-z79xb  1/1    Terminating
logcd-5r5mn  1/1    Terminating

```

## 摘要

在本章中，我们了解到 DaemonSet 控制器用于在 Kubernetes 集群的每个节点中部署单个 Pod，以便可以使用 TCP 或文件系统对其进行本地访问，这两种方式通常都比其他类型的*场外*网络访问更快。本章举例说明的日志聚合器被用作教学范例；更多的工业用例包括健康监控代理和服务网格代理——或者所谓的*边车*。

虽然 DaemonSets 与部署类似，但我们看到了一个关键的区别，即它们不适合零停机更新场景，因为 pod 在被新版本替换之前就被终止了；此行为可能会暂时中断使用 TCP 回送设备或文件系统在节点级别访问 DaemonSet 的 pod 的本地 pod。因此，如果希望 daemon set pod 的客户端能够经受住 daemon set pod 的实时更新，则必须以容错方式设计这些客户端。