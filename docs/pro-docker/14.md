# 14.使用 Apache Spark

Apache Spark 是一个用于大型数据集的数据处理引擎。Apache Spark 比 Apache Hadoop MapReduce 快得多(内存快 100 倍)。在集群模式下，Spark 应用作为独立的进程运行，由主程序驱动程序中的`SparkContext`对象协调。`SparkContext`可以连接到几种类型的集群管理器，为 Spark 应用分配资源。支持的集群管理器包括独立的集群管理器、Mesos 和 YARN。Apache Spark 旨在访问来自各种数据源的数据，包括 HDFS、Apache HBase 和 NoSQL 数据库，如 Apache Cassandra 和 MongoDB。在这一章中，我们将使用我们用于几个 Apache Hadoop 框架(包括 Apache Hive 和 Apache HBase)的相同的 CDH Docker 映像。我们将使用 Docker 容器中的 YARN cluster manager 在集群模式下运行 Apache Spark Master。

*   设置环境
*   运行 CDH 的 Docker 容器
*   以纱线集群模式运行 Apache Spark 作业
*   在 yarn-client 模式下运行 Apache Spark 作业
*   运行 Apache Spark Shell

## 设置环境

本章需要以下软件。

*   -Docker 引擎(版本 1.8)
*   apache spark 的 docker image

使用 Amazon EC2 实例的公共 IP 地址连接到该实例。公共 IP 地址可以从 Amazon EC2 控制台找到，如附录 a 中所述。

`ssh -i "docker.pem"` `ec2-user@54.208.146.254`

启动 Docker 服务并验证状态是否为已启动。

`sudo service docker start`

`sudo service docker status`

下载 CDH 的 Docker 镜像，svds/cdh 镜像(如果之前章节没有下载的话)。

`sudo docker pull svds/cdh`

Docker 镜像 svds/cdh 被下载，如图 [14-1](#Fig1) 所示。

![A978-1-4842-1830-3_14_Fig1_HTML.jpg](A978-1-4842-1830-3_14_Fig1_HTML.jpg)

图 14-1。

Downloading svds/cdh Docker Image

## 运行 CDH 的 Docker 容器

使用 Apache Spark 主端口 as 8088 为 CDH 框架启动一个 Docker 容器。

`sudo docker run  -p 8088 -d --name cdh svds/cdh`

列出正在运行的 Docker 容器。

`sudo docker ps`

包括 Apache Spark 在内的 cdh 进程启动，容器 CDH 被列为正在运行，如图 [14-2](#Fig2) 所示。

![A978-1-4842-1830-3_14_Fig2_HTML.jpg](A978-1-4842-1830-3_14_Fig2_HTML.jpg)

图 14-2。

Starting Docker Container for CDH including Apache Spark

为 cdh 容器启动一个交互式终端。

`sudo docker exec -it cdh bash`

交互终端启动，如图 [14-3](#Fig3) 所示。

![A978-1-4842-1830-3_14_Fig3_HTML.jpg](A978-1-4842-1830-3_14_Fig3_HTML.jpg)

图 14-3。

Starting the TTY

在 YARN 模式中，Spark 应用可以提交给 yarn-cluster 模式或 yarn-client 模式中的集群。在 yarn-cluster 模式下，Apache Spark 驱动程序运行在一个由 yarn 管理的应用主机中。在纱线客户端模式下。Spark 驱动程序在 YARN 之外的客户端进程中运行，而应用主机仅用于向 YARN 请求资源。根据提交申请的方式，`--master`参数为`yarn-cluster`或`yarn-client`。在 yarn-client 模式下，Spark 驱动程序登录到控制台。

我们将使用每种应用提交模式运行 Spark 应用。我们将使用示例应用`org.apache.spark.examples.SparkPi`。

## 以纱线集群模式运行 Apache Spark 作业

要使用 1000 次迭代在纱线簇模式下提交 Spark 应用`SparkPi`，运行下面的`spark-submit`命令，将`--master`参数作为纱线簇。

`spark-submit --master yarn-cluster --class org.apache.spark.examples.SparkPi /usr/lib/spark/examples/lib/spark-examples-1.3.0-cdh5.4.7-hadoop2.6.0-cdh5.4.7.jar 1000`

前面的命令从交互终端运行，如图 [14-4](#Fig4) 所示。

![A978-1-4842-1830-3_14_Fig4_HTML.jpg](A978-1-4842-1830-3_14_Fig4_HTML.jpg)

图 14-4。

Submitting the Spark Application in yarn-cluster Mode

火花应用的输出如图 [14-5](#Fig5) 所示。

![A978-1-4842-1830-3_14_Fig5_HTML.jpg](A978-1-4842-1830-3_14_Fig5_HTML.jpg)

图 14-5。

Output from Spark Job in yarn-cluster Mode

下面列出了来自`spark-submit`命令的更详细的输出:

`spark-submit --master yarn-cluster --class org.apache.spark.examples.SparkPi /usr/lib/spark/examples/lib/spark-examples-1.3.0-cdh5.4.7-hadoop2.6.0-cdh5.4.7.jar 1000`

`15/10/23 19:12:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable`

`15/10/23 19:12:54 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032`

`15/10/23 19:12:56 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers`

`15/10/23 19:12:56 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)`

`15/10/23 19:12:56 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead`

`15/10/23 19:12:56 INFO yarn.Client: Setting up container launch context for our AM`

`15/10/23 19:12:56 INFO yarn.Client: Preparing resources for our AM container`

`15/10/23 19:12:59 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.`

`15/10/23 19:12:59 INFO yarn.Client: Uploading resource file:/usr/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.7-hadoop2.6.0-cdh5.4.7.jar -> hdfs://localhost:8020/user/root/.sparkStaging/application_1445627521793_0001/spark-assembly-1.3.0-cdh5.4.7-hadoop2.6.0-cdh5.4.7.jar`

`15/10/23 19:13:05 INFO yarn.Client: Uploading resource file:/usr/lib/spark/examples/lib/spark-examples-1.3.0-cdh5.4.7-hadoop2.6.0-cdh5.4.7.jar -> hdfs://localhost:8020/user/root/.sparkStaging/application_1445627521793_0001/spark-examples-1.3.0-cdh5.4.7-hadoop2.6.0-cdh5.4.7.jar`

`15/10/23 19:13:06 INFO yarn.Client: Setting up the launch environment for our AM container`

`15/10/23 19:13:07 INFO spark.SecurityManager: Changing view acls to: root`

`15/10/23 19:13:07 INFO spark.SecurityManager: Changing modify acls to: root`

`15/10/23 19:13:07 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)`

`15/10/23 19:13:07 INFO yarn.Client: Submitting application 1 to ResourceManager`

`15/10/23 19:13:08 INFO impl.YarnClientImpl: Submitted application application_1445627521793_0001`

`15/10/23 19:13:09 INFO yarn.Client: Application report for application_1445627521793_0001 (state: ACCEPTED)`

`15/10/23 19:13:09 INFO yarn.Client:`

`client token: N/A`

`diagnostics: N/A`

`ApplicationMaster host: N/A`

`ApplicationMaster RPC port: -1`

`queue: root.root`

`start time: 1445627587658`

`final status: UNDEFINED`

`tracking URL:` `http://4b4780802318:8088/proxy/application_1445627521793_0001/`

`user: root`

`15/10/23 19:13:10 INFO yarn.Client: Application report for application_1445627521793_0001 (state: ACCEPTED)`

`15/10/23 19:13:11 INFO yarn.Client: Application report for application_1445627521793_0001 (state: ACCEPTED)`

`15/10/23 19:13:24 INFO yarn.Client: Application report for application_1445627521793_0001 (state: RUNNING)`

`15/10/23 19:13:24 INFO yarn.Client:`

`client token: N/A`

`diagnostics: N/A`

`ApplicationMaster host: 4b4780802318`

`ApplicationMaster RPC port: 0`

`queue: root.root`

`start time: 1445627587658`

`final status: UNDEFINED`

`tracking URL:` `http://4b4780802318:8088/proxy/application_1445627521793_0001/`

`user: root`

`15/10/23 19:13:25 INFO yarn.Client: Application report for application_1445627521793_0001 (state: RUNNING)`

`15/10/23 19:13:26 INFO yarn.Client: Application report for`

`15/10/23 19:13:51 INFO yarn.Client: Application report for application_1445627521793_0001 (state: FINISHED)`

`15/10/23 19:13:51 INFO yarn.Client:`

`client token: N/A`

`diagnostics: N/A`

`ApplicationMaster host: 4b4780802318`

`ApplicationMaster RPC port: 0`

`queue: root.root`

`start time: 1445627587658`

`final status: SUCCEEDED`

`tracking URL:` `http://4b4780802318:8088/proxy/application_1445627521793_0001/A`

`user: root`

在纱线聚类模式下，Spark 应用结果不会输出到控制台，如果最终状态为`SUCCEEDED`，则必须使用浏览器中的跟踪 URL `http://4b4780802318:8088/proxy/application_1445627521793_0001/A`从`ResourceManager`访问纱线容器日志。

## 在 yarn-client 模式下运行 Apache Spark 作业

要在 yarn-client 模式下提交使用 1000 次迭代的 Spark 应用`SparkPi`，运行下面的`spark-submit`命令，将`--master`参数作为 yarn-client。

`spark-submit`

`--master yarn-client`

`--class org.apache.spark.examples.SparkPi`

`/usr/lib/spark/examples/lib/spark-examples-1.3.0-cdh5.4.7-hadoop2.6.0-cdh5.4.7.jar`

`1000`

火花提交命令的输出如图 [14-6](#Fig6) 所示。

![A978-1-4842-1830-3_14_Fig6_HTML.jpg](A978-1-4842-1830-3_14_Fig6_HTML.jpg)

图 14-6。

Submitting Spark Application in yarn-client Mode

来自 Apache Spark 应用的更详细的输出如下所示，其中包括近似计算的 Pi 值。

`spark-submit --master yarn-client --class org.apache.spark.examples.SparkPi /usr/lib/spark/examples/lib/spark-examples-1.3.0-cdh5.4.7-hadoop2.6.0-cdh5.4.7.jar 1000`

`15/10/23 19:15:19 INFO spark.SparkContext: Running Spark version 1.3.0`

`15/10/23 19:15:43 INFO cluster.YarnScheduler: Adding task set 0.0 with 1000 tasks`

`15/10/23 19:15:43 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 4b4780802318, PROCESS_LOCAL, 1353 bytes)`

`15/10/23 19:15:43 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 4b4780802318, PROCESS_LOCAL, 1353 bytes)`

`15/10/23 19:15:57 INFO scheduler.TaskSetManager: Finished task 999.0 in stage 0.0 (TID 999) in 22 ms on 4b4780802318 (999/1000)`

`15/10/23 19:15:57 INFO scheduler.TaskSetManager: Finished task 998.0 in stage 0.0 (TID 998) in 28 ms on 4b4780802318 (1000/1000)`

`15/10/23 19:15:57 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool`

`15/10/23 19:15:57 INFO scheduler.DAGScheduler: Stage 0 (reduce at SparkPi.scala:35) finished in 14.758 s`

`15/10/23 19:15:57 INFO scheduler.DAGScheduler: Job 0 finished: reduce at SparkPi.scala:35, took 15.221643 s`

`Pi is roughly 3.14152984`

## 运行 Apache Spark Shell

Apache Spark shell 在 yarn-client 模式下启动，如下所示。

`spark-shell --master yarn-client`

显示如图 [14-7](#Fig7) 所示的`scala>`命令提示符。Spark 上下文被创建并作为“sc”可用。SQL 上下文也可以作为“SQL context”使用。

![A978-1-4842-1830-3_14_Fig7_HTML.jpg](A978-1-4842-1830-3_14_Fig7_HTML.jpg)

图 14-7。

The scala> Command Prompt

`spark-shell`命令更详细的输出如下。

`root@4b4780802318:/# spark-shell --master yarn-client`

`15/10/23 19:17:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable`

`15/10/23 19:17:16 INFO spark.SecurityManager: Changing view acls to: root`

`15/10/23 19:17:16 INFO spark.SecurityManager: Changing modify acls to: root`

`15/10/23 19:17:16 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)`

`15/10/23 19:17:16 INFO spark.HttpServer: Starting HTTP Server`

`15/10/23 19:17:16 INFO server.Server: jetty-8.y.z-SNAPSHOT`

`15/10/23 19:17:16 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56899`

`15/10/23 19:17:16 INFO util.Utils: Successfully started service 'HTTP class server' on port 56899.`

`Welcome to`

`____              __`

`/ __/__  ___ _____/ /__`

`_\ \/ _ \/ _ `/ __/  '_/`

`/___/ .__/\_,_/_/ /_/\_\   version 1.3.0`

`/_/`

`Using Scala version 2.10.4 (OpenJDK 64-Bit Server VM, Java 1.7.0_79)`

`Type in expressions to have them evaluated.`

`Type :help for more information.`

`15/10/23 19:17:22 INFO spark.SparkContext: Running Spark version 1.3.0`

`15/10/23 19:17:45 INFO repl.SparkILoop: Created spark context..`

`Spark context available as sc.`

`15/10/23 19:17:45 INFO repl.SparkILoop: Created sql context (with Hive support)..`

`SQL context available as sqlContext.`

`15/10/23 19:17:45 INFO storage.BlockManagerMasterActor: Registering block manager 4b4780802318:48279 with 530.3 MB RAM, BlockManagerId(2, 4b4780802318, 48279)`

`scala>`

运行下面的 Scala 脚本，它由一个 Hello World 程序的 Spark shell 中的`HelloWorld`模块组成。

`object HelloWorld {`

`def main(args: Array[String]) {`

`println("Hello, world!")`

`}`

`}`

`HelloWorld.main(null)`

Scala 脚本的输出如图 [14-8](#Fig8) 所示。

![A978-1-4842-1830-3_14_Fig8_HTML.jpg](A978-1-4842-1830-3_14_Fig8_HTML.jpg)

图 14-8。

Output from Scala Script

## 摘要

在本章中，我们使用 spark-submit 命令在 Docker 容器中的 YARN 集群上运行了 Apache Spark 应用。我们以 yarn-cluster 和 yarn-client 模式提交了示例应用。我们还在 Spark shell 中运行了一个`HelloWorld` Scala 脚本。

这一章结束了关于Docker工人的书。除了在 Docker 上运行一些常用的软件，我们还讨论了主要的 Docker 管理任务，例如安装 Docker、下载 Docker 映像、创建和运行 Docker 容器、启动交互式 shell、在交互式 shell 中运行命令、列出 Docker 容器、列出 Docker 容器日志、停止 Docker 容器以及删除 Docker 容器和 Docker 映像。在本书的范围内，只有一些软件应用可以被讨论。在 [`https://hub.docker.com/`](https://hub.docker.com/) 的 Docker hub 上还有更多 Docker 图片。