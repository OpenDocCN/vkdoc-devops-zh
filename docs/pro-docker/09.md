# 九、使用 Apache Hive

Apache Hive 是用于存储、管理和查询大型数据集的数据仓库框架。HiveQL 是一种类似 SQL 的语言。默认情况下，Hive 将数据存储在 HDFS 中，并且可以使用 Hive 表来定义数据的结构。Hive 支持两种表:托管表和外部表。托管表由 Hive 框架管理，而外部表则不是。删除托管表时，元数据和表数据也会被删除。当删除配置单元外部表时，仅删除元数据，而不删除表数据，因为表数据不由配置单元框架管理。Hive 利用 metastore 来存储有关 Hive 表的元数据。配置单元 metastore 数据库用于 metastore，默认情况下是 Derby 数据库。metastore 数据库可以在嵌入式模式或远程模式下运行；默认为嵌入式模式。在本章中，我们将使用一个 Docker 映像来运行 Docker 容器中的 Apache Hive。

*   设置环境
*   正在启动 Apache Hive
*   连接到直线 CLI 外壳
*   连接到 HiveServer2
*   创建配置单元表
*   将数据加载到配置单元表中
*   查询配置单元表
*   停止 Apache 蜂房

## 设置环境

本章需要以下软件。

*   -Docker(使用 1.8 版)
*   apache hive 的 docker image

我们使用 Amazon EC2 实例来安装软件。按照第 [1](01.html) 章所述安装 Docker。SSH 连接到 Amazon EC2 实例。

`ssh -i "docker.pem"` `ec2-user@52.23.241.186`

启动 Docker 服务并验证 Docker 服务的状态。

`sudo service docker start`

`sudo service docker status`

下载`svds/cdh` Docker 镜像，它与 Apache HBase、Apache Sqoop 和 Apache Spark 上的一些其他 Apache Hadoop 生态系统章节中使用的镜像相同。

`sudo docker pull svds/cdh`

## 正在启动 Apache Hive

要启动 Apache Hive，请启动一个运行`cdh`进程或组件的 Docker 容器。运行下面的`docker run`命令，该命令以分离模式启动 Docker 容器，并将名称“cdh”分配给容器。

`sudo docker run  -d --name cdh svds/cdh`

列出正在运行的 Docker 容器；应该会列出“cdh”容器。

`sudo docker ps`

启动一个交互式终端来运行 Apache Hive shell 命令。

`sudo docker exec -it cdh bash`

## 连接到直线 CLI 外壳

Apache Hive 提供了 Hive CLI 来从命令行界面访问 HiveServer1。在 Hive 的较新版本中，HiveServer1 已被弃用，并被替换为 HiveServer2，Hive CLI 已被弃用，并被替换为 Beeline CLI。Hive CLI 是一个基于 Apache Thrift 的客户端，而 Beeline 是一个基于 SQLLine CLI 的 JDBC 客户端。对于 Beeline，仍然使用 Thrift API，但不是直接从客户端使用；JDBC 驱动程序使用 Thrift API 与 HiveServer2 通信。

在使用 Hive CLI 或 Beeline CLI 之前，我们需要修改 Hive 存储其数据的 HDFS 目录的权限，这个目录就是`/user/hive/warehouse`目录。在`/user/hive/warehouse`目录上设置全局权限(777)。

`hdfs dfs –chmod –R 777 /user/hive/warehouse`

前面的命令在交互终端中运行，如图 [9-1](#Fig1) 所示。

![A978-1-4842-1830-3_9_Fig1_HTML.jpg](A978-1-4842-1830-3_9_Fig1_HTML.jpg)

图 9-1。

Setting Permissions on the Hive Warehouse Directory

如果要使用 Hive CLI，请在交互式终端中运行以下命令。

`hive`

配置单元 CLI 已启动。如图 [9-2](#Fig2) 所示，还会输出一条警告消息，指出 Hive CLI 已被否决，建议迁移到 Beeline。

![A978-1-4842-1830-3_9_Fig2_HTML.jpg](A978-1-4842-1830-3_9_Fig2_HTML.jpg)

图 9-2。

Message about Migration to Beeline

我们将在本章中使用直线 CLI。使用`exit`或`quit`命令退出 Hive CLI。使用以下命令启动直线 CLI。

`beeline`

直线版本 1.1.0 CDH 5.4.3 开始如图 [9-3](#Fig3) 所示。

![A978-1-4842-1830-3_9_Fig3_HTML.jpg](A978-1-4842-1830-3_9_Fig3_HTML.jpg)

图 9-3。

Starting Beeline

## 连接到 HiveServer2

我们在上一节中启动了 Beeline CLI，但是我们还没有连接到 HiveServer2。要进行演示，请运行以下命令。

`use default;`

`show tables;`

输出“无电流连接”信息，如图 [9-4](#Fig4) 所示。

![A978-1-4842-1830-3_9_Fig4_HTML.jpg](A978-1-4842-1830-3_9_Fig4_HTML.jpg)

图 9-4。

Message “No Current Connection”

要连接到 HiveServer2，我们需要运行`!connect`命令。`!connect`命令用途可通过以下命令输出。

`!connect`

`!connect`命令用法得到如图 [9-5](#Fig5) 所示的输出。

![A978-1-4842-1830-3_9_Fig5_HTML.jpg](A978-1-4842-1830-3_9_Fig5_HTML.jpg)

图 9-5。

Command Usage for !connect

HiveServer2 可以以两种模式之一连接:嵌入式或远程。如果 Beeline CLI 在安装了 Hive 的同一台计算机上运行，则可以使用嵌入式模式。如果 Beeline CLI 在配置单元的远程机器上，则必须使用远程模式。我们将使用嵌入式模式。连接 url 的语法如下，其中`dbName`是 Hive 数据库，`<host>`和`<port>`是 HiveServer2 的主机名和端口号。

`jdbc:hive2://<host>:<port>/dbName`

运行下面的直线命令`!connect`，其中首先指定到 HiveServer2 的连接 url，然后是用户名、密码和 Hive JDBC 驱动程序。对于默认用户名、密码和配置单元 JDBC 驱动程序，请指定空字符串“”。默认的 Hive JDBS 驱动程序是`org.apache.hive.jdbc.HiveDriver`。

`!connect jdbc:hive2://localhost:10000/default "" "" ""`

如图 [9-6](#Fig6) 所示，建立了到 Apache Hive 1.1.0 的连接。Apache Hive 1.1.0 版本是重新命名的 Hive 0.15.0 版本。

![A978-1-4842-1830-3_9_Fig6_HTML.jpg](A978-1-4842-1830-3_9_Fig6_HTML.jpg)

图 9-6。

Connecting with Hive2 Server

以前不运行的直线命令在连接到 HiveServer2 后会运行。再次运行以下命令，将数据库设置为“默认”并列出配置单元表。

`use default`

`show tables`

数据库被设置为默认值，并列出配置单元表。该数据库已经是连接 url 中指定的“默认”数据库，并且运行`use default`命令来演示该命令的运行。没有列出任何表格，因为还没有创建任何表格，如图 [9-7](#Fig7) 所示。我们将在下一部分创建一个表。

![A978-1-4842-1830-3_9_Fig7_HTML.jpg](A978-1-4842-1830-3_9_Fig7_HTML.jpg)

图 9-7。

Listing Tables

## 创建配置单元表

在本节中，我们将创建一个名为“wlslog”的配置单元表，其中包含列`time_stamp`、`category`、`type`、`servername`、`code`和`msg,`，所有列的类型都是`string`。Hive 使用序列化器/反序列化器，也称为 Serde。可以使用自定义 Serde，也可以使用本地 Serde。如果没有指定`ROW FORMAT`，则使用本地 Serde。如果为带分隔符的数据文件指定了`ROW FORMAT DELIMITED`，也将使用本地 Serde。要用'，'分隔字段，请指定`FIELDS TERMINATED BY`'，'并用换行符结束一行数据，请指定`LINES TERMINATED BY '\n'`。

运行下面的`CREATE TABLE`命令来创建一个配置单元管理的表；配置单元外部表的命令是`CREATE EXTERNAL TABLE`。

`CREATE TABLE wlslog(time_stamp STRING,category STRING,type STRING,servername STRING,code STRING,msg STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n';`

名为`wlslog`的配置单元表被创建，如图 [9-8](#Fig8) 所示。我们还没有使用`wlslog`表中的`PRIMARY KEY`字段。

![A978-1-4842-1830-3_9_Fig8_HTML.jpg](A978-1-4842-1830-3_9_Fig8_HTML.jpg)

图 9-8。

Creating Hive Table

运行以下命令来描述`wlslog`表。

`desc wlslog;`

由列名和数据类型组成的表结构如图 [9-9](#Fig9) 所示。

![A978-1-4842-1830-3_9_Fig9_HTML.jpg](A978-1-4842-1830-3_9_Fig9_HTML.jpg)

图 9-9。

Describing Table Structure

## 将数据加载到配置单元表中

接下来，我们将数据加载到 Hive 表中。运行下面的`INSERT` HiveQL 语句将一行数据添加到`wlslog`表中。

`INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:16-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000365','Server state changed to STANDBY');`

MapReduce 作业开始将数据加载到 Hive 表中，如图 [9-10](#Fig10) 所示。

![A978-1-4842-1830-3_9_Fig10_HTML.jpg](A978-1-4842-1830-3_9_Fig10_HTML.jpg)

图 9-10。

Running the INSERT Command

MapReduce 作业由 1 个映射器和 0 个缩减器组成。数据被加载到`default.wlslog`表中，如图 [9-11](#Fig11) 所示。

![A978-1-4842-1830-3_9_Fig11_HTML.jpg](A978-1-4842-1830-3_9_Fig11_HTML.jpg)

图 9-11。

Loading Data into Hive Table

如果没有指定`PRIMARY KEY`，配置单元表中的数据不会被约束为具有唯一的列值，我们没有指定。可以添加具有相同数据的行，而不在表定义中添加`PRIMARY KEY`。运行下面的`INSERT`语句，再添加 7 行数据，包括一行具有重复列数据的数据。

`INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:16-PM-PDT','Notice','WebLogicServer','AdminServer,BEA-000365','Server state changed to STANDBY');`

`INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:17-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000365','Server state changed to STARTING');`

`INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:18-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000365','Server state changed to ADMIN');`

`INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:19-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000365','Server state changed to RESUMING');`

`INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:20-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000331','Started WebLogic AdminServer');`

`INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:21-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000365','Server state changed to RUNNING');`

`INSERT INTO TABLE wlslog VALUES ('Apr-8-2014-7:06:22-PM-PDT','Notice','WebLogicServer','AdminServer','BEA-000360','Server started in RUNNING mode');`

## 查询配置单元表

创建了一个 Hive 表并将数据加载到该表中后，我们将使用一个`SELECT` HiveQL 语句查询该表。在直线 CLI 中运行以下查询。

`select * from wlslog;`

8 行数据被列出，如图 [9-12](#Fig12) 所示。

![A978-1-4842-1830-3_9_Fig12_HTML.jpg](A978-1-4842-1830-3_9_Fig12_HTML.jpg)

图 9-12。

Running a SELECT HiveQL Statement

## 停止 Apache 蜂房

要停止 Apache Hive 进程，运行`docker stop`命令来停止运行 cdh 框架的 Docker 容器。

`sudo docker stop cdh`

## 摘要

在本章中，我们使用了一个 Docker 映像来运行 CDH 框架，包括 Docker 容器中的 Apache Hive 框架。我们启动了一个直线 CLI，它取代了 Hive CLI，并从直线 CLI 连接到 HiveServer2。我们创建了一个配置单元管理表，并将数据加载到配置单元表中。随后，我们从 Beeline CLI 查询了 Hive 表。在下一章中，我们将使用 Docker 容器中的 Apache HBase 数据库。