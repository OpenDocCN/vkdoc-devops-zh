# 八、使用 Apache Hadoop

Apache Hadoop 是处理大型数据集的事实上的框架。Apache Hadoop 是一个分布式软件应用，运行在一个集群中的几个(多达成百上千个)节点上。Apache Hadoop 由两个主要组件组成:Hadoop 分布式文件系统(HDFS)和 MapReduce。HDFS 用于存储大型数据集，MapReduce 用于处理大型数据集。Hadoop 可以线性扩展而不会降低性能，并且利用商用硬件而不是任何专用硬件。Hadoop 旨在容错，并通过将计算转移到数据而不是将数据转移到计算来利用数据局部性。MapReduce 框架有两个版本 MapReduce1 (MR1)和 MapReduce2 (MR2)(也叫 YARN)。MR1 是 Hadoop 早期版本(Hadoop 1.x)的默认 MapReduce 框架，YARN 是 Hadoop 后期版本(Hadoop 2.x)的默认 MapReduce 框架。

*   设置环境
*   启动 Hadoop
*   启动交互式 Shell
*   为 MapReduce 字数统计应用创建输入文件
*   运行 MapReduce 字数统计应用
*   停止 Hadoop Docker 容器
*   使用 CDH 坞站映像

## 设置环境

本章使用了以下软件。

*   -Docker(版本 1.8)
*   Apache Hadoop 坞站映像
*   -Cloudera Hadoop (CDH)坞站映像

在其他章节中，我们使用了一个基于 Red Hat Enterprise Linux 7.1 (HVM)、SSD 卷类型 ami-12663b7a 的 Amazon EC2 实例来安装软件。到 Amazon EC2 实例的 SSH 登录。

`ssh -i "docker.pem"` `ec2-user@52.23.207.240`

按照第 [1](01.html) 章所述安装 Docker。启动 Docker 服务。

`sudo service docker start`

OK 消息表明 Docker 服务已经启动，如图 [8-1](#Fig1) 所示。

![A978-1-4842-1830-3_8_Fig1_HTML.jpg](A978-1-4842-1830-3_8_Fig1_HTML.jpg)

图 8-1。

Starting the Docker Service

添加一个名为“hadoop”的组和一个名为“hadoop”的用户。

`groupadd hadoop`

`useradd -g hadoop hadoop`

Apache Hadoop 有几个 Docker 映像。我们使用了 Docker Hub 上的`sequenceiq/hadoop-docker` Docker 映像。下载标签为 2.7.0 的 Docker 映像或最新的标签映像(如果不同)。

sudo dock pull sequence IQ/Hadoop dock:2 . 7 . 0

`docker pull`命令如图 [8-2](#Fig2) 所示。

![A978-1-4842-1830-3_8_Fig2_HTML.jpg](A978-1-4842-1830-3_8_Fig2_HTML.jpg)

图 8-2。

Running the docker pull Command

Docker 映像`sequenceiq/hadoop-docker`被下载，如图 [8-3](#Fig3) 所示。

![A978-1-4842-1830-3_8_Fig3_HTML.jpg](A978-1-4842-1830-3_8_Fig3_HTML.jpg)

图 8-3。

Downloading Docker Image sequenceiq/hadoop-docker

## 启动 Hadoop

接下来，启动 Hadoop 组件 HDFS 和 MapReduce。Docker 映像`sequenceiq/hadoop-docker`默认配置为启动 YARN 或 MR2 框架。运行下面的`docker` `run`命令，以分离模式启动 Docker 容器，启动 HDFS (NameNode 和 DataNode)和 YARN (ResourceManager 和 NodeManager)。

`sudo docker  run -d --name hadoop sequenceiq/hadoop-docker:2.7.0`

随后，列出正在运行的 Docker 容器。

`sudo docker ps`

前面两个命令的输出如图 [8-4](#Fig4) 所示，包括基于`sequenceiq/hadoop-docker`映像的 Apache Hadoop 的运行 Docker 容器。Docker 容器名为“hadoop”，容器 id 为“27436aa7c645”。

![A978-1-4842-1830-3_8_Fig4_HTML.jpg](A978-1-4842-1830-3_8_Fig4_HTML.jpg)

图 8-4。

Running Docker Container for Apache Hadoop

## 启动交互式 Shell

使用以下命令启动交互式 shell 或终端(tty)。

`sudo docker exec -it hadoop bash`

显示如图 [8-5](#Fig5) 所示的交互终端提示。

![A978-1-4842-1830-3_8_Fig5_HTML.jpg](A978-1-4842-1830-3_8_Fig5_HTML.jpg)

图 8-5。

Starting Interactive Terminal

也可以使用容器 id 而不是容器名称来启动交互式外壳。

`sudo docker exec -it  27436aa7c645 bash`

如果`docker run`命令中省略了`–d`命令参数，并且使用以下命令提供了`–it`参数(与`–i`和`–t`一起提供), Docker 容器将以前台模式启动。

`sudo docker run -it --name hadoop sequenceiq/hadoop-docker:2.7.0 /etc/bootstrap.sh –bash`

Hadoop 组件启动并将控制台连接到 Hadoop 标准输入、标准输出和标准错误流，如图 [8-6](#Fig6) 所示。对于每个启动的 Hadoop 组件，控制台都会输出一条消息。`–it`参数启动交互终端(tty)。

![A978-1-4842-1830-3_8_Fig6_HTML.jpg](A978-1-4842-1830-3_8_Fig6_HTML.jpg)

图 8-6。

Starting Docker Container in Foreground

## 为 MapReduce 字数统计应用创建输入文件

在本节中，我们将为 MapReduce Word Count 应用创建输入文件，该应用包含在 Hadoop 发行版打包的示例中。要创建输入文件，请将目录(cd)更改为`$HADOOP_PREFIX`目录。

`bash-4.1# cd $HADOOP_PREFIX`

如图 [8-7](#Fig7) 所示，前面的命令将从交互终端(tty)运行。

![A978-1-4842-1830-3_8_Fig7_HTML.jpg](A978-1-4842-1830-3_8_Fig7_HTML.jpg)

图 8-7。

Setting Current Directory to $HADOOP_PREFIX Directory

在 HDFS 中为输入文件创建一个名为`/input`的目录。随后，将目录权限设置为全局(777)。

`bash-4.1# bin/hdfs dfs -mkdir  /input`

`bash-4.1# bin/hdfs dfs -chmod -R 777 /input`

前面的命令也从交互终端运行，如图 [8-8](#Fig8) 所示。

![A978-1-4842-1830-3_8_Fig8_HTML.jpg](A978-1-4842-1830-3_8_Fig8_HTML.jpg)

图 8-8。

Creating Input Directory

向`/input`目录添加两个文本文件(`input1.txt`和`input2.txt`)和一些示例文本。要创建一个文本文件`input1.txt`，在 tty 中运行下面的 vi 编辑器命令。

`vi input1.txt`

在`input1.txt`中添加以下两行文本。

`Hello World Application for Apache Hadoop`

`Hello World and Hello Apache Hadoop`

使用`:` `wq`命令保存`input1.txt`文件，如图 [8-9](#Fig9) 所示。

![A978-1-4842-1830-3_8_Fig9_HTML.jpg](A978-1-4842-1830-3_8_Fig9_HTML.jpg)

图 8-9。

The input1.txt File

用下面的命令将 input1.txt 文件放到 HDFS 目录`/input`中，也如图 [8-10](#Fig10) 所示。

`bin/hdfs dfs -put input1.txt /input`

`input1.txt`文件被添加到 HDFS 的`/input`目录中。

![A978-1-4842-1830-3_8_Fig10_HTML.jpg](A978-1-4842-1830-3_8_Fig10_HTML.jpg)

图 8-10。

Putting the input1.txt in the HDFS

类似地，用下面的 vi 命令打开另一个新的文本文件`input2.txt`。

`vi input2.txt`

在`input2.txt`文件中添加以下两行文本。

`Hello World`

`Hello Apache Hadoop`

使用`:wq`命令保存`input2.txt`文件，如图 [8-11](#Fig11) 所示。

![A978-1-4842-1830-3_8_Fig11_HTML.jpg](A978-1-4842-1830-3_8_Fig11_HTML.jpg)

图 8-11。

The input2.txt File

将`input2.txt`文件放到 HDFS 目录`/input`中。

`bin/hdfs dfs -put input2.txt /input`

随后，运行以下命令来运行`/input`目录中的文件。

`bin/hdfs –ls /input`

添加到 HDFS 的两个文件被列出，如图 [8-12](#Fig12) 所示。

![A978-1-4842-1830-3_8_Fig12_HTML.jpg](A978-1-4842-1830-3_8_Fig12_HTML.jpg)

图 8-12。

Listing the Input Files in the HDFS

## 运行 MapReduce 字数统计应用

在本节中，我们将运行一个 MapReduce 应用进行字数统计；应用打包在`hadoop-mapreduce-examples-2.7.0.jar`文件中，可以用参数“wordcount”调用。`wordcount`应用要求提供输入和输出目录。输入目录是我们之前创建的 HDFS 中的`/input`目录，输出目录是`/output`，它在运行 hadoop 命令之前必须不存在。从交互式 shell 中运行下面的`hadoop`命令。

`bin/hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.0.jar wordcount  /input /output`

MapReduce 作业使用 YARN 框架开始，如图 [8-13](#Fig13) 所示。

![A978-1-4842-1830-3_8_Fig13_HTML.jpg](A978-1-4842-1830-3_8_Fig13_HTML.jpg)

图 8-13。

Starting MapReduce Application with YARN Framework

纱线作业完成，如图 [8-14](#Fig14) 所示，字数统计应用输出到 HDFS 的`/output`目录。

![A978-1-4842-1830-3_8_Fig14_HTML.jpg](A978-1-4842-1830-3_8_Fig14_HTML.jpg)

图 8-14。

Output from the MapReduce Application

`hadoop`命令的完整输出如下。

`<mapreduce/hadoop-mapreduce-examples-2.7.0.jar wordcount  /input /output`

`15/10/18 15:46:17 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032`

`15/10/18 15:46:19 INFO input.FileInputFormat: Total input paths to process : 2`

`15/10/18 15:46:19 INFO mapreduce.JobSubmitter: number of splits:2`

`15/10/18 15:46:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1445197241840_0001`

`15/10/18 15:46:21 INFO impl.YarnClientImpl: Submitted application application_1445197241840_0001`

`15/10/18 15:46:21 INFO mapreduce.Job: The url to track the job:` `http://fb25c4cabc55:8088/proxy/application_1445197241840_0001/`

`15/10/18 15:46:21 INFO mapreduce.Job: Running job: job_1445197241840_0001`

`15/10/18 15:46:40 INFO mapreduce.Job: Job job_1445197241840_0001 running in uber mode : false`

`15/10/18 15:46:40 INFO mapreduce.Job:  map 0% reduce 0%`

`15/10/18 15:47:03 INFO mapreduce.Job:  map 100% reduce 0%`

`15/10/18 15:47:17 INFO mapreduce.Job:  map 100% reduce 100%`

`15/10/18 15:47:18 INFO mapreduce.Job: Job job_1445197241840_0001 completed successfully`

`15/10/18 15:47:18 INFO mapreduce.Job: Counters: 49`

`File System Counters`

`FILE: Number of bytes read=144`

`FILE: Number of bytes written=345668`

`FILE: Number of read operations=0`

`FILE: Number of large read operations=0`

`FILE: Number of write operations=0`

`HDFS: Number of bytes read=324`

`HDFS: Number of bytes written=60`

`HDFS: Number of read operations=9`

`HDFS: Number of large read operations=0`

`HDFS: Number of write operations=2`

`Job Counters`

`Launched map tasks=2`

`Launched reduce tasks=1`

`Data-local map tasks=2`

`Total time spent by all maps in occupied slots (ms)=41338`

`Total time spent by all reduces in occupied slots (ms)=11578`

`Total time spent by all map tasks (ms)=41338`

`Total time spent by all reduce tasks (ms)=11578`

`Total vcore-seconds taken by all map tasks=41338`

`Total vcore-seconds taken by all reduce tasks=11578`

`Total megabyte-seconds taken by all map tasks=42330112`

`Total megabyte-seconds taken by all reduce tasks=11855872`

`Map-Reduce Framework`

`Map input records=6`

`Map output records=17`

`Map output bytes=178`

`Map output materialized bytes=150`

`Input split bytes=212`

`Combine input records=17`

`Combine output records=11`

`Reduce input groups=7`

`Reduce shuffle bytes=150`

`Reduce input records=11`

`Reduce output records=7`

`Spilled Records=22`

`Shuffled Maps =2`

`Failed Shuffles=0`

`Merged Map outputs=2`

`GC time elapsed (ms)=834`

`CPU time spent (ms)=2760`

`Physical memory (bytes) snapshot=540696576`

`Virtual memory (bytes) snapshot=2084392960`

`Total committed heap usage (bytes)=372310016`

`Shuffle Errors`

`BAD_ID=0`

`CONNECTION=0`

`IO_ERROR=0`

`WRONG_LENGTH=0`

`WRONG_MAP=0`

`WRONG_REDUCE=0`

`File Input Format Counters`

`Bytes Read=112`

`File Output Format Counters`

`Bytes Written=60`

`bash-4.1#`

用下面的命令列出 HDFS 目录中的输出文件。

`bin/hdfs dfs -ls  /output`

列出两个文件:`_SUCCESS`，表示纱线作业成功完成，`part-r-00000`，是`wordcount`应用的输出，如图 [8-15](#Fig15) 所示。

![A978-1-4842-1830-3_8_Fig15_HTML.jpg](A978-1-4842-1830-3_8_Fig15_HTML.jpg)

图 8-15。

Files Output by the YARN Application

使用以下命令列出`wordcount`应用的输出。

`hdfs dfs -cat /output/part-r-00000`

输入文件`input1.txt`和`input2.txt`中每个不同单词的字数得到输出，如图 [8-16](#Fig16) 所示。

![A978-1-4842-1830-3_8_Fig16_HTML.jpg](A978-1-4842-1830-3_8_Fig16_HTML.jpg)

图 8-16。

Listing the Word Count

## 停止 Hadoop Docker 容器

可以使用`docker` `stop`命令停止运行 Hadoop 进程的 Docker 容器。

`sudo docker stop hadoop`

随后运行`docker ps`命令，没有容器被列为运行中，如图 [8-17](#Fig17) 所示。

![A978-1-4842-1830-3_8_Fig17_HTML.jpg](A978-1-4842-1830-3_8_Fig17_HTML.jpg)

图 8-17。

Listing Running Docker Containers after stopping Apache Hadoop Container

## 使用 CDH 坞站映像

如前所述，Apache Hadoop 有几个 Docker 映像可用。另一个 Docker 映像是`svds/cdh` Docker 映像，我们也将在随后的章节中使用，它基于由名为 CDH 的 Cloudera Hadoop 发行版打包的 Apache Hadoop 生态系统。`svds/cdh`映像不仅包括 Apache Hadoop，还包括 Apache Hadoop 生态系统中的几个框架，其中一些将在后面的章节中讨论。用下面的命令下载`svds/cdh`镜像。

`sudo docker pull svds/cdh`

启动一个运行 CDH 框架的 Docker 容器。

`sudo docker run  -d --name cdh svds/cdh`

启动交互式终端来运行 CDH 框架的命令。

`sudo docker exec -it cdh bash`

在 tty 中，Hadoop 框架应用无需进一步配置即可运行。例如，在命令行上运行带有“hdfs”的 HDFS 命令。`hdfs`命令的用法如下。

`hdfs`

HDFS 命令用法得到如图 [8-18](#Fig18) 所示的输出。

![A978-1-4842-1830-3_8_Fig18_HTML.jpg](A978-1-4842-1830-3_8_Fig18_HTML.jpg)

图 8-18。

hdfs Command Usage

配置文件在`/etc/hadoop/conf`符号链接中，如图 [8-19](#Fig19) 所示。

![A978-1-4842-1830-3_8_Fig19_HTML.jpg](A978-1-4842-1830-3_8_Fig19_HTML.jpg)

图 8-19。

Listing the Symlink for the Configuration Directory

图 [8-20](#Fig20) 列出了`conf`符号链接指向的`/etc/alternatives/hadoop-conf`目录下的配置文件如下。

![A978-1-4842-1830-3_8_Fig20_HTML.jpg](A978-1-4842-1830-3_8_Fig20_HTML.jpg)

图 8-20。

Listing the Configuration Files

可使用`docker stop`命令停止 cdh 容器。

`sudo docker stop cdh`

## 摘要

在本章中，我们在 Docker 容器中运行了 Apache Hadoop 组件。我们创建了一些文件，并把这些文件放在 HDFS。随后，我们运行了一个与 Hadoop 发行版中的示例打包在一起的 MapReduce `wordcount`应用。我们还介绍了基于 Cloudera Hadoop 发行版(CDH)的 Docker 映像，我们还将在基于 Apache Hadoop 生态系统框架的后续章节中使用它。