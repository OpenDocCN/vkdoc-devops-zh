# 八、数据仓库

关于数据仓库的这一章是上一章的延伸，上一章讲述了使用分布式对象存储系统 MinIO 开发现代数据湖。数据湖存储各种各样的数据形式，而数据仓库管理各种各样的数据源。数据仓库提供对数据目录、元数据、索引、键/值存储、消息队列、事件流、文档和关系数据库(包括数据湖)的访问。数据湖和数据仓库之间的界限并不总是很清楚；这本书将数据仓库的概念区分为任何包含数据的源的管理集合，这些数据是经过处理、组织、索引、编目或以其他方式有目的地标识的。

开源数据湖管理系统，如 Delta Lake <sup>[1](#Fn1)</sup> 带来了 ACID 事务、元数据、统一流和批量数据，而 Kylo <sup>[2](#Fn2)</sup> 则提供了一个健壮的用户界面，用于数据摄取、准备和发现。这些复杂的数据湖应用程序开始模糊一个巨大的、无形式的数据湖和组织良好的数据仓库之间的界限。然而，这些系统的结果很可能是更高层次的数据仓库概念的候选者。

数据湖在收集数据时是不加选择的；当组织获取任何类型的数据时，在使用数据的业务案例出现之前，可能会出现存储数据的需求。当了解了一组数据的价值和用途后，就可以对其进行处理、开发模式、编制属性索引、对值进行规范化，并对元数据进行编目，以供感兴趣的服务或人类分析师使用。数据仓库提供对实时事件和消息数据以及历史数据集合的访问，为决策支持系统、商业智能、分析、机器学习和推理做好准备。

## 数据和数据科学

与支持数据科学活动相关的概念非常广泛，此外还有大量技术和实现，专注于由人类或机器提供数据驱动的决策。数据平台促进了数据的接收、访问和管理，在其中，数据仓库提供了数据源、模式和元数据的目录。

在数据科学领域，机器学习活动通常会对数据提出一系列特别苛刻的要求。来自谷歌的十名研究人员撰写了一篇题为“机器学习系统中隐藏的技术债务”的研究论文。 <sup>[3](#Fn3) 支持机器学习的基础设施包括配置、数据收集、特征提取、数据验证、机器资源管理、分析工具、过程管理工具、服务基础设施和监控(见图 [8-1](#Fig1) )。此外，许多其他数据科学活动需要大量这种资源，包括商业智能和分析。</sup>

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig1_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig1_HTML.jpg)

图 8-1

机器学习基础设施 <sup>3</sup>

下一节将介绍一个适中但功能强大的现代数据仓库的基础，它能够提供大多数数据科学活动(包括机器学习)所需的大部分(如果不是全部)功能。

### 数据平台

在 Kubernetes 中构建一个现代化的数据仓库提供了一个抽象的底层基础设施、一个统一的控制平面、标准化的配置管理、整体监控、基于角色的访问控制、网络策略，以及与云原生技术的快速发展前景 <sup>[4](#Fn4)</sup> 的兼容性。

本章安装并配置了三个新的数据源:MySQL <sup>[5](#Fn5)</sup> 集群，代表一个公共的 RDBMS 数据库；Apache Cassandra<sup>[6](#Fn6)</sup>作为一个宽列分布式 NoSQL 数据库；Apache Hive<sup>[7](#Fn7)</sup>能够在上一章设置的 S3 兼容对象存储之上投影一个模式。很快， <sup>[8](#Fn8)</sup> 一个针对大数据的分布式 SQL 查询引擎将这些现有的数据源绑定到一个目录中，提供模式和连接。Presto 原生支持 20 多种典型的数据应用，包括 Elasticsearch(在第 [6](06.html) 章配置)和 Apache Kafka(在第 [5](05.html) 章配置)。

编写一个本地连接并使用来自多个源的数据的应用程序并不罕见。但是，Presto 等技术整合和抽象了这种能力，将查询分布到集群中的工作人员，汇总结果，并监控性能。通过管理不同的连接要求和模式管理，集中访问 Presto 的巨大数据仓库减少了跨专业系统的技术债务(见图 [8-2](#Fig2) )。

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig2_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig2_HTML.jpg)

图 8-2

Presto 分布式 SQL 连接多个数据源

## 发展环境

以下练习继续利用前面章节中提到的小型集群，包括一个用于 Kubernetes 主节点的 2 vCPU/8G RAM/40G SSD 和四个用于 Kubernetes 工作节点的 4 vCPU/16G RAM/160G SSD 实例。本章中的概念和配置是按比例缩小的，以适应这个经济的实验和开发集群。

本章利用第 [3](03.html) 、 [5](05.html) 和 [6](06.html) 章中定义的应用和集群配置以及第 [7](07.html) 章中的新 MinIO 集群(参见表 [7-1](https://doi.org/10.1007/978-1-4842-5611-4_7Tab#1) )。本章继续在文件夹`cluster-apk8s-dev5`下组织配置清单。

## 数据和元数据源

数据仓库不仅提供对来自各种来源的历史数据的访问，而且还帮助获取、开发和描述数据集。本节将安装 MySQL，稍后 Apache Hive 将使用它来存储元数据，本书将通过在 MinIO 中的对象上投影模式来演示。此外，本章还安装了 Apache Cassandra 来进一步演示 Kubernetes 中各种数据管理系统的操作，以及利用数据仓库概念的组合效应。

### 关系型数据库

MySQL 是一个非常流行的数据库。根据 2019 年 Stack Overflow 开发者调查，54%的受访者使用 MySQL。这些结果并不令人惊讶，每天都有成千上万的网站由 MySQL 支持的内容管理系统驱动，如 WordPress 和 Drupal。 <sup>[10](#Fn10)</sup> WordPress 声称它为 35%的互联网提供动力；如果这种说法是准确的，那么可以有把握地假设所有在线数据(以网站内容表示)的很大一部分是由 MySQL 数据库提供的。

数据仓库应用程序 Apache Hive 需要一个数据库来存储和管理元数据。Hive 可以使用 MySQL(以及许多其他数据库)来存储元数据。对 MySQL 的平台支持既可以作为可能的数据源，也可以作为数据仓库的功能依赖(见图 [8-2](#Par147) )。

MySQL 以及大多数传统的数据库系统都出现在 Kubernetes 甚至云原生概念之前。用于配置和维护有状态数据库工作负载的挑战性需求的交钥匙解决方案正在快速发展。本节安装一个 MySQL Kubernetes 操作符，并定义新 MySQL 集群的期望状态。

#### MySQL 运算符

本节配置由 Presslabs 提供的稳定的、有良好文档记录的、积极维护的 MySQL Kubernetes 操作符。<sup>[12](#Fn12)</sup>MySQL 操作员定义了一个新的自定义资源，由自定义资源定义(CRD) `MysqlCluster`表示。

如果按照前面的章节，本书开发的平台在第 [3](03.html) 章定义和管理资源`CephCluster`中设置了 Rook Ceph 操作符，在第 [7](07.html) 章定义和管理资源`Tenant`中设置了 MinIO 操作符。像以前的操作符一样，新的 MySQL 操作符扩展了 Kubernetes，因此赋予了本书中开发的平台在一个或多个名称空间中快速部署和管理一个或多个 MySQL 集群的能力。

下面的配置将 MySQL 操作符安装在新的名称空间`mysql-operator`中，并且可以管理在任何名称空间中创建的`MysqlCluster`资源。在集群级别组织命名空间配置和安装文档。创建目录`cluster-apk8s-dev5/000-cluster/25-mysql-operator`来包含 MySQL 操作符名称空间配置和文档。接下来，用清单 [8-1](#PC1) 中的内容创建一个名为`00-namespace.yml`的文件。此外，创建一个名为`README.md`的文件来记录下一步执行的舵命令。

```
apiVersion: v1
kind: Namespace
metadata:
  name: mysql-operator

Listing 8-1MySQL operator Namespace

```

应用 MySQL 操作符名称空间配置:

```
$ kubectl apply -f 00-namespace.yml

```

接下来，将 Presslabs 图表存储库添加到 Helm:

```
$ helm repo add presslabs \
https://presslabs.github.io/charts

```

最后，安装 mysql-operator。配置操作员使用第 [3](03.html) 章中设置的 rook-ceph-block 存储类别:

```
$ helm install presslabs/mysql-operator \
  --set orchestrator.persistence.storageClass=rook-ceph-block \
  --name mysql-operator \
  --namespace mysql-operator

```

新的 mysql-operator 准备安装和管理 MysqlCluster 资源中定义的 mysql 集群，下一节将对此进行描述。此外，mysql-operator 将 GitHub 的 MySQL Orchestrator 公开为 mysql-operator 名称空间中的服务 mysql-operator:80。Orchestrator 是一个 MySQL 管理和可视化工具，提供拓扑发现、重构和恢复功能。 <sup>[十三](#Fn13)</sup>

通过端口转发服务并在浏览器中访问它来访问 Orchestrator:

```
$ kubectl port-forward service/mysql-operator \
8080:80 -n mysql-operator

```

#### MySQL 集群

下一节定义了一个小型的双节点 MySQL 集群，在名称空间`data`中命名为`mysql`。最初，本章使用 MySQL 作为 Apache Hive 的元数据后端，后来使用 Presto 演示不同数据源之间的复杂连接。

创建目录`cluster-apk8s-dev5/003-data/080-mysql`来包含 MySQL 集群配置。接下来，从清单 [8-2](#PC6) 中创建一个名为`90-cluster.yml`的文件。

```
apiVersion: v1
kind: Secret
metadata:
  name: mysql-credentials
  namespace: data
type: Opaque
stringData:
  ROOT_PASSWORD: strongpassword
  USER: hive
  PASSWORD: strongpassword
  DATABASE: objectmetastore
---
apiVersion: mysql.presslabs.org/v1alpha1
kind: MysqlCluster
metadata:
  name: mysql
  namespace: data
spec:
  replicas: 2
  secretName: mysql-credentials
  volumeSpec:
    persistentVolumeClaim:
      accessModes: ["ReadWriteOnce"]
      storageClassName: "rook-ceph-block"
      resources:
        requests:
          storage: 1Gi

Listing 8-2MySQL cluster configuration

```

应用 MySQL 集群配置:

```
$ kubectl apply -f 90-cluster.yml

```

### 阿帕奇卡桑德拉

Apache Cassandra 是一个高性能、高可用性的宽列数据库。将 Cassandra 添加到本书描述的数据平台中，通过提供网络规模的数据库解决方案，完善了数据访问和存储能力。网飞是 Cassandra 更著名和公开的用户之一，“网飞在 AWS 上使用 Cassandra，作为其全球分布式流媒体产品的关键基础设施组件。”网飞公布的基准测试显示每秒超过 100 万次写入。

Cassandra 的点对点设计意味着没有主节点可以压倒或超越，从而允许 Cassandra 在数据量和速度方面进行线性扩展。这些特征提供了将大量大数据需求与高速宽列存储数据相结合的功能。

下一节配置用于在 Kubernetes 中准备和管理一个或多个 Cassandra 集群的 Rook Cassandra 操作符。

#### 卡珊德拉算子

Rook <sup>[14](#Fn14)</sup> 是一家为 Kubernetes 提供数据存储运营商的知名供应商。这本书在第 [3](03.html) 章介绍了 Rook Ceph 操作符。Rook Cassandra 操作符在 API 名称空间`cassandra.rook.io`下用新的定制资源定义`Cluster`扩展了 Kubernetes。

Rook Cassandra 操作符 <sup>[15](#Fn15)</sup> 支持集群设置，允许指定所需的 Cassandra 版本、容器映像库、注释，以及使用 Scylla、 <sup>[16](#Fn16)</sup> 的选项，这是一种用 C++编写的 Cassandra 兼容的替代方案。Scylla 声称每个节点的性能达到 1，000，000 次操作，并且能够扩展到数百个节点，99%的延迟不到 1 毫秒。Rook 与 Scylla 和 Cassandra 数据库的兼容性有助于试验这两种解决方案。此外，Rook Cassandra 操作员支持 Cassandra 物理拓扑的定义，从而能够为每个集群指定数据中心和机架配置。

创建目录`cluster-apk8s-dev5/000-cluster/23-rook-cassandra`来包含车卡珊德拉操作员配置。接下来，从清单 [8-3](#PC8) 中创建一个名为`00-operator.yml`的文件。

```
apiVersion: v1
kind: Namespace
metadata:
  name: rook-cassandra-system
---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: clusters.cassandra.rook.io
spec:
  group: cassandra.rook.io
  names:
    kind: Cluster
    listKind: ClusterList
    plural: clusters
    singular: cluster
  scope: Namespaced
  version: v1alpha1
  validation:
    openAPIV3Schema:
      properties:
        spec:
          type: object
          properties:
            version:
              type: string
              description: "Version of Cassandra"
            datacenter:
              type: object
              properties:
                name:
                  type: string
                  description: "Datacenter Name"
                racks:
                  type: array
                  properties:
                    name:
                      type: string
                    members:
                      type: integer
                    configMapName:
                      type: string
                    storage:
                      type: object
                      properties:
                        volumeClaimTemplates:
                          type: object
                      required:
                       - "volumeClaimTemplates"
                    placement:
                      type: object
                    resources:

                      type: object
                      properties:
                        cassandra:
                          type: object
                        sidecar:
                          type: object
                      required:
                        - "cassandra"
                        - "sidecar"
                    sidecarImage:
                      type: object
                  required:
                    - "name"
                    - "members"
                    - "storage"
                    - "resources"
              required:
                - "name"
          required:
            - "version"
            - "datacenter"

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole

metadata:
  name: rook-cassandra-operator
rules:
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get", "list", "watch", "delete"]
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["*"]
  - apiGroups: [""]
    resources: ["persistentvolumes", "persistentvolumeclaims"]
    verbs: ["get", "delete"]
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get"]
  - apiGroups: ["apps"]
    resources: ["statefulsets"]
    verbs: ["*"]
  - apiGroups: ["policy"]
    resources: ["poddisruptionbudgets"]
    verbs: ["create"]
  - apiGroups: ["cassandra.rook.io"]
    resources: ["*"]
    verbs: ["*"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create","update","patch"]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rook-cassandra-operator
  namespace: rook-cassandra-system
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: rook-cassandra-operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: rook-cassandra-operator
subjects:
- kind: ServiceAccount
  name: rook-cassandra-operator
  namespace: rook-cassandra-system
---
 apiVersion: apps/v1
 kind: StatefulSet

 metadata:
   name: rook-cassandra-operator
   namespace: rook-cassandra-system
   labels:
     app: rook-cassandra-operator
 spec:
   replicas: 1
   serviceName: "non-existent-service"
   selector:
     matchLabels:
       app: rook-cassandra-operator
   template:
     metadata:
       labels:
         app: rook-cassandra-operator
     spec:
       serviceAccountName: rook-cassandra-operator
       containers:
       - name: rook-cassandra-operator
         image: rook/cassandra:v1.1.2
         imagePullPolicy: "Always"
         args: ["cassandra", "operator"]
         env:
         - name: POD_NAME
           valueFrom:
             fieldRef:
               fieldPath: metadata.name
         - name: POD_NAMESPACE
           valueFrom:
             fieldRef:
               fieldPath: metadata.namespace

Listing 8-3Rook Cassandra operator

```

应用 Cassandra 运算符配置:

```
$ kubectl apply -f 00-operator.yml

```

#### 卡桑德拉星团

本节创建一个三节点 Apache Cassandra 集群，稍后用于演示 web 级宽列存储数据库和大数据系统的强大聚合，这些大数据系统用 Presto 分布式 SQL 查询引擎表示。下面的配置在数据命名空间中定义了 Kubernetes 角色、ServiceAccount 和 RoleBinding，以便在 Cassandra 集群中使用。Cassandra 集群名为 apk8s，配置在一个名为`r1`的虚拟机架中。更广泛和复杂的集群应该通过设置`nodeAffinity`、`podAffinity`、`podAntiAffinity`和`tolerations`的位置值来定义分布在 Kubernetes 集群内的多个数据中心和机架。

创建目录`cluster-apk8s-dev5/003-data/060-cassandra`来包含 Cassandra 集群配置。接下来，从清单 [8-4](#PC10) 中创建一个名为`15-rbac.yml`的文件。

```
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: cassandra-member
  namespace: data
rules:
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get"]
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["get","list","patch","watch"]
  - apiGroups: ["cassandra.rook.io"]
    resources: ["clusters"]
    verbs: ["get"]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cassandra-member
  namespace: data
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: cassandra-member
  namespace: data
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: cassandra-member
subjects:
  - kind: ServiceAccount
    name: cassandra-member
    namespace: data

Listing 8-4Rook Cassandra RBAC configuration

```

应用 Cassandra 集群 RBAC 配置:

```
$ kubectl apply -f 15-rbac.yml

```

接下来定义的小型 Cassandra 集群被限制在一个虚拟机架上，没有指定的 Kubernetes 节点、关联或容差。以下配置将 Cassandra 集群中的每个节点限制为一个 CPU 和 2gb 内存。

从清单 [8-5](#PC12) 中创建一个名为`90-cluster.yml`的文件。

```
apiVersion: cassandra.rook.io/v1alpha1
kind: Cluster
metadata:
  name: cassandra
  namespace: data
spec:
  version: 3.11.1
  mode: cassandra
  datacenter:
    name: apk8s
    racks:
      - name: r1
        members: 3
        storage:
          volumeClaimTemplates:
            - metadata:
                name: cassandra-data
              spec:
                storageClassName: rook-ceph-block
                resources:
                  requests:
                    storage: 5Gi
        resources:
          requests:
            cpu: 1
            memory: 2Gi
          limits:
            cpu: 1
            memory: 2Gi

Listing 8-5Rook Cassandra cluster configuration

```

应用 Cassandra 集群配置:

```
$ kubectl apply -f 90-cluster.yml

```

### Apache 蜂巢

Apache Hive 是最初由脸书开发的数据仓库软件，后来交给了 Apache 软件基金会。网飞 <sup>[17](#Fn17)</sup> 和 FINRA <sup>[18](#Fn18)</sup> 等组织使用 Hive 跨分布式存储系统查询海量结构化数据，包括 Hadoop 的 HDFS 和亚马逊 S3。Hive 通过提供标准的 SQL 接口，简化了查询大数据通常需要的复杂 MapReduce 作业。虽然 Hive 不是一个数据库，但它提供了将模式投影到存储在 HDFS 或 S3 兼容存储中的任何结构化数据上的能力。亚马逊的 AWS 提供产品 Elastic MapReduce，包括一个版本的 Hive as a service。 <sup>[19](#Fn19)</sup>

Apache Hive 使组织能够利用大量不受正式数据库管理系统管理的结构化数据、稳定的物联网数据流、从遗留系统导出的数据以及临时数据摄取。Apache Hive 通过在巨大的数据湖中提供 SQL 接口、元数据和模式，降低了执行数据科学活动的复杂性和工作量，包括业务分析、业务智能和机器学习。

#### 集装箱化

本节创建一个定制的 Apache Hive 容器，该容器被配置为使用 MySQL 来存储与驻留在 S3 兼容的分布式存储系统中的对象相关的模式和元数据，例如在第 [7](07.html) 章中配置的 MinIO 集群。与许多大数据应用程序一样，Apache Hive 是在 Cloud-Native 和 Kubernetes 生态系统之外发展起来的，因此需要更多的努力才能将其纳入集群。下面从构建一个适用于 Kubernetes 和本地实验的定制容器开始。

创建目录`apk8s-hive`来包含新 Apache Hive Docker 容器的必要组件和配置。 <sup>[20](#Fn20)</sup> 接下来，创建目录`src`，下载并解压缩 Apache Hive 及其主依赖 Apache Hadoop:

```
$ mkdir -p apk8s-hive/src
$ cd apk8s-hive

$ curl -L http://mirror.cc.columbia.edu/pub/software/apache/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz -o ./src/apache-hive-3.1.2-bin.tar.gz

$ curl -L http://archive.apache.org/dist/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz -o ./src/hadoop-3.1.2.tar.gz

$ tar -xzvf ./src/apache-hive-3.1.2-bin.tar.gz -C ./src
$ tar -xzvf ./src/hadoop-3.1.2.tar.gz -C ./src

```

接下来，通过添加 JAR 文件来扩展 Apache Hive 的功能，JAR 文件包含连接到 S3 兼容的对象存储和 MySQL 进行模式和元数据管理所需的功能:

```
$ export HIVE_LIB=$(pwd)/src/apache-hive-3.1.2-bin/lib
$ export MIRROR=https://repo1.maven.org/maven2

$ curl $MIRROR/org/apache/hadoop/hadoop-aws/3.1.1/hadoop-aws-3.1.1.jar -o $HIVE_LIB/hadoop-aws-3.1.1.jar

$ curl $MIRROR/com/amazonaws/aws-java-sdk/1.11.406/aws-java-sdk-1.11.307.jar -o $HIVE_LIB/aws-java-sdk-1.11.307.jar

$ curl $MIRROR/com/amazonaws/aws-java-sdk-core/1.11.307/aws-java-sdk-core-1.11.307.jar -o $HIVE_LIB/aws-java-sdk-core-1.11.307.jar

$ curl $MIRROR/com/amazonaws/aws-java-sdk-dynamodb/1.11.307/aws-java-sdk-dynamodb-1.11.307.jar -o $HIVE_LIB/aws-java-sdk-dynamodb-1.11.307.jar

$ curl $MIRROR/com/amazonaws/aws-java-sdk-kms/1.11.307/aws-java-sdk-kms-1.11.307.jar -o $HIVE_LIB/aws-java-sdk-kms-1.11.307.jar

$ curl $MIRROR/com/amazonaws/aws-java-sdk-s3/1.11.307/aws-java-sdk-s3-1.11.307.jar -o $HIVE_LIB/aws-java-sdk-s3-1.11.307.jar

$ curl $MIRROR/org/apache/httpcomponents/httpclient/4.5.3/httpclient-4.5.3.jar -o $HIVE_LIB/httpclient-4.5.3.jar

$ curl $MIRROR/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar -o $HIVE_LIB/joda-time-2.9.9.jar

$ curl $MIRROR/mysql/mysql-connector-java/5.1.48/mysql-connector-java-5.1.48.jar -o $HIVE_LIB/mysql-connector-java-5.1.48.jar

```

与许多基于 Java 的应用程序一样，Hive 使用 XML 文件进行配置，在本例中是 hive-site.xml。但是，将包含敏感身份验证令牌、密码和特定于环境的服务位置的配置值打包是一种反模式，会导致安全问题并限制容器的可重用性。从文件系统挂载配置文件(或者在 Kubernetes 的情况下挂载 ConfigMaps)是配置容器的标准方法，为使用容器的管理员或开发人员提供了相当大的灵活性；但是，这种方法限制了利用 Kubernetes 中现有的 Secrets 和 ConfigMap 值的能力。本节描述的技术创建了一个配置文件模板，该模板将由容器在运行时用环境变量填充。

用清单 [8-6](#PC16) 中的内容创建一个名为`hive-site-template.xml`的文件。

```
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
<value>jdbc:mysql://MYSQL_ENDPOINT/objectmetastore?createDatabaseIfNotExist=true&useSSL=false</value>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionDriverName</name>
      <value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionUserName</name>
      <value>MYSQL_USER</value>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionPassword</name>
      <value>MYSQL_PASSWORD</value>
    </property>
    <property>
      <name>fs.s3a.endpoint</name>
      <value>S3A_ENDPOINT</value>
    </property>
    <property>
      <name>fs.s3a.access.key</name>
      <value>S3A_ACCESS_KEY</value>
    </property>
    <property>
      <name>fs.s3a.secret.key</name>
      <value>S3A_SECRET_KEY</value>
    </property>
    <property>
      <name>fs.s3a.path.style.access</name>
      <value>S3A_PATH_STYLE_ACCESS</value>
    </property>
</configuration>

Listing 8-6Apache Hive configuration template hive-site-template.xml

```

创建一个名为`entrypoint.sh`的 shell 脚本作为容器的初始进程。入口点脚本使用 sed 将`hive-site.xml`配置文件中的值替换为通过容器运行时传递的环境变量中的值，这在前面的部分中进行了定义。应用配置后，脚本运行实用程序`schematool`来添加任何 MySQL 数据库和 Hive 存储模式和元数据所需的表。最后，入口点脚本启动一个 Hive 服务器和一个 Hive Metastore <sup>[21](#Fn21)</sup> 服务器。

创建一个名为`entrypoint.sh`的 Bash <sup>[22](#Fn22)</sup> 脚本，将清单 [8-7](#PC17) 中的内容用作新容器的入口点。

```
#!/bin/bash

# provide ample time for other services to come online
sleep 10

# configuration file location
HIVE_CONF="/opt/hive/conf/hive-site.xml"

# template replacements
for v in \
    MYSQL_ENDPOINT \
    MYSQL_USER \
    MYSQL_PASSWORD \
    S3A_ENDPOINT \
    S3A_ACCESS_KEY \
    S3A_SECRET_KEY \
    S3A_PATH_STYLE_ACCESS; do

    sed -i'' "s/${v}/${!v//\//\\/}/g" $HIVE_CONF
done

# add metastore schema to mysql
$HIVE_HOME/bin/schematool -dbType mysql -initSchema
$HIVE_HOME/bin/hiveserver2 start &
$HIVE_HOME/bin/hiveserver2 --service metastore

Listing 8-7Apache Hive container entrypoint.sh script

```

接下来，用清单 [8-8](#PC18) 中的内容创建一个 Dockerfile。

```
FROM ubuntu:16.04

ENV HADOOP_HOME /opt/hadoop
ENV HIVE_HOME /opt/hive
ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64

RUN apt-get update \
 && apt-get install -y --reinstall build-essential \
 && apt-get install -y \
    curl ssh rsync vim \
    net-tools openjdk-8-jdk python2.7-dev \
    libxml2-dev libkrb5-dev libffi-dev \
    libssl-dev libldap2-dev python-lxml \
    libxslt1-dev libgmp3-dev libsasl2-dev \
    libsqlite3-dev libmysqlclient-dev

ADD src/hadoop-3.1.2 /opt/hadoop
ADD src/apache-hive-3.1.2-bin /opt/hive

COPY ./hive-site-template.xml /opt/hive/conf/hive-site.xml

ADD entrypoint.sh /
RUN chmod 775 /entrypoint.sh

ENTRYPOINT ["/entrypoint.sh"]

EXPOSE 9083
EXPOSE 10000
EXPOSE 10002

Listing 8-8Apache Hive entrypoint.sh

```

确保定制的 Apache Hive 容器化项目包含前面指定的所有必要文件，如清单 [8-9](#PC20) 所示。接下来，为本地测试构建 docker 文件中定义的容器:

```
.
├── Dockerfile
├── docker-compose.yml
├── entrypoint.sh
├── hive-site-template.xml
└── src
    ├── apache-hive-3.1.2-bin
    ├── apache-hive-3.1.2-bin.tar.gz
    ├── hadoop-3.1.2
    └── hadoop-3.1.2.tar.gz

Listing 8-9Apache Hive containerization files

```

```
$ docker build -t apk8s-hive-s3m:3.1.2 .

```

创建一个版本标记并将新容器推送到公共注册中心(或者在测试容器后创建标记，如下一节所述):

```
$ docker tag apk8s-hive-s3m:3.1.2 \
apk8s/hive-s3m:3.1.2-1.0.0

```

#### 本地蜂箱测试

本节通过创建一个映射到 MinIO (S3) bucket `test`的数据库和表模式来测试在上一节中构建的 Hive 容器。在第 [7](07.html) 章定义的 MinIO 集群中创建 bucket `test`。在本书的后面，Hive 用于将对象位置作为数据源进行编目，并将模式投影到它们上面。下面演示了通过在 Hive 中创建一个映射到空桶`test`的模式来创建数据源(参见图 [8-3](#Fig3) )。

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig3_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig3_HTML.jpg)

图 8-3

在本地工作站上测试配置单元

在构建新容器`apk8s-hive-s3m:3.1.2`之后，如前一节所述，创建一个 Docker Compose <sup>[23](#Fn23)</sup> 文件，用于在用于构建容器的工作站上进行本地测试。用清单 [8-10](#PC22) 中的内容创建文件`docker-compose.yml`。将环境变量`S3A_ACCESS_KEY`和`S3A_SECRET_KEY`设置为第 [7](07.html) 章中建立的 MinIO 凭证。Docker Compose 配置定义了一个`mysql:8.0.18`数据库容器以及之前构建的 Apache Hive 容器`apk8s-hive-s3m:3.1.2`。

```
version: "3"

services:
  mysql:
    container_name: mysql
    image: mysql:8.0.18
    command: --default-authentication-plugin=mysql_native_password
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: demo
    ports:
      - "3306:3306"
  hive-metastore:
    container_name: hive
    image: apk8s-hive-s3m:3.1.2
    environment:
      MYSQL_ENDPOINT: "mysql:3306"
      MYSQL_USER: "root"
      MYSQL_PASSWORD: "demo"
      S3A_ENDPOINT: "https://obj.data.dev5.apk8s.dev"
      S3A_ACCESS_KEY: "miniouser"
      S3A_SECRET_KEY: "miniopassword"
      S3A_PATH_STYLE_ACCESS: "true"
    ports:
      - "9083:9083"
      - "10000:10000"
      - "10002:10002"
    depends_on:
      - mysql

Listing 8-10Apache Hive docker-compose.yml

```

运行新的 Docker 合成容器堆栈:

```
$ docker-compose up

```

启动 Docker Compose 后，新的 Apache Hive 容器连接到 MySQL，创建一个数据库和表，用于存储以后定义的模式和元数据。Apache Hive 容器公开了三个端口:HiveServer2 监听端口 10000，通过节俭/JDBC 提供 SQL 访问；Hive Metastore 侦听端口 9083，允许通过 thrift 协议访问元数据和表。Hive 在端口 10002 上提供了一个 web 接口，用于性能监控、调试和观察。

通过执行运行容器中可用的命令行应用程序，开始测试 Apache Hive:

```
$ docker exec -it hive /opt/hive/bin/hive

```

创建一个名为`test`的数据库:

```
hive> CREATE DATABASE IF NOT EXISTS test;
OK

```

使用空桶`test`在`test`数据库中创建一个名为`message`的表(如果桶不存在，在 MinIO 中创建桶):

```
hive> CREATE TABLE IF NOT EXISTS test.message (
    >     id int,
    >     message string
    > )
    > row format delimited fields terminated by ','
    > lines terminated by "\n" location 's3a://test/messages';

```

在新的`test.message`表中插入一条记录:

```
hive> INSERT INTO test.message
    > VALUES (1, "Hello MinIO from Hive");

```

选择从 MinIO (S3)返回的数据:

```
hive> SELECT * FROM test.message;
OK
1      Hello MinIO from Hive

```

前面的测试创建了一种分布式数据库，能够从一个高度可伸缩的分布式 MinIO 对象存储系统中编目和查询数 Pb 的数据。假设指定存储桶和前缀`(/test/messages/`中的所有数据都具有相同的结构，前面的练习能够对现有数据进行建模。这个强大的概念允许组织开始收集结构化数据，并在将来需要访问时应用模式。

下一节将 Apache Hive 的强大功能引入 Kubernetes 平台，这将在本书中继续讨论。在 Kubernetes 中运行 Hive 带来了容器管理、联网、监控和数据平台内所有服务的逻辑邻近性所提供的所有优势。

## 现代数据仓库

本书将现代数据仓库和数据湖视为一个开放的(采用容器化)、云原生的平台，以 Kubernetes(容器编排)为代表的云，并将该平台视为一个不断增长的数据管理应用程序集合，这些应用程序通过 API 和图形用户界面公开，能够在其中部署业务逻辑。

许多组织和应用程序需要访问各种数据源，从常见的 RDBMS 数据库到分布式文档、对象和密钥存储，这是数字化转型、物联网和数据科学活动(如机器学习)趋势的结果。将不同来源的数据关联起来是一种常见的做法；然而，根据这些来源之间的关系，这一过程可能具有挑战性。将所有数据源迁移到商业数据仓库可能成本过高，带来不可接受的限制，或者导致供应商锁定。在 Kubernetes 上构建一个现代的、云原生的、厂商中立的数据仓库可能会带来新的可能性，甚至与商业应用程序和 PaaS 产品一起。以很少的努力和资金实现了大量的功能和灵活性，从小处着手，具有近乎无限的扩展能力。

本节将 Presto 和 Apache Hive 添加到 Kubernetes 中，在本书开发的数据平台上应用新的层。Presto 和 Hive 展示了表示和组合 MinIO (S3)、Cassandra、MySQL 等数据源的能力，创建了一个具有分布式查询执行的集中式数据访问点。

### 储备

本节将部署本章前面开发的定制 Apache Hive 容器。Hive 在 Apache Hadoop 上提供了类似 SQL 的功能，将其用途扩展到更广泛的数据分析、分析和管理应用程序。Hadoop 的大数据功能传统上与 Hadoop 分布式文件系统(HDFS)相关联。然而，早期开发的自定义容器扩展了 Hive，使其能够使用 S3 兼容的对象存储作为 Hadoop HDFS 的现代替代方案。Apache Hive 在一个更大的数据湖中创建了一个数据仓库，如图 [8-4](#Fig4) 所示。

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig4_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig4_HTML.jpg)

图 8-4

Apache Hive 仓库结构化和半结构化数据

#### 库比涅斯配置

下面的配置定义了一个由实现本章前面开发的定制映像`apk8s/hive-s3m:3.1.2-1.0.0`的`hive`部署支持的`hive` Kubernetes 服务。新的 Hive 容器使用 MySQL 存储模式，定义存储在 MinIO (S3)中的结构化和半结构化对象。

创建目录`cluster-apk8s-dev5/003-data/085-hive`来包含 Apache Hive Kubernetes 配置。接下来，从清单 [8-11](#PC29) 中创建一个名为`10-service.yml`的文件。

```
apiVersion: v1
kind: Service
metadata:
  name: hive
  namespace: data
  labels:
    app: hive
spec:
  selector:
    app: hive
  ports:
    - protocol: "TCP"
      port: 10000
      targetPort: tcp-thrift
      name: tcp-thrift
    - protocol: "TCP"
      port: 9083
      targetPort: tcp-thrift-meta
      name: tcp-thrift-meta
    - protocol: "TCP"
      port: 10002
      targetPort: http-hwi
      name: http-hwi
  type: ClusterIP

Listing 8-11Apache Hive Service

```

应用 Apache 配置单元服务配置:

```
$ kubectl apply -f 10-service.yml

```

接下来，从清单 [8-12](#PC31) 中创建一个名为`30-deployment.yml`的文件。下面的部署将本章前面定义的环境变量`MYSQL_USER`和`MYSQL_PASSWORD`设置为 MySQL 集群配置的一部分。第 [7](07.html) 章用秘密`minio-creds-secret`配置了 MinIO，它为这个定制配置单元部署中的`S3A_ACCESS_KEY`和`S3A_SECRET_KEY`环境变量提供值。

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hive
  namespace: data
  labels:
    app: hive
spec:
  replicas: 1
  revisionHistoryLimit: 1
  selector:
    matchLabels:
      app: hive
  template:
    metadata:
      labels:
        app: hive
    spec:
      containers:
        - name: hive
          image: apk8s/hive-s3m:3.1.2-1.0.0
          imagePullPolicy: IfNotPresent
          env:
            - name: MYSQL_ENDPOINT
              value: "mysql:3306"
            - name: MYSQL_USER
              valueFrom:
                secretKeyRef:
                  name: mysql-credentials
                  key: USER
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-credentials
                  key: PASSWORD
            - name: S3A_ENDPOINT
              value: "http://minio:9000"
            - name: S3A_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-creds-secret
                  key: accesskey
            - name: S3A_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-creds-secret
                  key: secretkey
            - name: S3A_PATH_STYLE_ACCESS
              value: "true"
          ports:
            - name: tcp-thrift-meta
              containerPort: 9083
            - name: tcp-thrift
              containerPort: 10000
            - name: http-hwi
              containerPort: 10002

Listing 8-12Apache Hive Deployment

```

应用 Apache 配置单元部署:

```
$ kubectl apply -f 30-deployment.yml

```

#### 测试数据

正如本章前面所演示的，Apache Hive 提供了将模式投射到空存储桶上的能力，允许创建特定的但结构良好的数据集。虽然 Hive 本身不是一个数据库，但它可以在分布式对象存储上创建大规模可伸缩的基于对象的数据库，在这种情况下，是 S3 兼容的 MinIO。Hive 提供了存储支持给定类型的现有结构化和半结构化对象的模式的能力。

以下练习创建了第 [7](07.html) 章中介绍的新献血者示例数据集，由分布在一千个 CSV 文件中的一百万条记录组成。每条记录包含虚构捐赠者的电子邮件、姓名、血型、生日和州的逗号分隔值。

按照第 [6 章](06.html)中的配置运行 JupyterLab，创建一个新的 Jupyter 笔记本；在这种情况下，浏览到一个自定义的 [`https://lab.data.dev5.apk8s.dev/`](https://lab.data.dev5.apk8s.dev/) 。将下列每个代码段添加到各自的单元格中。

Note

通过将`minio-internal-service.data:9000`替换为`minio.data.dev5.apk8s.dev:443`(在第 [7 章](07.html)中设置的 MinIO 集群入口)和`secure=False`到`secure=True`，以下练习可作为普通 Python 3 脚本在本地工作站上执行。

在基于 Python 的 Jupyter 笔记本的第一个单元中，确保安装了如下的`Faker`和`minio`库:

```
!pip install Faker==2.0.3
!pip install minio==5.0.1

```

导入以下 Python 库:

```
import os
import datetime
from faker import Faker
from minio import Minio
from minio.error import (ResponseError,
                         BucketAlreadyOwnedByYou,
                         BucketAlreadyExists)

```

创建一个函数，返回一个元组，其中包含一条虚构的提供者信息记录:

```
fake = Faker()

def makeDonor():
    fp = fake.profile(fields=[
        "name",
        "birthdate",
        "blood_group"
    ])

    return (
        fake.ascii_safe_email(),
        fp["name"],
        fp["blood_group"],
        fp["birthdate"].strftime("%Y-%m-%d"),
        fake.state(),
    )

```

创建一个 MinIO API 客户端并创建 bucket `exports`:

```
bucket = "exports"
mc = Minio('minio-internal-service.data:9000',
            access_key='<accesskey>',
            secret_key='<secretkey>',
            secure=False)

try:
    mc.make_bucket(bucket)
except BucketAlreadyOwnedByYou as err:
    pass
except BucketAlreadyExists as err:
    pass
except ResponseError as err:
    raise

```

最后，用数据时间创建一个名为的文件，包含一千个提供者记录。将文件上传到带有前缀`donors/`(例如`donors/20200205022452.csv`)的 MinIO bucket `exports`。重复这个过程 1000 次，总共有 100 万个测试记录。

```
for i in range(1,1001):
    now = datetime.datetime.now()
    dtstr = now.strftime("%Y%m%d%H%M%S")
    filename = f'donors/{dtstr}.csv'
    tmp_file = f'./tmp/{dtstr}.csv'

    with open(tmp_file,"w+") as tf:
        tf.write("email,name,type,birthday,state\n")
        for ii in range(1,1001):
            line = ",".join(makeDonor()) + "\n"
            tf.write(line)

        mc.fput_object(bucket, filename, tmp_file,
                    content_type='application/csv')

    os.remove(tmp_file)
    print(f'{i:02}: {filename}')

```

#### 创建模式

通过在 running Pod 中执行 Hive 命令行界面来测试新的自定义 Apache Hive 部署。

首先，在 MinIO 中创建一个名为`hive`的 bucket。

获取自定义 Apache 配置单元 Pod 名称:

```
$ kubectl get pods -l app=hive -n data

```

执行`hive`命令:

```
$ kubectl exec -it hive-8546649b5b-lbcrn \                /opt/hive/bin/hive -n data

```

从正在运行的 hive 命令中，创建一个名为`exports`的数据库:

```
hive> CREATE DATABASE exports;

```

接下来，创建表格`exports.donors`:

```
hive> CREATE TABLE exports.donors (
    >     email string,
    >     name string,
    >     blood_type string,
    >     birthday date,
    >     state string
    > )
    > row format delimited fields terminated by ','
    > lines terminated by "\n"
    > location 's3a://exports/donors';

```

本章使用一个定制的 Apache Hive 容器将模式投射到分布式对象存储上。虽然单个 Hive 容器能够通过在`hive:1000` Kubernetes 服务上公开的 ODBC/thrift 执行查询，但是直接针对 Hive 执行生产工作负载需要更大的 Hive 集群。但是，下一节使用一个 Presto 集群来执行分布式查询，并且只使用 Hive 从通过服务`hive:9083`公开的元数据服务器提供模式。

下一节将演示如何使用 Presto 连接使用 Hive 在 MinIO 分布式对象存储中收集的结构化数据，以及各种其他数据源，包括 RDBMS MySQL 和键/值数据库 Apache Cassandra。

### 很快

Presto 是本书中定义的现代数据仓库的最后一个组件。根据官网 prestodb.io 的介绍，“Presto 是一个开源的分布式 SQL 查询引擎，用于对从千兆字节到千兆字节的所有大小的数据源运行交互式分析查询。”虽然 Hive 也是一个查询海量数据的分布式 SQL 查询引擎电缆，但 Presto 连接了更广泛的数据源，包括 Apache Hive(如图 [8-5](#Fig5) 所示)。除了 Presto 的高性能查询功能，它还提供了一个数据源的中央目录。

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig5_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig5_HTML.jpg)

图 8-5

预先存储跨多个数据源的分布式 SQL 查询

Presto 减少了从多个来源检索数据所需的应用程序逻辑的数量，既通过标准的 SQL 抽象，又不需要客户端连接数据(在某些情况下被认为是反模式 <sup>[24](#Fn24)</sup> )。Presto 提供了跨所有受支持数据源的 SQL 抽象，执行分布式查询，并包括监控和可观察性。Presto 支持客户端库为 Go、 <sup>[25](#Fn25)</sup> C、 <sup>[26](#Fn26)</sup> Java、 <sup>[27](#Fn27)</sup> Node.js、 <sup>[28](#Fn28)</sup> PHP、 <sup>[29](#Fn29)</sup> Ruby、 <sup>[30](#Fn30)</sup> R、<sup>[31【T31](#Fn31)[32](#Fn32)</sup> 越来越多的基于 web 的 GUI 客户端、可视化和仪表板应用程序支持 Presto，包括 Apache Airflow 的创建者提供的新商业智能应用程序 Apache Superset(见图 [8-6](#Fig6) )。

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig6_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig6_HTML.jpg)

图 8-6

Apache 超集(图片来自 [https://超集。阿帕奇。组织](https://superset.apache.org)

#### 库比涅斯配置

本章在 Kubernetes 中使用一个稳定的开源 Helm chart by When I Work Data 安装了一个带有两个 workers 和一个协调器的 Presto 集群。 <sup>[33](#Fn33)</sup>

创建目录`cluster-apk8s-dev5/003-data/095-presto`来包含 Presto Helm 配置和文档。接下来，用清单 [8-13](#PC42) 中的内容创建一个名为`values.yml`的文件。此外，创建一个名为`README.md`的文件来记录下一步执行的舵命令。

在 Presto 中，一个目录代表一个顶级数据源。请注意在 Helm chart configuration values . yml 的 catalog 部分中定义的四个数据源(称为连接器)。前两个数据源`obj.properties`和`hive.properties`使用 hive-hadoop2 连接器。Presto 使用 Hive 访问包含在 HDFS 或 S3 的数据文件(对象),并使用 Hive Metastore 服务访问表示数据文件的元数据和模式。`hive.properties`配置演示了定制 Apache Hive 容器(安装在前面的小节中)在 MySQL 支持的 Metastore 服务中的使用。此外，`cassandra.properties`和`mysql.properties`展示了本章配置的 MySQL 和 Apache Cassandra 的连接。

```
presto:
  environment: "production"
  workers: 2
  logLevel: "INFO"

image:
  repository: "wiwdata/presto"
  tag: "0.217"
  pullPolicy: "IfNotPresent"

service:
  type: ClusterIP

catalog:
  obj.properties: |
    connector.name=hive-hadoop2
    hive.metastore=file
    hive.metastore.catalog.dir=s3://metastore/
    hive.allow-drop-table=true
    hive.s3.aws-access-key= miniobucketuserid
    hive.s3.aws-secret-key= miniobucketuserpassword
    hive.s3.endpoint=http://minio:9000
    hive.s3.path-style-access=true
    hive.s3.ssl.enabled=false
    hive.s3select-pushdown.enabled=true

  hive.properties: |
    connector.name=hive-hadoop2
    hive.metastore.uri=thrift://hive:9083
    hive.allow-drop-table=true
    hive.s3.aws-access-key= miniobucketuserid
    hive.s3.aws-secret-key= miniobucketuserpassword
    hive.s3.endpoint=http://minio:9000
    hive.s3.path-style-access=true
    hive.s3.ssl.enabled=false

  cassandra.properties: |
    connector.name=cassandra
    cassandra.contact-points=cassandra-data-r1-0,cassandra-data-r1-1,cassandra-data-r1-2

  mysql.properties: |
    connector.name=mysql
    connection-url=jdbc:mysql://mysql:3306
    connection-user= root
    connection-password= mysqlrootpassword

coordinatorConfigs: {}
workerConfigs: {}
environmentVariables: {}
coordinatorResources: {}
workerResources: {}
coordinatorNodeSelector: {}
workerNodeSelector: {}
coordinatorTolerations: []
workerTolerations: {}
coordinatorAffinity: {}
workerAffinity: {}

Listing 8-13Presto Helm configuration

```

接下来，克隆 Presto 舵图表库:

```
$ git clone git@github.com:apk8s/presto-chart.git

```

Note

GitHub 存储库 apk8s/presto-chart<sup>[34](#Fn34)</sup>从 wiwdata/presto-chart 派生而来，包含与 Kubernetes 1.16+兼容所需的微小更新。有关未来版本或与 Kubernetes 旧版本的兼容性，请参考上游存储库。

通过应用前面的 Helm chart 克隆，以及来自`values.yml`的自定义配置，创建一个新的 Presto 集群:

```
$ helm upgrade --install presto-data \
  --namespace data \
  --values values.yml \
  ./presto-chart/presto

```

一旦 Helm 完成安装过程，Kubernetes 集群就包含两个 Presto worker 节点和一个 Presto 协调器。

最后，添加一个由 Helm chart 生成的新`presto-data:80`服务支持的 Kubernetes 入口配置。下面的入口使用在第 [5 章](05.html)的“数据名称空间”部分设置的秘密`sysop-basic-auth`来添加简单的基本认证安全性。从清单 [8-14](#PC45) 中创建一个名为`50-ingress.yml`的文件。

```
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: presto
  namespace: data
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-production
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: sysop-basic-auth
    nginx.ingress.kubernetes.io/auth-realm: "Authentication Required"
spec:
  rules:
    - host: presto.data.dev5.apk8s.dev
      http:
        paths:
          - backend:
              serviceName: presto-data
              servicePort: 80
            path: /
  tls:
    - hosts:
        - presto.data.dev5.apk8s.dev
      secretName: presto-data-production-tls

Listing 8-14Presto Ingress

```

应用预存储入口配置:

```
$ kubectl apply -f 50-ingress.yml

```

下一节将演示如何使用 presto-python-client 库从 Jupyter 笔记本中连接到 Presto。

#### 询问

本节使用运行在 Kubernetes 集群中的基于 Python 的 Jupyter 笔记本演示了与 Presto 的交互(参见第 [6](06.html) 章)。

从 JupyterLab 环境启动一个新的 Python 3 笔记本，在各个单元格中添加并执行以下代码。从第一个单元开始，使用`pip`安装`presto-python-client`库:

```
!pip install presto-python-client==0.7.0

```

导入`prestodb`(从包`presto-python-client`)、`os`、`pandas` Python 库；创建一个新的用于执行命令的 Presto 数据库连接对象和光标，如图 [8-7](#Fig7) 所示。执行命令`SHOW CATALOGS`显示四个数据源，`cassandra`、`hive`、`mysql`和`obj`在前面章节中配置。`system`目录包含预先存储的内部配置和运行数据。

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig7_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig7_HTML.jpg)

图 8-7

木星笔记本执行显示目录 presto 命令

查询`system`目录中的 Presto 节点列表，如图 [8-8](#Fig8) 所示。将 select 语句的结果与列名一起加载到 Pandas<sup>[35](#Fn35)</sup>data frame<sup>[36](#Fn36)</sup>中，为管理和显示结果集提供了一个用户界面。在执行分析和数据科学活动时，这种方法变得特别有用。Pandas 通常是 Python 数据库的核心组件，包含许多强大的数据转换和数学运算功能。

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig8_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig8_HTML.jpg)

图 8-8

检索预先存储的节点列表

描述上一节中用 Apache Hive 配置的`donors`模式，如图 [8-9](#Fig9) 所示。Hive 和 Presto 完全抽象出`donors`数据集的位置和底层数据结构，在本章前面生成并上传了一千个 CSV 文件到`exports`桶。

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig9_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig9_HTML.jpg)

图 8-9

用 Presto 描述表格

图 [8-10](#Fig10) 描述了一个 SQL select 语句，该语句利用 Presto 扫描所有一千个 CSV 文件，查找其中`state`列的值以“新”开始的记录，并通过`state`和`blood_type`对记录进行分组，每组记录的计数。

Presto 提供了一个成熟的、文档完善的、功能全面的 SQL 接口以及几十个函数和操作符。利用 Presto 进行初始数据分析、应用数学函数和运算符、聚合等，通过利用 Presto 的分布式执行引擎来执行这些密集型任务，尤其是处理大量数据，消除了应用程序的操作复杂性。

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig10_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig10_HTML.jpg)

图 8-10

Presto 中的 SQL select 语句

连接不同的数据集是 Presto 的一个基本特性，也是数据仓库的核心概念。作为读者的一个练习，创建数据或将数据导入到 Apache Cassandra 或 MySQL 中，这些数据与前面使用的样本提供者数据相关。一个典型的 SQL 连接可能类似于图[8-11](#Fig11)；在这个例子中，名为 appointment 的 Cassandra 表存在于 Keyspace lab 中，表示约会数据。

图 [8-11](#Fig11) :使用 Presto 来 SQL 连接 Hive 和 Cassandra 数据集的示例。

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig11_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig11_HTML.jpg)

图 8-11

在 Presto 中的 SQL 连接语句

跨各种数据源连接大型数据集并对其执行操作会创建复杂的执行计划。Presto 为探索、监控和调试查询提供了一个直观的基于 web 的用户界面。上一节定义的入口配置在 [`https://presto.data.dev5.apk8s.dev`](https://presto.data.dev5.apk8s.dev) 展示 Presto UI，如图 [8-12](#Fig12) 所示。

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig12_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig12_HTML.jpg)

图 8-12

在 Presto 中的 SQL 连接语句

监控和可观察性对于大数据和网络规模的数据操作都至关重要。Presto web 用户界面支持深入每个查询，提供查询细节，包括资源利用、时间表、错误信息、阶段和与执行相关的任务。此外，Presto 提供了一个实时计划，如图 [8-13](#Fig13) 所示，通过网络图实时描绘了阶段之间的执行流程。

![../images/483120_1_En_8_Chapter/483120_1_En_8_Fig13_HTML.jpg](../images/483120_1_En_8_Chapter/483120_1_En_8_Fig13_HTML.jpg)

图 8-13

在 Presto 中的 SQL 连接语句

Presto 是在 Kubernetes 内部构建现代数据仓库的综合解决方案；它对一系列数据源的支持符合物联网和机器学习不断增长的需求，提供了检索、合并、关联、转换和分析无限数量和结构的数据的能力。

## 摘要

这一章，连同第 6 章，展示了构建在 Kubernetes 之上的数据湖和数据仓库概念的小规模表示。像 Apache Hive 和 Presto 这样的技术帮助组织处理孤立的数据管理操作；在 Kubernetes 上运行这些解决方案，通过统一底层数据和控制平面，进一步降低了这些应用程序在逻辑和概念上的接近程度。

本章介绍了 MySQL 集群的安装，它代表了一个非常流行的 RDBMS，Apache Cassandra 作为大数据键/值存储，Hive 公开了无限的结构化和半结构化数据对象。虽然对于一系列以数据为中心的问题领域(从机器学习到物联网)有大量的专门应用，但这本书涵盖了一套通用而全面的数据(和事件)管理解决方案。如果按照前面的章节，清单 [8-15](#PC48) 代表了到目前为止基于 Kubernetes 的数据平台组件的当前组织的高级快照。

现在有了存储和检索几乎无限量和形式的数据的能力，下一章将通过扩展数据收集、路由、转换和处理的能力来扩展这个基于 Kubernetes 的数据平台。

```
./008-cluster-apk8s-dev5
  ├── 000-cluster
  │   ├── 00-ingress-nginx
  │   ├── 01-helm
  │   ├── 10-cert-manager
  │   ├── 20-rook-ceph
  │   ├── 22-minio
  │   ├── 23-rook-cassandra
  │   ├── 25-mysql-operator
  │   └── 30-monitoring
  ├── 003-data
  │   ├── 000-namespace
  │   ├── 005-keycloak
  │   ├── 010-zookeeper
  │   ├── 020-kafka
  │   ├── 030-elasticsearch
  │   ├── 032-logstash
  │   ├── 034-kibana
  │   ├── 050-mqtt
  │   ├── 060-cassandra
  │   ├── 070-minio
  │   ├── 080-mysql
  │   ├── 085-hive
  │   ├── 095-presto
  │   └── 100-jupyterhub
  └── 005-data-lab
      └── 000-namespace

Listing 8-15Organization of Kubernetes-based data platform components

```

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

[T2`https://delta.io/`](https://delta.io/)

  [2](#Fn2_source)

[T2`https://kylo.io/`](https://kylo.io/)

  [3](#Fn3_source)

斯卡利、加里·霍尔特、丹尼尔·戈洛文、尤金·达维多夫、托德·菲利普斯、迪特马尔·埃布纳、维奈·乔杜里、迈克尔·杨、让-弗朗索瓦·克雷斯波和丹·丹尼森。“机器学习系统中隐藏的技术债务。”《神经信息处理系统的进展》28，c .科尔特斯、N. D .劳伦斯、D. D .李、m .杉山和 r .加内特编辑，2503–2511。柯伦联合公司，2015 年。 [`http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf`](http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf) 。

  [4](#Fn4_source)

[T2`https://landscape.cncf.io/`](https://landscape.cncf.io/)

  [5](#Fn5_source)

[T2`www.mysql.com/`](http://www.mysql.com/)

  [6](#Fn6_source)

[T2`https://cassandra.apache.org/`](https://cassandra.apache.org/)

  [7](#Fn7_source)

[T2`https://hive.apache.org/`](https://hive.apache.org/)

  [8](#Fn8_source)

[T2`https://prestodb.io/`](https://prestodb.io/)

  [9](#Fn9_source)

[T2`https://insights.stackoverflow.com/survey/2019#technology-_-databases`](https://insights.stackoverflow.com/survey/2019%2523technology-_-databases)

  [10](#Fn10_source)

[T2`www.drupal.org/`](http://www.drupal.org/)

  [11](#Fn11_source)

[T2`https://wordpress.com/activity/`](https://wordpress.com/activity/)

  [12](#Fn12_source)

[T2`https://github.com/presslabs/mysql-operator`](https://github.com/presslabs/mysql-operator)

  [13](#Fn13_source)

[T2`https://github.com/github/orchestrator`](https://github.com/github/orchestrator)

  [14](#Fn14_source)

[T2`https://rook.io/`](https://rook.io/)

  [15](#Fn15_source)

[T2`https://rook.io/docs/rook/v1.2/cassandra-cluster-crd.html`](https://rook.io/docs/rook/v1.2/cassandra-cluster-crd.html)

  [16](#Fn16_source)

[T2`www.scylladb.com/`](http://www.scylladb.com/)

  [17](#Fn17_source)

[T2`www.youtube.com/watch?v=Idu9OKnAOis`](http://www.youtube.com/watch%253Fv%253DIdu9OKnAOis)

  [18](#Fn18_source)

[T2`https://technology.finra.org/opensource.html#bigdata`](https://technology.finra.org/opensource.html%2523bigdata)

  [19](#Fn19_source)

[T2`https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hive.html`](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hive.html)

  [20](#Fn20_source)

[T2`https://github.com/apk8s/hive`](https://github.com/apk8s/hive)

  [21](#Fn21_source)

[T2`https://cwiki.apache.org/confluence/display/Hive/AdminManual+Metastore+3.0+Administration`](https://cwiki.apache.org/confluence/display/Hive/AdminManual%252BMetastore%252B3.0%252BAdministration)

  [22](#Fn22_source)

[T2`www.gnu.org/software/bash/manual/`](http://www.gnu.org/software/bash/manual/)

  [23](#Fn23_source)

[T2`https://docs.docker.com/compose/`](https://docs.docker.com/compose/)

  [24](#Fn24_source)

[`www.batey.info/cassandra-anti-pattern-distributed.html`](http://www.batey.info/cassandra-anti-pattern-distributed.html) ，

[T2`www.slideshare.net/chbatey/webinar-cassandra-antipatterns-45996021`](http://www.slideshare.net/chbatey/webinar-cassandra-antipatterns-45996021)

  [25](#Fn25_source)

[T2`https://github.com/prestodb/presto-go-client`](https://github.com/prestodb/presto-go-client)

  [26](#Fn26_source)

[T2`https://github.com/easydatawarehousing/prestoclient/tree/master/C`](https://github.com/easydatawarehousing/prestoclient/tree/master/C)

  [27](#Fn27_source)

[T2`https://prestodb.io/docs/current/installation/jdbc.html`](https://prestodb.io/docs/current/installation/jdbc.html)

  [28](#Fn28_source)

[T2`https://github.com/tagomoris/presto-client-node`](https://github.com/tagomoris/presto-client-node)

  [29](#Fn29_source)

[T2`https://github.com/Xtendsys-labs/PhpPrestoClient`](https://github.com/Xtendsys-labs/PhpPrestoClient)

  [30](#Fn30_source)

[T2`https://github.com/treasure-data/presto-client-ruby`](https://github.com/treasure-data/presto-client-ruby)

  [31](#Fn31_source)

[T2`https://github.com/prestodb/RPresto`](https://github.com/prestodb/RPresto)

  [32](#Fn32_source)

[T2`https://github.com/prestodb/presto-python-client`](https://github.com/prestodb/presto-python-client)

  [33](#Fn33_source)

[T2`https://github.com/wiwdata/presto-chart`](https://github.com/wiwdata/presto-chart)

  [34](#Fn34_source)

[T2`https://github.com/apk8s/presto-chart`](https://github.com/apk8s/presto-chart)

  [35](#Fn35_source)

[T2`https://pandas.pydata.org/`](https://pandas.pydata.org/)

  [36](#Fn36_source)

[T2`https://pandas.pydata.org/pandas-docs/stable/reference/frame.html`](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)

 </aside>