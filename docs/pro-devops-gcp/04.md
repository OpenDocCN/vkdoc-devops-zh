# 四、Docker和 Kubernetes 容器化

今天，当我们想到云时，我们会想到容器化。容器化可以被看作是虚拟化的发展。借助虚拟化，我们通常会重新创建一个完整的操作系统(OS ),并将其托管在主机上。

使用一个容器软件，比如 Docker，可以创建我们应用的完整映像，并通过公共注册表发布。为了管理和发布这个映像，我们可以使用称为容器编排器的软件，比如 Kubernetes。

当我们采用 CI 和 CD 的实践时，使用 Docker 之类的容器和 Kubernetes 之类的 orchestrators 有助于加速自动发布过程，同时，我们可以有一个强大的回滚策略。

## Docker 简介

Docker 可能是最著名的容器化软件。它提供了一个称为*操作系统级虚拟化*的虚拟化级别。这就是所谓的容器化。

这种类型的隔离允许我们在一个操作系统中运行多个操作系统。例如，可以用 Red Hat 在 Ubuntu Linux 中创建一个容器。容器和虚拟机(VM)之间有一个重要的区别，那就是容器不需要完整的操作系统来运行。当我们创建一个虚拟机时，我们实际上是重新创建一个完整的操作系统。当我们创建一个容器时，我们得到的只是操作系统的一部分。这将缩小映像的大小。当我们谈论虚拟化时，我们可以识别两种类型:*基于虚拟机管理程序的虚拟化*和*操作系统虚拟化*。在基于虚拟机管理程序的虚拟化中，系统模拟硬件。这意味着我们可以重新创建网络、硬盘驱动器(HDD)等。在操作系统虚拟化中，虚拟化是在操作系统级别进行的。主机将每个容器彼此隔离，特别是，主机隔离每个容器的文件系统，但是它们在单个主机中运行。因为容器具有文件系统隔离的 OS，所以容器失去了灵活性。您只能在同一主机上运行容器。例如，不可能在 Linux 主机上运行 Windows，因为操作系统虚拟化是由系统运行的。Windows 和 Linux 有两种不同的操作系统内核和文件系统结构，这不允许 Windows 在 Linux 上运行。

与虚拟机管理程序虚拟化相比，容器的安全性较低。这是因为当我们创建一个 Linux 容器时，我们使用 libcontainers。这些访问五个基本的名称空间——网络、进程、挂载、主机名和共享内存——但是，例如，不使用 SELinux、cgroups 和其他用于增强操作系统安全性的库。这意味着恶意软件阻止执行和操作的可能性更大。相反，容器是一个孤立的环境。这意味着在容器被破坏的情况下，不太可能在主机系统上产生问题，因为容器不与主机操作系统共享任何东西。

Docker 容器创建复杂，难以维护和自动化。Docker 本质上是一款基于系统操作虚拟化的软件，旨在创建其他软件。Docker 在虚拟化容器的顶部添加了一个应用部署。使用 Docker，很容易创建一个类似于生产环境的完整的运行时环境，这可以加快开发过程。

Docker 帮助开发人员消除软件在生产中开发和发布时可能产生的差异。这是因为当我们在生产中发布软件时，Docker 容器在用于开发软件的相同 OS 配置中工作。

使用 Docker，我们可以轻松地为 CI 和 CD 创建我们的流程，因为当我们提交代码时，我们可以直接创建和编译 Docker 映像，并在测试中发布它。

从架构的角度来看，使用 Docker，很容易实现微服务架构。这是因为任何容器都可以是应用的一个部分，我们可以独立于另一个部分来管理这个部分。

Docker 由以下不同的组件组成:

*   Docker 引擎是一个客户端-服务器应用。客户端与服务器应用(称为守护程序)进行通信。守护进程负责执行容器。客户端和守护程序可以在同一台机器上，也可以在不同的机器上。

*   *映像*是我们 Docker 架构的基础。映像用于启动我们的容器，我们可以从另一个基本映像开始创建个人映像。

*   *注册表*是存储映像的地方。我们可以识别两种类型的注册中心:私有的和公共的。可以通过地址 [`https://hub.docker.com`](https://hub.docker.com) 联系公共注册表。这是官方的 Docker Hub 注册表。在这里，我们可以创建一个帐户，并开始在注册表中存储我们的映像。

*   *容器*基本上是一个被执行的映像。一个容器内部可以有多个正在运行的进程，这取决于映像的设计和创建方式。容器本质上是一个轻量级的独立应用。我们可以组合多个容器来执行一个复杂的应用。

### 为什么要用 Docker？

Docker 越来越受云的欢迎，因为当我们必须构建 PaaS 云时，它非常有用。原因很简单。容器的概念允许我们创建一层不同的隔离容器，其中包含一个应用。我们可以轻松构建特定于单个客户的 PaaS。这允许在与我们的 PaaS 设计的发布相关的所有方面有很大的灵活性。

Docker 还可以用于

*   为开发人员创建一个类似于生产环境的环境。Docker 可以拥有与生产中使用的相同的软件栈。

*   创建面向服务或微服务架构的构建块。使用 Docker，我们可以轻松地隔离应用，并使用它来构建我们的微服务或面向服务的架构(SOA)。

*   创建 CI 和 CD 系统。我们可以使用 Docker 来隔离应用，并在测试环境甚至生产环境中轻松部署。

*   为测试和实验创建独立的轻量级应用环境。

这些只是采用 Docker 的几个例子。越来越多的公司采用 Docker 来加速发布或部署过程。现代集成开发环境，如 Visual Studio 或 IntelliJ，现在有一个插件来“dockerize”我们的应用。这使得开发人员每次构建软件时都可以轻松地创建 Docker 映像。

## 在 GCP中使用 Docker

学东西最好的方法就是把手弄脏，所以在谷歌云平台(GCP)学习 Docker 最好的方法就是使用它。

有了 Docker，我们可以创建我们的 SaaS 和 IaaS，因为我们可以用它来提供我们的基础设施。这是因为我们可以创建一个容器，例如，为我们的数据库，和我们的应用，例如，我们的基于 Java 或 Ruby 的网站。在 GCP，我们可以使用谷歌计算引擎创建 Docker 容器。首先，要理解如何创建和使用 Docker，理解它是什么以及如何在 Compute Engine 中创建实例是很重要的。

### 谷歌计算引擎简介

谷歌计算引擎是 GCP 提供的 IaaS 组件。Google 计算引擎由三个基本组件组成:

*   虚拟计算机

*   电路的组成部分

*   永久磁盘

使用 Google Compute Engine，我们可以创建一个工作流，用于从单个实例扩展到全球分布式实例。当我们创建 Google 计算引擎时，我们可以选择 CPU、内存和空间方面的任何配置。谷歌计算引擎也使得使用预定义的实例成为可能。这些是

*   *标准*:这种机器每个 CPU 3.75 GB 内存。我们可以选择多达 8 种处理器配置，从 1 到 96。我们可以使用的永久磁盘的最大数量是 16 个。这种配置非常适合需要在 CPU 和内存之间取得良好平衡的任务。

*   *高内存*:这种配置每个 CPU 6.5 GB 内存。我们可以选择最少 2 个 CPU，最多 96 个。我们可以使用的永久磁盘的最大数量是 16 个。当需要比 CPU 更多的内存时，这种配置是理想的。

*   *高 CPU* :这种配置每个 CPU 有 0.90GB 内存。我们可以选择最少 2 个 CPU，最多 96 个。我们可以使用的永久磁盘的最大数量是 16 个。当需要比内存更多的 CPU 时，这种配置是理想的。

### 注意

当我们在计算引擎中创建新的持久磁盘时，有一些限制。永久磁盘的最大大小为 64TB。如果我们必须创建一个更大的磁盘，我们必须创建一个持久磁盘集群。每个实例最多可以连接 16 个磁盘。有一个测试功能，例如，在持久磁盘的限制可以连接到每个实例。对于共享核心，只能连接 16 个实例。对于 1 个 CPU，最多可以连接 32 个磁盘。对于 2 到 4 个 CPU，最多可以连接 64 个磁盘。对于 8 个或更多 CPU，最多可以连接 128 个磁盘。

Google 计算引擎的核心组件是一个*实例*。这是一个托管在谷歌基础设施上的虚拟机。

可以在 Windows 服务器上创建 Google 提供的基于 Linux 的实例，也可以通过运行 Docker 映像来创建或导入自定义映像。在这种情况下，Google 为运行 Docker 映像提供了一个优化的操作系统。这个操作系统基于 Chromium 操作系统。

### 创建计算引擎实例

要创建一个新的计算引擎，我们可以通过命令`gcloud compute`使用 Google SDK，也可以使用控制台。要创建实例，我们必须遵循以下两个步骤:

1.  配置`gcloud`。

2.  选择地区和区域。

第一步，配置`gcloud`，创建 OAuth2 来验证和访问资源。要使用`gcloud` compute，首先我们必须配置 Google SDK 来创建授权所需的令牌。

为了配置 Google SDK，我们必须打开命令行，使用命令`gcloud init`。这使用默认配置，并且适用于大多数配置。打开 Google SDK 并运行命令`gcloud init`，它会给出以下输出:

```
Welcome! This command will take you through the configuration of gcloud.

Settings from your current configuration [default] are:
core:
  account: pierluigi.riti@gmail.com
  disable_usage_reporting: 'False'
  project: practicaldevopsgcp-197023

Pick configuration to use:
 [1] Re-initialize this configuration [default] with new settings
 [2] Create a new configuration
Please enter your numeric choice:

```

在这种情况下，选择数字 1，然后按 Enter 键。我们需要这个额外的输出:

```
Your current configuration has been set to [default]

You can skip diagnostics next time by using the following flag:
  gcloud init --skip-diagnostics

Network diagnostic detects and fixes local network connection issues.
Checking network connection...done.
Reachability Check passed.
Network diagnostic (1/1 checks) passed.

Choose the account you would like to use to perform operations for
this configuration:
 [1] pierluigi.riti@gmail.com
 [2] Log in with a new account
Please enter your numeric choice:

```

选择我们要用于配置 Google SDK 的邮件。我们可以使用登录时的用户身份或登录新帐户。

```
You are logged in as: [pierluigi.riti@gmail.com].

Pick cloud project to use:
 [1] practicaldevopsgcp-197023
 [2] Create a new project
Please enter numeric choice or text value (must exactly match list
item):

```

选择我们要使用的项目或创建一个新项目。在这种情况下，创建一个新的，名为`practicaldevopsgcpcli`。要创建它，请选择选项 2，它将给出如下所示的输出:

```
Please enter numeric choice or text value (must exactly match list
item):  2

Enter a Project ID. Note that a Project ID CANNOT be changed later.
Project IDs must be 6-30 characters (lowercase ASCII, digits, or
hyphens) in length and start with a lowercase letter.

```

插入实例的名称，然后按 Enter 键。

```
Your current project has been set to: [practicaldevopsgcpcli].

Not setting default zone/region (this feature makes it easier to use
[gcloud compute] by setting an appropriate default value for the
--zone and --region flag).
See https://cloud.google.com/compute/docs/gcloud-compute section on how to set
default compute region and zone manually. If you would like [gcloud init] to be
able to do this for you the next time you run it, make sure the
Compute Engine API is enabled for your project on the
https://console.developers.google.com/apis page.

Your Google Cloud SDK is configured and ready to use!

* Commands that require authentication will use pierluigi.riti@gmail.com by default
* Commands will reference project `practicaldevopsgcpcli` by default
Run `gcloud help config` to learn how to change individual settings

This gcloud configuration is called [default]. You can create additional configurations if you work with multiple accounts and/or projects.
Run `gcloud topic configurations` to learn more.

Some things to try next:

* Run `gcloud --help` to see the Cloud Platform services you can interact with. And run `gcloud help COMMAND` to get help on any gcloud command.
* Run `gcloud topic -h` to learn about advanced features of the SDK like arg files and output formatting

```

最后，我们可以登录控制台，在选择项目的部分，我们可以看到创建的新项目(图 [4-1](#Fig1) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig1_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig1_HTML.jpg)

图 4-1

用命令行创建的新项目

该命令用于创建新项目。现在我们已经设置了项目，下一步是创建新的实例。因为我们有两个项目，所以我们必须设置默认项目。

```
gcloud config set project practicaldevopsgcpcli
Updated property [core/project].

```

这将主项目配置为我们刚刚创建的新项目。要使用命令行，我们必须为项目启用 API。对于链接，只需在控制台上创建以下命令:

```
gcloud compute instances create example-instance --zone us-centra1-f

```

因为没有启用 API，所以输出为

```
ERROR: (gcloud.compute.instances.create) Could not fetch resource:
 - Project 377223342623 is not found and cannot be used for API calls. If it is recently created, enable Compute Engine API by visiting https://console.developers.google.com/apis/api/compute.googleapis.com/overview?project=377223342623 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.

```

要启用 API，只需获取链接并将其放入浏览器，然后启用 API。当 API 启用时，控制台显示如图 [4-2](#Fig2) 的选项。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig2_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig2_HTML.jpg)

图 4-2

用于创建新计算引擎的控制台

我们最终可以使用`gcloud`命令创建实例。

```
gcloud compute instances create practicaldevopsgcp --zone us-east1-b

```

输出是

```
Created [https://www.googleapis.com/compute/v1/projects/practicaldevopsgcpcli/zones/us-east1-b/instances/practicaldevopsgcp].
NAME                ZONE        MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP   STATUS
practicaldevopsgcp  us-east1-b  n1-standard-1               10.142.0.2   35.227.53.98  RUNNING

```

这个实例终于被激活了。结果显示了具有内部和外部 IP 的实例的访问信息。可以检查在控制台中创建的实例。只需连接到仪表板并查看新实例(参见图 [4-3](#Fig3) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig3_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig3_HTML.jpg)

图 4-3

可以看到计算引擎使用的仪表板

为了连接到我们刚刚创建的实例，我们必须转到计算引擎仪表板。在“连接”列下，选择连接到新浏览器。这将在新页面中打开连接(图 [4-4](#Fig4) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig4_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig4_HTML.jpg)

图 4-4

选择打开实例上的连接

选择在浏览器窗口中打开，在另一个浏览器窗口中打开连接(图 [4-5](#Fig5) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig5_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig5_HTML.jpg)

图 4-5

我们实例上的连接在另一个浏览器中打开

我们刚刚完成了一审。默认情况下，基本实例是用 Debian Linux 创建的。我们可以在系统中安装 Docker，或者简单地使用 Docker 的特定映像创建一个不同的实例。谷歌为 Docker 设计了四种预建映像。

*   *谷歌的容器优化操作系统*:这是基于 Chromium 操作系统项目直接创建的谷歌映像。这个映像包括 Docker 和 Kubernetes。映像项目为`cos-cloud`，映像族为`cos-stable`。

*   *CoreOS* :这是一款基于 Linux 的操作系统，专为容器化设计。它包括 Docker、rkt 和 Kubernetes。映像项目叫`coreos-cloud`，映像族叫`coreos-stable`。

*   *Ubuntu* :这是一张基于 Ubuntu 版本 16.04 LTS 的图片，包括 LXD。映像项目为`ubuntu-os-cloud`，映像族为`ubuntu-1604-lts`。

*   *Windows* :这是 Windows 按照容器化设计的核心版本，包括 Docker。映像项目为`windows-cloud`，映像族为`windows-1709-core-for-containers`。

因为我们想为我们的系统创建一个 Docker 映像，所以我们现在基于其中一个 Docker 映像创建一个新实例。

### 实例组

在计算引擎中，我们可以创建一个命名的虚拟机组。当我们创建一组实例时，我们可以同时管理所有的实例。我们可以创建两种类型的实例组:*托管的*和*非托管的*。

当我们创建一个托管实例组时，我们使用一个*实例模板*。这用于创建一组相同的实例。使用托管实例，我们可以将所有实例作为一个实例来管理，这意味着当我们修改实例模板时，我们同时修改了所有实例。托管实例组有几个好处。

*   *自动扩展*:当应用需要更多资源时，我们可以扩展实例以适应新的需求。

*   *负载均衡*:因为所有的实例都作为一个整体来管理，所以资源在实例之间共享和平衡。当然，我们必须在此基础上创建负载均衡器以确保功能性。

*   *不健康实例的管理*:当组中的一个实例停止或崩溃时，它会自动重新创建，并与前一个实例同名。

有两种类型的托管实例:

*   *一个分区管理组*:所有实例都在同一个分区中。

*   *一个区域管理组*:所有实例都在同一个区域。

Google 建议使用一个区域性的管理小组，而不是一个地区小组，让应用分布在不同的地理区域。将应用分布在不同的地理位置可以降低故障风险，因为不同的地理区域可能会同时出现由自然灾害或人为错误导致的故障。因此，区域管理可以提高我们软件的可用性。

Google 不推荐非托管实例，它没有托管实例的任何好处。该组由不同的实例组成，只能使用负载均衡器。只有当有一些旧的实例，并且我们想在其上使用负载均衡器时，才能使用这种方法。

## GCP中的容器应用

容器可能是发布微服务并将其投入生产的最佳方式。为了在 GCP 创建一个容器，我们可以用一个容器优化的操作系统构建一个新的计算引擎。这是一个操作系统家族，针对计算引擎中的运行容器进行了优化。比如 CoreOS 就是操作系统之一。

### 注意

CoreOS 是基于 Linux 内核的轻量级操作系统，旨在为集群提供基础设施。CoreOS 有一个最小的命令集，可以自动化所有与容器应用相关的工作。使用 CoreOS，可以很容易地以编程方式部署和维护容器化的基础设施，并且因为它是基于集群的，所以我们可以确保我们的应用总是可访问的。

我们现在用 CoreOS 操作系统构建一个新的计算引擎，然后在其中创建一个容器。以下是在 GCP 创建容器应用的方法之一。

1.  连接到我们的 GCP实例并选择项目`practicaldevopsgcpcli`。

2.  Click the board Compute Engine, which opens the page to manage our Compute Engine instance (Figure [4-6](#Fig6)).

    ![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig6_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig6_HTML.jpg)

    图 4-6

    计算引擎板，摘自谷歌控制台仪表板

3.  这将打开我们的计算引擎页面。我们现在必须基于一个容器优化的操作系统创建一个新的实例。从工具栏中选择“创建实例”按钮。

4.  In the page for creating the instance, type the name *practicaldevopscontainerinstance* and check the Container box (Figure [4-7](#Fig7)). This changes the default OS from Debian to one that is container-optimized.

    ![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig7_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig7_HTML.jpg)

    图 4-7

    创建新的容器实例

5.  在容器映像文本框中，我们可以确定我们想要使用的 Docker 映像。对于我们的测试，我们可以使用 busybox 映像。在文本框中，我们必须插入以下字符串: [`gcr.io/google-containers`](https://console.cloud.google.com/gcr/images/google-containers/GLOBAL) `/busybox`。

### 注意

Google 为 Docker 容器提供了一个私有注册表。这个注册表可以用来存储我们的私有 Docker 映像和创建一个新的实例。通过此链接可以看到注册表中的所有映像: [`https://console.cloud.google.com/gcr/images/google-containers/GLOBAL`](https://console.cloud.google.com/gcr/images/google-containers/GLOBAL) 。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig8_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig8_HTML.jpg)

图 4-8

新实例是用 Docker 创建的

1.  单击 Create 按钮，然后使用 Docker 映像创建新的计算引擎实例(图 [4-8](#Fig8) )。

我们可以通过单击名称来访问新实例。这将打开实例的详细信息。然后向下滚动到远程访问并点击 SSH(图 [4-9](#Fig9) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig9_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig9_HTML.jpg)

图 4-9

远程访问选择

这将为带有 Docker 和我们的映像的实例打开新的浏览器窗口。我们可以看到实际安装的映像，命令为`docker images`。当我们在实例中执行命令时，我们得到如图 [4-10](#Fig10) 所示的输出。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig10_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig10_HTML.jpg)

图 4-10

Docker 映像命令输出

创建一个计算引擎实例，在其中创建我们的容器是一个很好的起点。Google 提供了一个私有注册中心，我们可以上传我们的图片到注册中心，并在我们的实例中使用。使用谷歌注册，我们可以把我们的 CI/CD 基本系统。例如，我们可以使用 Jenkins 创建映像并将其放入注册表中。

使用计算引擎实例来创建 Docker 映像确实有一些限制。

*   可以在 VM 中只部署一个容器。

*   只能使用优化的容器操作系统来创建实例。

在计算引擎中，也可以使用 Docker Hub 注册表中的映像；但是，虚拟机只能有一个容器。如果我们想设计一个微服务应用，我们可能需要在每个虚拟机上使用多个容器。为此，谷歌提供了另一项名为 Kubernetes Engine 的服务。

Kubernetes Engine 是部署和管理容器化应用的托管环境。该引擎运行 Kubernetes，这是一个旨在管理和扩展容器的开源平台。使用 Kubernetes 引擎允许使用多个容器。在开始创作之前，我们必须了解 Kubernetes 是什么。

## 什么是 Kubernetes？

Kubernetes，有时被称为 K8s，是由 Google 开发的开源平台，由云原生计算基金会管理。它用于管理和扩展集群中的容器化应用，如 Docker。

### 注意

Kubernetes 是一个非常复杂的应用。我可以用一整本书来讨论 Kubernetes，这不在本章的讨论范围之内。我只想简单介绍一下 Kubernetes 平台。

Kubernetes 定义了一些创建和管理资源的基本构件。所有组件都被设计成松散耦合的。Kubernetes 构建模块的第一个组件叫做 *pod* 。pod 是 Docker 容器的集合，所有容器都具有相同的 IP 地址。每个 pod 可以由一个或多个容器组成，托管在同一主机中并共享资源。每个 pod 与群集共享一个唯一的 IP 地址，并且可以通过 API 或控制器进行手动管理。

Kubernetes 中定义的另一个资源叫做*标签*。这些用于创建密钥对值以识别资源，例如 pod。标签没有提供任何独特性。在 Kubernetes 中，可以有多个同名的对象，并创建一个所谓的*标签选择器*，或*选择器*。

使用选择器，可以识别一组对象。选择器是 Kubernetes 中对对象进行分组的核心原语。实际上，当我们想要识别一个资源时，我们可以使用两种类型的选择符，基于等式的选择符和基于集合的选择符。标签选择器可以由多个需求组成，用逗号分隔。在这种情况下，必须满足所有要求。

基于集合的标签选择器用于允许过滤，使用根据一组值的键。选择器支持三种类型的运算符:`in`、`notin`和`exist`。例如，选择器可用于仅选择一种类型的资源，如环境=生产或层(在生产阶段)。

*控制器*用于管理集群的状态。为了改变集群的状态，控制器管理 pod。有三种控制器。

*   *复制控制器*:用于在 Kubernetes 集群中复制服务。复制控制器的另一个重要用途是在一个 pod 出现故障时启动新的 pod。它用于维持最少数量的节点运行，并确保集群的高可用性。

*   *DaemonSet 控制器*:当我们在集群中添加一个节点时，这个控制器负责确保所有节点运行一个 pod 的副本。此服务将 pod 添加到新节点。

*   *作业控制器*:用于运行一个 pod，直到部分或全部运行成功完成。它检查 pod 的状态，当某个数量完成时，作业会自行终止。

构建模块的最后一块是*服务*。在 Kubernetes 中，服务是一组协同工作的 pod。例如，我们可以创建一个包含完整微服务架构的 pod，并以此定义服务。服务由标签定义和标识。这有助于识别服务本身。使用 Kubernetes，可以通过服务发现来搜索服务，并使用 IP 地址或 DNS 名称来查找我们需要管理的服务。

### 注意

松耦合系统是这样设计和实现的，每个服务都不知道或很少知道其他服务的定义。这些服务只为它们之间交换的数据而相互识别，并且不知道该服务是如何实现的以及是否使用了另一个服务。

Kubernetes 是一个容器编排器，用于自动化容器化应用(例如 Docker)的部署、管理和伸缩。该容器在 pod 中定义。这提供了高层次的抽象，将容器化的应用分组。pod 是每个 Kubernetes 应用的基本构建块。POD帮助我们释放容器。我们可以释放容器，而不是一次释放一个容器。一个 pod 在定义中可以有多个容器，这有助于一次释放多个容器。

使用 Kubernetes，我们可以创建一个*集群*来管理系统。集群是一个集合节点。Kubernetes 集群有一个主节点和零个或多个工作节点。这意味着我们可以拥有一个只有一个主节点的 Kubernetes 集群。在 Kubernetes 中，节点是一台机器，可以在其中运行和调度 pod。机器可以是物理的，也可以是虚拟的。因为节点本质上是群集的基本块，所以每个节点都可以是主节点或工作节点。它只取决于我们为集群选择的配置。

Kubernetes 的关键组件之一是 *etcd* 。这是一个由 CoreOS 开发的轻量级分布式持久密钥库。该组件用于随时存储集群的状态。etcd 用于定义高可用性集群。

使用 Kubernetes 的原因可以从 DevOps 本身的性质中找到。当一家公司决定采用 DevOps 实践时，通过 Kubernetes，我们可以使用 Docker 更快地发布和部署我们的应用。

与此同时，Kubernetes 可以随着业务需要而发展。这是因为服务本身的可伸缩性。使用 Kubernetes，我们可以在集群中添加或删除一个节点，Kubernetes 负责管理我们的应用中的 pods。

## 使用 Kubernetes 引擎部署应用

Kubernetes 发动机在 GCP 提供了 K8s 的灵活性和动力。使用 Kubernetes 引擎，可以创建一个 Docker 容器集群来设计我们的微服务架构。现在您将看到如何使用 Kubernetes 引擎来创建和管理 Docker 容器和集群。

要访问 Kubernetes 引擎，我们必须安装另一个命令行:Kubernetes 命令行名为[](https://kubernetes.io/docs/user-guide/kubectl-overview/)*。这个命令行为我们提供了管理 Kubernetes 集群所需的命令。这个命令行内置在 Google Cloud Shell 中。我们可以直接从谷歌云控制台打开命令外壳。我们可以将这个控制台添加到我们的 Google SDK 中，如下所示:*

 *![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig11_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig11_HTML.jpg)

图 4-11

Kubernetes version 命令显示命令行的版本

1.  打开谷歌云 SDK。

2.  运行命令`gcloud components install kubectl`。这将开始下载并安装 Kubernetes 命令行工具。

3.  当安装完成时，我们可以使用命令`kubectl version`来验证所有的安装是否正确。该命令显示安装在 Kubernetes 命令行上的版本(图 [4-11](#Fig11) )。

可以使用谷歌控制台中的命令行。我们所要做的就是打开 GCP 控制台并点击控制台按钮。这将打开控制台底部的外壳(图 [4-12](#Fig12) )。我们可以使用相同的命令并看到相同的输出

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig12_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig12_HTML.jpg)

图 4-12

谷歌云外壳按钮

首先，要继续，我们必须确保`gcloud`配置了正确的项目 id 和区域。要设置项目 id，在我们的实例 practicaldevopsgcpcli 中，使用以下命令:

```
gcloud config set project practicaldevopsgcpcli

```

这个命令的输出是一个简单的行:`Updated property [core/project]`。这表明我们已经正确地更新了我们的项目。

我们需要更新的下一个属性是默认计算区域。这样，我们就可以准确地在我们想要的地方创建集群。为此，我们可以使用以下命令行:

```
gcloud config set compute/zone us-east1-b

```

这个命令的输出是一个简单的行:`Updated property [compute/zone]`。这表明我们已经正确更新了计算区域。

现在我们已经设置了区域和代码项目，我们可以开始创建我们的 Kubernetes 集群了。在 Kubernetes 中，一个集群至少是一台服务器。该节点实际上是计算引擎虚拟机，我们在其上运行 Kubernetes 流程，作为集群的一部分。第一步是在`gcloud`中创建集群。

```
gcloud container clusters create practicaldevopsgcpcluster

```

### 注意

我们第一次执行这个命令时会得到一个错误，因为我们没有配置 Kubernetes API。我们必须从以下链接进入: [`https://console.cloud.google.com/apis/api/container.googleapis.com/overview?project=practicaldevopsgcpcli`](https://console.cloud.google.com/apis/api/container.googleapis.com/overview?project=practicaldevopsgcpcli) 。

该命令开始创建 Kubernetes 集群，这可能需要几个小时才能完成。最后，我们可以在控制台中看到集群。操作的结果是一行，告诉我们集群可以使用了。我们可以导航到页面。默认集群默认有三个节点。节点中使用的映像是容器优化的操作系统。基本映像是由 Google 为容器创建的。机器的大小是 n1 标准，相当于 1 个 CPU，3.75GB 内存。这基本上足以满足 Kubernetes 的基本使用。

[T2`https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1b/practicaldevopsgcpcluster?project=practicaldevopsgcpcli`](https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1b/practicaldevopsgcpcluster?project=practicaldevopsgcpcli)

要查看我们集群的实例，如果所有完成的操作都是好的，您将看到类似图 [4-13](#Fig13) 的内容。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig13_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig13_HTML.jpg)

图 4-13

Kubernetes 引擎集群创建了

集群准备就绪后，我们需要做的是获取访问集群的凭证。要获取凭证，我们必须使用以下命令:

```
gcloud container clusters get-credentials practicaldevopsgcpcluster.

```

该命令的结果如下:

```
Fetching cluster endpoint and auth data.
kubeconfig entry generated for practicaldevopsgcpcluster.

```

我们现在准备好部署我们的集群了。对于我们的例子，我们使用一个 Google 就绪的应用。目前的目标是部署在 Kubernetes。这个应用叫做 hello-server，是一个简单的 Go 服务器应用。

### 部署我们的第一款 Kubernetes 应用

如您所见，Kubernetes 创建了一个集群，并允许我们从一个单点管理它。当我们在 Kubernetes 中创建集群时，我们部署在主节点上，而主节点部署在每个节点上。

这种行为由 etcd 管理。当主节点看到节点上的不同状态时，etcd 是用于记住集群状态的键值。节点中的守护进程安装应用并对齐每个节点。服务维护通常一次完成一个节点。这意味着当一个节点正在安装或更新时，另一个节点是可访问的。为了在集群中安装应用，我们可以使用`kubectl`命令行启动以下命令:

```
kubectl run hello-server --image gcr.io/google-samples/hello-app:1.0 --port 8080

```

这个命令非常简单，它采用服务器的名称、映像参数和发送到 Docker 的端口作为参数。操作的结果是一个简单的行:`deployment "hello-server" created`。我们可以在集群中看到新的服务器(图 [4-14](#Fig14) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig14_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig14_HTML.jpg)

图 4-14

带有 hello-server 应用的 Kubernetes 集群

花一些时间在命令行上分析参数是很有用的。参数`--image`用于指示我们希望在集群中部署的映像。该映像可以是来自 Docker Hub 的公共 get，也可以是来自 Google Repository 的。重要的是映像的版本。在 Docker 中，我们可以通过在`:`后添加值来标识映像的版本，例如`hello-app:1.0`表示映像`hello-app`的版本为 1.0。当我们为映像修复一个版本时，如果我们想要将 CI/CD 系统放在适当的位置，我们必须确保总是部署相同的映像版本。例如，我们可以将映像命名为 *stable* ，因为我们想要使用映像的最后一次构建。

使用特定的名称来标记我们的 Docker 映像有助于在生产中始终部署具有该名称的最后一个映像。当我们将映像发布到注册表时，Kubernetes 会检查该映像是否是最新的，并下载带有相同标记的映像进行安装。这意味着如果我们把一个新的稳定在注册表中，这是自动部署在我们的系统中。

我们现在已经部署了我们的应用，但是为了使它有用，它必须可以被其他用户访问。为了在互联网上公开我们的应用，我们必须配置一个负载均衡器。

负载均衡器用于平衡集群中的资源。当我们必须管理来自互联网的流量时，这是很重要的。因为 Kubernetes 创建了一个资源集群，所以通常使用集群来管理流量。在 Kubernetes 中，我们可以使用来自`kubectl`命令行的命令`kubectl expose`来公开集群。

```
kubectl expose deployment hello-server --type "LoadBalancer"

```

当我们添加参数`--type "LoadBalancer"`时，我们已经定义了负载均衡器。这将我们的服务公开给互联网，并配置一个负载均衡器来管理请求。如果我们想向外界公开服务，那么`LoadBalancer`命令是很重要的。`LoadBalancer`是在 GCP 创建的，并且在 IP 被分配给集群的外部 IP 之后。通过这种方式，可以连接到集群并显示服务运行。

使用外部 IP 将应用公开在互联网上。要查看 IP，我们必须查看有关我们群集的信息。我们可以通过使用命令`kubectl get service`来获取信息。这显示了关于我们在 Kubernetes 中指出的服务的信息。为了获得关于我们的应用的信息，我们使用以下命令:

```
kubectl get service hello-server

```

结果是一个显示服务信息的表格。

```
NAME          TYPE          CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE

hello-server  LoadBalancer  10.35.247.216  35.196.27.26  8080:32104/TCP 20m

```

### 注意

外部 IP 用于识别我们的应用。这将是不同的，取决于你的谷歌云配置。

我们可以看到我们的应用正在工作(图 [4-15](#Fig15) )。打开浏览器并点击以下链接:

`http://35.196.27.26:8080`

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig15_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig15_HTML.jpg)

图 4-15

实时 hello-server 应用

恭喜你！我们现在已经部署了我们的第一个 Kubernetes 应用。

#### 配置 Kubernetes 仪表板

到目前为止，我们已经看到了如何通过命令行使用 Kubernetes，但 Kubernetes 有一个令人惊叹的界面。要在 GCP 使用它，我们必须将其配置为在该平台上访问。

### 警告

对于新版本的 GCP，谷歌强烈建议你禁用经典的 Kubernetes 用户界面，而使用谷歌控制台仪表板。

通过安装和配置 Kubernetes，我们已经创建了一个集群。它有不同的基本组件，可以通过 HTTP/HTTPS 访问。我们可以使用以下命令查看有关群集的信息:

```
kubectl cluster-info

```

这向我们显示了关于集群的信息(图 [4-16](#Fig16) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig16_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig16_HTML.jpg)

图 4-16

Kubernetes 集群信息

要访问仪表板，我们需要点击以下链接:

`https://<kubernetes master ip>/api/v1/namespaces/kube-system/services/`https:kubricks 控制板:/proxy

如果我们试图访问 UI，我们会得到如图 [4-17](#Fig17) 所示的错误。这是因为我们还没有配置服务帐户来访问 Kubernetes 集群。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig17_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig17_HTML.jpg)

图 4-17

尝试访问 Kubernetes 用户界面时出现的错误

要访问 Kubernetes UI，我们必须为服务帐户配置身份和访问管理(IAM)。

### 注意

你将在第 9 章中了解更多关于我的信息。现在，您只需要知道如何配置 Kubernetes UI 所需的用户访问。

第一步是为用户获取密钥。为此，我们使用连接到命令行界面。我们只需使用控制台仪表板，转到 IAM & Admin 部分，然后从那里转到 Service Account 屏幕(参见图 [4-18](#Fig18) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig18_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig18_HTML.jpg)

图 4-18

Google 控制台上的服务帐户屏幕

现在我们可以看到，对于我们的项目，我们没有任何服务帐户的键。这产生了我们在尝试访问 Kubernetes UI 时看到的错误。首先，我们必须为帐户创建密钥，然后下载 JSON 格式的密钥，并使用它来配置对 Kubernetes UI 的访问。

要创建密钥，我们只需点击操作下的三个点，然后选择创建密钥菜单选项(参见图 [4-19](#Fig19) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig19_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig19_HTML.jpg)

图 4-19

用于创建新密钥的菜单

创建关键点打开一个新的模态窗口，从中选择我们想要创建的关键点类型。选择 JSON，然后单击创建。这将创建一个与我们的服务帐户相关联的新密钥。同时，密钥被下载到我们的电脑上。该密钥可用于在 Kubernetes 用户界面上配置访问权限(参见图 [4-20](#Fig20) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig20_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig20_HTML.jpg)

图 4-20

与服务帐户关联的密钥

有了创建并与我们的服务帐户关联的密钥，我们就可以为 Kubernetes UI 配置服务帐户访问。我们需要配置`gcloud`授权的命令如下:

```
gcloud auth activate-service-account practicaldevopsgcpcli@appspot.gserviceaccount.com --key-file=<path where we download the JSON key>

```

我们可以在 Cloud SDK 中执行该命令。命令的结果告诉我们，服务帐户现在已被激活(参见图 [4-21](#Fig21) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig21_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig21_HTML.jpg)

图 4-21

通过 Cloud SDK 激活服务帐户

现在，我们已经使用我们的服务帐户配置了对 Kubernetes 的访问。下一步是使用以下命令更新我们之前在 GCP 创建的集群，并使用我们新的服务帐户凭据进行更新:

```
gcloud container clusters get-credentials practicaldevopsgcpcluster  --zone us-east1-b --project practicaldevopsgcpcli

```

该命令在为集群生成的`kubeconfig`中添加一个新条目，并将服务帐户与集群相关联。要运行仪表板，首先我们必须看到集群中的所有 Kubernetes 服务。我们可以使用以下命令来实现这一点:

```
kubectl get secrets -n kube-system

```

### 注意

如果我们在运行`kubectl`命令时遇到错误，我们可以将它作为 Google Cloud SDK 的一部分进行安装。安装的命令是`gcloud components install kubectl`。这将在 SDK 上安装并下载 Kubernetes 命令行。

这显示了我们集群中的所有令牌。我们可以使用它来查看有关令牌的信息，我们需要这些信息来访问我们的仪表板(参见图 [4-22](#Fig22) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig22_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig22_HTML.jpg)

图 4-22

我们的 Kubernetes 集群中存在的 Kubernetes 令牌

要连接到 UI，我们必须有一个令牌。当我们需要进入 Kubernetes UI 时，使用这个令牌。我们可以使用以下命令获取令牌:

```
kubectl -n kube-system describe secret replicaset-controller-token-thsvx

```

请注意，`replicaset-controller-token`的值可能与您的配置不同，尤其是最后一部分。当我们运行这个命令时，我们可以看到如图 [4-23](#Fig23) 所示的输出。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig23_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig23_HTML.jpg)

图 4-23

用于访问仪表板的 Kubernetes 令牌

有了令牌，我们终于可以运行命令`kubectl proxy`。这将启动我们计算机上的服务器，并显示访问它的地址和端口。这通常是 127.0.0.1:8001。我们可以运行服务器并在浏览器中插入地址`localhost:8001/ui/`。这将执行 Kubernetes 仪表板，并询问我们如何在服务器上进行认证(参见图 [4-24](#Fig24) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig24_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig24_HTML.jpg)

图 4-24

Kubernetes 仪表板登录

我们可以插入之前获得的令牌，并使用它登录仪表板。仪表盘显示警告。这是因为每个服务都有不同的令牌。仪表板如图 [4-25](#Fig25) 所示。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig25_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig25_HTML.jpg)

图 4-25

Kubernetes的 UI

我们可以看到谷歌建议我们禁用经典的 Kubernetes UI，使用云控制台 UI。这是因为后者更好地集成到系统中。

#### 探索 Kubernetes 实例

当我们创建 Kubernetes 集群时，我们实际上创建了一个不同的计算引擎。我们可以在 Kubernetes 计算引擎仪表板中检查创建的实例(图 [4-26](#Fig26) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig26_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig26_HTML.jpg)

图 4-26

为管理集群而创建的 Kubernetes 计算引擎

我们可以识别实例，因为它们都是用前缀`gke-`创建的。我们可以通过单击实例来检查实例的详细信息。

使用控制台，可以探索集群的 Kubernetes 配置。如果我们打开控制台并检查 Kubernetes 计算引擎，我们可以看到关于集群的信息(图 [4-27](#Fig27) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig27_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig27_HTML.jpg)

图 4-27

Kubernetes 集群信息

我们可以看到，集群的最小值是三个节点。可以通过点击右侧的铅笔图标来更改聚类的值(图 [4-28](#Fig28) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig28_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig28_HTML.jpg)

图 4-28

Kubernetes 集群的节点池部分

可以在“节点池”部分管理群集的节点。在这一部分，我们可以配置集群的不同参数，例如，改变池中节点的数量。这是在大小值中配置的。我们可以通过在集群中添加更多节点来更改该值。例如，我们可以将该值更改为 5，并向群集中添加另外两个节点。在此部分中，可以为集群启用自动缩放。这将自动向集群添加和删除节点(图 [4-29](#Fig29) )。

![../images/464715_1_En_4_Chapter/464715_1_En_4_Fig29_HTML.jpg](../images/464715_1_En_4_Chapter/464715_1_En_4_Fig29_HTML.jpg)

图 4-29

新的计算引擎实例

#### 删除立方结构丛集

为了完成我们的 Kubernetes 之旅，我们必须了解如何摧毁我们的 Kubernetes 集群。有时，这对于维持公司成本或淘汰旧的基础架构是必要的。

我们可以删除 Kubernetes 集群，使用这个命令:`kubectl delete service hello-server`。这将删除 Kubernetes 负载均衡器。删除负载均衡器后，我们现在必须删除集群。删除集群的命令是`gcloud container clusters delete practicaldevopsgcpcluster`。这个命令销毁我们在 Google Cloud 中创建的集群，并要求确认删除集群。选择 Y 删除集群。

## 结论

使用容器对于加快上市时间非常重要，并且有很多好处。容器应用可用于复制开发生产环境。通过容器应用，我们可以实施 CI 和 CD 实践。本章简要介绍了 Kubernetes，并展示了如何在 GCP 配置经典的 Kubernetes UI。目的不是深入解释 Kubernetes。为此，我建议在 [`www.youtube.com/watch?v=GNj63thbiCM&t=222s`](http://www.youtube.com/watch?v=GNj63thbiCM%2526t=222s) 可以看到大卫·冈萨雷斯的演讲。它很好地介绍了 Kubernetes。

在 GCP，我们可以使用计算引擎以编程方式创建一个实例。计算引擎是用于容器应用和容器的虚拟机。管理容器的最佳方式是使用 Kubernetes 计算引擎。这样，就有可能创建一个带有特定操作系统的引擎集群来维护容器。在接下来的章节中，您将学习如何使用 Kubernetes 并将其与 CI 和 CD 实践相结合，以实现 DevOps 的原则。*