# 五、使用 Apache Kafka 发送消息

在前面的章节中，我们主要关注跨应用通信的同步方法的使用，更具体地说是 REST。尽管 REST(及其生态系统)的特性非常丰富，可以支持许多不同的用例，但它不像某些异步通信模式那样具有可伸缩性和弹性。同步通信要求后端能够立即响应客户端的调用，但是一些服务由于其复杂性可能需要更多的时间来响应，或者甚至可能依赖于其他服务，这可能会产生超时链，其中链中的一个服务可能会成为瓶颈并使请求开始失败。

在有状态与无状态的讨论中，由于无状态架构的许多好处，我们理想地尝试无状态，我们知道不是每个应用都是无状态的。对于一些必须同步执行的流程和服务也是如此。这个想法是为了理解异步通信是如何工作的，我们拥有哪些模式，以及我们如何实现它们。我们可以将反应式编程或事件驱动编程作为异步处理如何有益于应用性能的例子。这意味着没有一个组件需要等待另一个组件来完成它的任务，所以它可以不等待，而是执行别的事情。

在这一章中，我们将深入研究使用消息传递系统的异步通信。选择的工具是另一个 Apache 基金会项目，Apache Kafka。您将学习何时以及如何使用消息传递来使用异步通信，同时学习如何使用 Kafka 和 Camel 来实现它。

## 面向消息的中间件

面向消息的中间件(MOMs)是专门接收和发送消息格式的数据的系统。他们充当中间人的角色，保证从生产者那里接收到消息，并且该消息将是可用的，并被正确地传递给消费者。让我们来讨论一下这种系统是如何工作的，我们能从中得到什么。

在谈论妈妈之前，我们首先需要定义消息传递。谈论消息传递可能听起来有些多余，因为这个概念在我们的生活中非常普遍。电子邮件、短信应用，甚至邮政服务都可以作为消息传递的一个很好的类比，即*使用服务在实体之间传递消息*。消息传递的另一个特征是，生产者或消息发送者不需要等待消费者或消息接收者来确认它收到了消息。消息生产和消息消费的中介由中间件层完成。正是中间件层向生产者确认消息的传递，一旦有了它，该层就有了保证消息到达目的地的机制。这使得生产者无需等待消费者就可以执行其他任务，而消费者可以按照自己的节奏使用消息。

除了异步通信的特性之外，由于其模式，mom 的使用还允许其他可能性。我们可以强调的一点是使用 mom 如何提高服务的可组合性。

可组合性是一种设计原则，它分析服务如何相互连接，以创建可以服务于新用例的组合。为了阐明这意味着什么，让我们把这个概念放到一个真实的生活例子中。想想社交媒体。这一切都是从人们联系的方式开始的。你想知道你的家人怎么样，你的朋友在做什么，甚至想认识新的人。现在将它与现在的情况进行比较。它现在是一个公众人物的平台，从政治家到流行艺术家，在这里你可以买卖任何东西，观看现场音乐表演或体育比赛等活动。它在服务和容量方面增长如此之快，以至于我们觉得我们生活的方方面面都在那里得到了处理。这是可能的，因为人们的数据处理方式。当然，这是一个非常有说服力的例子，因为它带来的不仅仅是可组合性的概念，而是为了举例说明它的含义。

妈妈们通常使用目的地的概念，也就是消息被发送的地址。这个目的地并不存在于生产者或消费者中，而是消息传递系统或消息代理中的一个寄存器，这使得它成为一种通过促进解耦来提高可组合性的方法。生产者不知道谁在消费来自目的地的消息，消费者也不知道谁在发送消息。这样，如果生产者能够产生预期的数据，我们可以向目的地添加更多的生产者，或者如果数据与更多的应用相关，我们可以添加更多的消费者。注意，这种通信更多的是关于被交换的数据，而不是组件的关系。一个好的领域设计对于实现更好的可组合性是必不可少的。

目的地通常分为两种类型:队列和主题。我们单独讨论一下。

队列是通信通道的目的地，接收方通常是单个应用。它们就像电子邮件收件箱。他们可以接收来自任何人的消息，但只有电子邮件所有者能够访问这些信息。消息会一直留在队列中，直到被相应的接收者使用，或者直到“生存时间”等规则(根据消息在队列中的时间来清除消息)生效。你可以在图 [5-1](#Fig1) 中看到一个队列的表示。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig1_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig1_HTML.jpg)

图 5-1

队列表示

另一方面，话题是传播信息的交流渠道。不同的用户可以订阅一个主题，一旦任何消息可用，所有用户(如果没有配置过滤)都会收到该消息的副本。您可以在图 [5-2](#Fig2) 中看到一个主题表示。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig2_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig2_HTML.jpg)

图 5-2

主题表征

这是消息传递中主要概念的总体表示。根据您使用的产品或语言，这些概念可能有不同的名称。这里我使用 Jakarta 消息传递(以前的 JMS，Java 消息传递)规范术语。规范本身在 Java 语言使用的公共 API 中抽象了这些概念，独立于供应商或实现，因此当我们使用 Java 创建与消息传递的集成时，使用这种命名法是公平的。

谈到实现，我们还必须考虑队列和主题的其他方面，而持久性可能是主要方面。

队列和主题可以是持久的，也可以不是。这完全取决于生产者和消费者的关系以及数据的性质。以负责监控卡车位置的设备为例。它会不时发送通知消息，告知卡车的当前坐标。根据卡车的移动方式，如果它在交通中停止或正在加油，您可能会收到许多具有相同坐标的消息。对于这种情况，并不是每条消息都很重要。真正重要的是消息排序。它可能会丢失一些消息，但仍然不会影响整体监控，但消息需要不断出现，消费者需要跟上生产者的节奏。在这种情况下，我们可以轻松地实现非持久队列。我们将获得中间件层的灵活性，并允许生产者向消费者提供更好的吞吐量。我们仍然需要注意中间件资源，以允许它接收生产者的负载，并在消费者比生产者慢时暂时保持它。

在这种情况下，排序也很重要。代理之间的消息负载平衡之类的策略将变得更加难以实现，因为这可能导致生产者向不同的代理发送消息，而消费者不按照发送顺序访问代理。不过，如果我们有不同的案子，这就不是问题了。

想象一下，我们有一个电子商务网站，将客户订单放在队列中进行处理。在这种情况下，排序不是问题，因为每个订单都是完全独立的事件。因此，我们可以通过负载平衡轻松地分配负载，但每个事件都很重要，不容错过。对于这种情况，我们需要一个持久的队列来保证我们有机制在代理失败时恢复消息，因为我们不能冒丢失消息的风险。

题目也有类似的要求。更传统的实现使主题成为订阅者的广播机制，订阅者在代理收到消息时可用，因此消息并没有真正持久化，但仍然存在我们需要广播消息并保证消费者稍后可以获得它们的情况。传统的消息传递是关于消费消息的。一旦消息被处理，它就会从目的地被删除。对于主题来说，完全采用这种机制会更加困难，因为很难期望所有的订阅者都阅读特定的条目，或者在任何给定的时间添加更多的订阅者，并且仍然保持一致。为了解决主题需要持久性的问题，不同的产品实现了不同的机制，从将消息从主题路由到专门为订阅者创建的持久性队列，到不基于读取而是基于时间或存储空间来删除消息，您将在后面看到。

高可用性、性能、数据复制、可伸缩性、监控和其他因素将引导您实现一个特定的消息代理。我们不会孤立地讨论这些特征；我们在描述阿帕奇卡夫卡的时候会谈到他们。

## 阿帕奇卡夫卡

因此，让我们通过在一个实现产品中具体化消息代理理论来实现它。您将学习 Kafka 的核心概念和特征，然后学习如何在 Camel 中使用它们。

用项目网页的话说，“Apache Kafka 是一个开源的分布式事件流平台”。让我们分解其中的一些单词来理解它们真正的意思。从“事件流”开始，从更广泛的意义上来说，事件是由一个源生成的数据，该数据由将在某种级别上处理该数据的消费者捕获或接收。事件源的一些例子是传感器、数据库改变、网络挂钩、应用调用等等。它们都生成可以触发其他应用的数据。流意味着这些事件持续发生，并且有高容量的可能性。

要理解分布式的部分，首先需要理解卡夫卡的架构。

### 概念和架构

围绕卡夫卡有很多炒作。大型科技公司正在使用它，他们说他们每天处理数十亿次交易，移动数万亿字节的数据，这显然会引起需要为其内部服务通信构建弹性和高性能解决方案的开发人员和架构师的注意。所以让我们了解卡夫卡到底是什么，然后你就可以得出你自己的结论。

Kafka 是 LinkedIn 在 2011 年成为开源之前创建的。它最初是为处理大数据流而设计的，比如跟踪页面浏览事件，从服务中收集聚合日志。你可能会问自己，为什么 LinkedIn 会创建一个市场上有这么多可用的消息系统？它需要一个强大且可扩展的平台，以非常低的延迟处理非常高的容量，因此必须做出一些重大的设计决策来实现这一点。

卡夫卡只提供持久的话题。如前所述，您可能需要不同的策略来允许持久主题，因为很难同步消费者如何阅读主题中的消息，所以基于阅读来删除它们变得很复杂。在 Kafka 中，消息不会被消费，而是根据存储利用率或消息的持续时间进行轮换。

这个单一的设计选择开启了新的可能性。由于一切都是一个主题，我们可以根据需要向目的地添加更多的消费者，消费者将能够获得他们开始订阅之前就存在的消息。虽然这可能是某些情况下的期望行为，但对于消费者不希望接收旧消息的其他情况，这可能不是期望的行为。如果现在的消费者下线了呢？它将如何从它开始的地方恢复？Kafka 使用名为 **offset** 的结构保存消息索引，如图 [5-3](#Fig3) 所示。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig3_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig3_HTML.jpg)

图 5-3

偏移表示

偏移是 Kafka 用来标记消息位置的连续长值。它们用于识别哪个消息是为某个消费者群体阅读的(稍后我们将讨论消费者群体)。

卡夫卡的信息处理有些不同。主题分为**个分区**。每个分区都是存储主题消息的独立结构。为了实现这个解释，想象一个有两个代理(Kafka 实例)的 Kafka 集群，如图 [5-4](#Fig4) 所示。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig4_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig4_HTML.jpg)

图 5-4

卡夫卡分区分布

在这个例子中，有一个主题，两个分区分布在两个代理之间。每个分区都是独立的，接收来自生产者的隔离写入，并为消费者提供读取。每个分区都有自己的偏移量计数，该偏移量用于使用者组识别哪个消息在该分区中被读取。消费者组允许同一个消费者应用的不同实例并行读取，而没有重复。在本例中，使用者组中的每个使用者都被分配到一个分区，只有该使用者可以从该分区中读取数据。如果该消费者退出，并且为同一消费者组分配了新的消费者，则新的消费者可以从旧消费者停止的地方开始读取。

如你所见，卡夫卡中的主题本质上是一组分区。分区是允许并行和分布式处理的很好的设计选择。我们在主题创建中设置我们需要的分区数量，但是我们也可以在以后添加更多的分区。分区的数量是根据预期的容量、预期的响应时间、集群安排、消费者行为、存储空间等决定的。这里的重要思想是调整这种配置的灵活性，以满足我们的系统需求。

有许多低层次的配置也会影响性能，但我们这里的重点是使 Kafka 成为一个非常有趣的消息传递解决方案的设计选择。

继续我们对卡夫卡描述中“分布式”含义的转换，你需要理解如何组装一个集群。看一下图 [5-5](#Fig5) 。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig5_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig5_HTML.jpg)

图 5-5

卡夫卡集群

Kafka 实例在启动时做的第一件事就是在 Zookeeper 实例中注册自己。Zookeeper 是分布式应用的协调服务，这意味着它提供命名、配置管理、同步和组服务等公共服务。Kafka 利用 Zookeeper 来管理关于集群成员、主题、访问控制列表和一个非常重要的任务的信息，即 Kafka **控制器**的选举，Kafka 实例将成为集群自动化背后的大脑。

> *2 . 8 . 0 版本提供了 KIP-500 的早期访问版本，允许你在没有 Apache ZooKeeper 的情况下运行 Kafka brokers，但这不是生产就绪，这就是为什么我在这里谈论 ZooKeeper。*

Zookeeper 是这个架构中的一个重要部分，因为它通过提供协调来实现集群的高可用性。动物园管理员也是哈。它利用一个选举过程，一旦选出一个领导者，传入的写请求总是由该领导者处理，该领导者向所有可用节点请求相同的写。如果达到法定人数，则该请求被视为成功。

当我们谈论系统中的高可用性时，我们不仅仅是在谈论服务可用性，还包括数据可用性，尤其是对于一个行为类似于数据库的系统。Kafka 用一种叫做**复制品**的功能解决了这种必要性。看图 [5-6](#Fig6) 检查 Kafka 如何复制分区数据。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig6_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig6_HTML.jpg)

图 5-6

卡夫卡复制品

在上面的例子中，有一个主题，它有三个分区，分布在三个代理之间。新的是每个分区都是复制的，所以是三个分区两个副本的题目。

我之前说过，每个分区都是独立的，并且将接收独立的写请求，这仍然是正确的，即使我们有多个副本。所发生的是控制器必须选择一个分区副本作为领导者。只有领导者接收写入和读取的请求，它负责向追随者发送写入请求以保持副本的一致性。这一过程受到高度监控，其状态通过 **ISR** (同步副本)值来表示。您将在几页中看到该值的显示。理想情况下，分区副本不会在同一个代理中，这样我们就有了数据冗余以防代理失败。

继续上面的例子，假设一个经纪人倒下了。我们会遇到如图 [5-7](#Fig7) 所示的情况。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig7_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig7_HTML.jpg)

图 5-7

代理失败

在这个例子中，`partition 2`领导者和`partition 0`跟随者在失败的代理中。假设最小 ISR 是 1，并且所有分区都是同步的，我们将有一个场景，在这个场景中，`broker 1`中的`partition 2`跟随者将成为领导者。`partition 0`将有一个同步的副本，即`broker 0`中的领导者。使用这种配置，不会丢失任何数据，并且该服务仍可用于所有分区。

还有更多的概念和可能的配置需要讨论，但这里的想法是在你开始使用它之前，对卡夫卡的架构以及它为什么有趣有一个基本的了解。这些是每个和卡夫卡一起工作的人需要理解的主要概念。

接下来，您将看到如何在本地安装和使用一个实例。

### 安装和运行

您已经了解了卡夫卡的基本概念，现在是时候尝试这个工具了。它可以被配置为创建巨大的集群，以支持大量生产者和消费者交换大量数据，但是，像往常一样，我们将从小处着手，使用一个可以在您的开发设置中轻松运行的示例。

您使用 Docker 来促进您对 Keycloak 的体验，您将对 Kafka 做同样的事情。不幸的是，该项目没有提供现成的容器图像，但我们可以指望社区为我们提供一个。您将使用`wurstmeister/kafka`图像。在`kafka-installation`文件夹下是本例中使用的图像的 git 项目，`kafka-docker`和`zookeeper-docker`，以防您想知道这些图像是如何构建的或者甚至想自己构建它们。在同一个文件夹中，你会发现一个`docker-compose.yml`文件，你将使用它来启动应用。在 IDE 或文本编辑器中打开该文件。我们来看一下；见清单 [5-1](#PC1) 。

```
version: '3'
services:
  zookeeper:
    image: wurstmeister/zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 22181:2181

  kafka:
    image: wurstmeister/kafka:2.13-2.7.0
    container_name: broker
    depends_on:
      - zookeeper
    ports:
    - 9092:9092
    environment:
      KAFKA_ADVERTISED_HOST_NAME: localhost
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

Listing 5-1Kafka docker-compose.yml

```

对于这个例子，您使用 Docker compose，因为 Kafka 需要一个 Zookeeper 实例来连接，所以您在文档中定义了两个服务，`zookeeper`和`kafka`。对于 Kafka 如何工作以及使用它在应用之间交换消息的基本体验，您不需要集群，这就是为什么您要通过在每个服务中固定一个容器名称来设置这个合成文件只允许单个实例。它还将帮助您使用需要执行的 docker 命令。

让我们从卡夫卡开始。在终端中，导航到`kafka-installation`文件夹并运行以下命令:

```
kafka-installation $ docker compose up -d

```

一旦它完成下载图像，你应该得到一个类似图 [5-8](#Fig8) 的可视化效果。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig8_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig8_HTML.jpg)

图 5-8

坞站合成 up result

要检查 Kafka 是否正确启动，请使用以下命令查看容器日志:

```
$ docker logs broker

```

查找类似清单 [5-2](#PC4) 的日志条目。如果你找到了他们，这意味着卡夫卡已经准备好了。

```
...
[2021-06-05 15:30:28,450] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
[2021-06-05 15:30:28,506] INFO [broker-1001-to-controller-send-thread]: Recorded new controller, from now on will use broker 1001 (kafka.server.BrokerToControllerRequestThread)

Listing 5-2Kafka Container Log Snippet

```

Kafka 没有提供可视化工具或控制台，尽管有许多项目和供应商提供这种功能，但它提供了一组脚本，允许您管理它。

首先访问代理容器来可视化脚本集合。从终端运行以下命令:

```
$ docker exec -it broker /bin/sh

```

从这一点上，你可以导航到卡夫卡在这个图像中的安装位置。这里的安装路径是`/opt/kafka`。使用命令转到该文件夹:

```
/ # cd /opt/kafka/bin/

```

一旦在目录中，列出它。你会得到一个如图 [5-9](#Fig9) 的结果。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig9_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig9_HTML.jpg)

图 5-9

卡夫卡的剧本

使用这些脚本可以进行许多不同的配置，但是您将只执行一些基本的操作，这些操作将帮助您利用 Kafka 进行消息传递。

第一步是创建一个主题。运行以下命令创建主题:

```
/opt/kafka_2.13-2.7.0/bin # kafka-topics.sh \
--bootstrap-server localhost:9092 --create \
--replication-factor 1 --partitions 2 --topic myTestTopic

```

预期结果是“`Created topic myTestTopic.`”消息。

您可以使用`kafka-topics.sh`查找更多与主题管理相关的操作，例如，列出集群中存在的主题:

```
/opt/kafka_2.13-2.7.0/bin # kafka-topics.sh \
--bootstrap-server localhost:9092 --list

```

该操作仅显示主题名称，以便您知道它们的存在，但是如果您需要关于主题的更多信息，您可以描述它，如以下命令所示:

```
/opt/kafka_2.13-2.7.0/bin # kafka-topics.sh \
--bootstrap-server localhost:9092 --describe \
--topic myTestTopic

```

如果您运行这个命令，您会得到如图 [5-10](#Fig10) 所示的结果。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig10_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig10_HTML.jpg)

图 5-10

主题描述命令

这个命令显示了关于这个主题的许多重要信息，比如它的分区数量、复制因子以及它可能具有的特定配置，但是真正有趣的是第二行。它显示了分区在哪里，谁是领导者，副本在哪里，以及哪些副本是同步的。在本例中，有两个分区，但只有一个代理实例。在这种情况下，分区领导者位于 id 为 1001 的代理中(您可以在启动日志中看到这一点)，因此每个分区都有一个副本，这就是分区领导者本身。

您也可以改变此实体配置。假设您想将主题的保持期设置为 10 秒。你可以这样做:

```
/opt/kafka_2.13-2.7.0/bin # kafka-configs.sh \
--bootstrap-server localhost:9092 \
--topic myTestTopic --alter --add-config retention.ms=10000

```

然后，您可以再次检查该主题，看看上面的命令是否有一些效果。再次运行`describe`命令，如图 [5-11](#Fig11) 所示。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig11_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig11_HTML.jpg)

图 5-11

改变话题

已应用更改。您可以看到该主题保留期有了新的配置。

### 测试安装

现在您已经有了一个正在运行的 Kafka broker，您需要开始使用应用测试它。稍后您将使用 Camel 访问 Kafka，但是首先让我们利用 Kafka 安装提供的一些应用。

我希望您仍然打开了带有代理容器终端。如果没有，就按照上一节的步骤，因为您将在那里使用两个脚本:`kafka-console-producer.sh`和`kafka-console-consumer.sh.`

先从设置消费 app 开始。在已经打开的终端的`kafka/bin`目录中，运行以下命令:

```
/opt/kafka_2.13-2.7.0/bin # kafka-console-consumer.sh \
--bootstrap-server localhost:9092 --topic myTestTopic

```

此时命令行处于冻结状态，等待消息开始进入主题，因此让我们准备好生产者。打开一个新的终端，访问代理容器，并转到`/opt/kafka/bin`目录。像这样运行生产者脚本:

```
/opt/kafka_2.13-2.7.0/bin # kafka-console-producer.sh--bootstrap-server localhost:9092 --topic myTestTopic

```

将为您打开一个光标。键入一条消息，然后按 Enter。然后检查你的消费者。它会收到你发送的准确信息。

通过按 Control + C 停止消费者和生产者。您现在将执行一个新的测试。首先，让我们增加保留期，将其设置回默认值，即 7 天。运行以下命令:

```
/opt/kafka_2.13-2.7.0/bin # kafka-configs.sh \
--bootstrap-server localhost:9092 --topic myTestTopic \
--alter --config retention.ms=60480000

```

再次打开生成器。发送三条这样的消息:

*   编译

*   生产者

*   消费者

现在像以前一样打开消费者。你不会得到任何消息。发生这种情况是因为该使用者被配置为仅读取新消息。添加选项`-from-beginning`，你将得到这些信息，如图 [5-12](#Fig12) 。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig12_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig12_HTML.jpg)

图 5-12

读取旧偏移

本节展示了如何使用 Kafka 作为消息代理来连接应用。这些脚本可以帮助您进行调试，因为它们可以接收不同的配置，比如使用特定的分区或使用给定的组 id。

## 骆驼和卡夫卡

您刚刚学习了 Kafka 的概念和架构，如何执行基本操作，以及如何运行基本测试。现在，您将连接一个 Camel 应用，并讨论这种实现的一些注意事项。

在第一个使用 Camel 访问 Kafka 主题的例子中，您将使用两个不同的应用:`camel-kafka-producer`和`camel-kafka-consumer`。生产者将公开一个 REST 接口，使您能够向消费者应用发送消息。通过这个简单的设置，您将探索使用 Kafka 组件的生产者和消费者的一些配置。

### 设置应用

让我们看看如何配置 Camel 应用来访问 Kafka 主题。

从分析`camel-kafka-producer`代码开始。将它加载到您喜欢的 IDE 中。查看清单 [5-3](#PC15) 中的 pom 文件。

```
...
<dependencies>
<dependency>
<groupId>org.apache.camel.quarkus</groupId>
<artifactId>camel-quarkus-kafka</artifactId>
</dependency>
<dependency>
<groupId>org.apache.camel.quarkus</groupId>
<artifactId>camel-quarkus-rest</artifactId>
</dependency>
</dependencies>
...

Listing 5-3pom.xml Snippet

```

这个项目只有两个依赖项，`camel-quarkus-rest`和`camel-quarkus-kafka`。你已经知道的 REST 组件。它将负责添加 webserver 实现并启用 REST DSL。卡夫卡成分是你的研究对象。让我们看看这个项目路线是什么样子的。打开清单 [5-4](#PC16) 所示的`RestKafkaRoute.java`文件。

```
public class RestKafkaRoute extends RouteBuilder {

@Override
public void configure() throws Exception {

  rest("/kafka")
  .consumes(TEXT_PLAIN)
  .produces(TEXT_PLAIN)
  .post()
  .route()
    .routeId("rest-route")
    .log("sending message.")
    .removeHeaders("*")
    .to("{{kafka.uri}}")
    .removeHeaders("*")
    .setBody(constant("message sent."))
    .log("${body}")
  .endRest();
}}

Listing 5-4RestKafkaRoute.java File

```

这个路由接收到一个`text/plain`体，发送到一个 Kafka 主题，得到一个响应通知消息已经发送到主题，但是这个逻辑中间有一个你以前没有做过的事情。就在 Kafka 组件步骤之前，您正在使用一个无所不包的模式删除消息头。这是您以前没有做过的事情，因为您面临的案例没有受到标头传播的影响。

根据组件的不同，它可能会对一些特殊的头做出反应，例如 JPA 查询参数，但是对于这个组件，其他头会被完全忽略。在这种情况下，您正在使用一个对消息头更敏感的组件，因为被调用的应用在其数据模型中有消息头。

Kafka 消息(也称为记录)是带有一些元数据和消息头的键值对条目。该键是用于分区分配的可选字段。该值是您想要发送的实际消息。

在这个例子中，您删除了来自 HTTP 请求的所有 of 头，因为您不需要它们，也不想向 Kafka 发送无用的信息。在组件调用之后，您还要删除头，因为您不需要返回的信息，也不想将 Kafka 信息暴露给 HTTP 客户端。

您可能已经注意到了用于声明端点配置的属性键。因为这个组件比前面的例子需要更多的配置，所以使用`application.properties`文件来提高代码的可读性和可配置性是有意义的。

在 IDE 中打开属性文件(清单 [5-5](#PC17) )。

```
topic=example1
brokers=localhost:9092
id=producer
kafka.uri=kafka:{{topic}}?brokers={{brokers}}&clientId={{id}}

Listing 5-5application.properties File

```

Kafka 组件需要一些参数才能正常工作。第一个是它将向其发送消息的`topic`。在这里，您将设置“`example1`”作为值。稍后您将创建这个主题。你还需要设置`brokers`地址。如果要连接到集群，则必须在此参数中配置一个列表。Kafka 客户端需要知道集群的所有成员，以便根据分区分布或负载平衡来访问它们。这种情况下的`clientId`会帮助卡夫卡和你追踪通话。

现在，让我们看一下消费者应用。在您的 IDE 中打开`camel-kafka-consumer`项目。看清单 [5-6](#PC18) 中的`RouteBuilder`。

```
public class KafkaConsumerRoute extends RouteBuilder {

    @Override
    public void configure() throws Exception {

      from("{{kafka.uri}}")
      .routeId("consumer-route")
      .log("Headers : ${headers}")
      .log("Body : ${body}");
    }
}

Listing 5-6KafkaConsumerRoute.java File

```

这个路由使用来自一个主题的消息并记录消息内容，首先是消息头，然后是消息内容。

让我们看看清单 [5-7](#PC19) 中该项目的`application.properties`。

```
topic=example1
brokers=localhost:9092
kafka.uri=kafka:{{topic}}?brokers={{brokers}}&clientId=${kafka.clientid}&groupId=${kafka.groupid}

Listing 5-7camel-kafka-consumer Project’s application.properties File

```

这种配置与您之前看到的类似。唯一不同的是，对于消费者，建议设置一个`groupId`。组 id 允许您持久化读取的偏移量，因此如果您重新启动消费者应用，它将能够从停止的地方重新启动。`clientId`和`groupId`使用属性标记作为值，因为您将把这些参数作为 JVM 变量传递给应用。

### 首次测试

您已经看到了示例应用是如何配置的。现在你需要看看它们在不同的场景下会有怎样的表现。

让我们测试代码。在运行应用之前，您需要创建“`example1`”主题。您可以运行以下命令来完成此操作:

```
docker exec -it broker /opt/kafka/bin/kafka-topics.sh \
--create --bootstrap-server localhost:9092 \
--replication-factor 1 --partitions 2 --topic example1

```

创建主题后，您就可以启动消费者了。在终端的`camel-kafka-consumer`目录下，运行以下命令:

```
camel-kafka-consumer/ $ mvn quarkus:dev -Dkafka.clientid=test  -Dkafka.groupid=testGroup

```

消费者启动后，查看消费者日志。那里有一些有趣的信息。它们看起来会像这样:

```
[Consumer clientId=test, groupId=testGroup] Notifying assignor about the new Assignment(partitions=[example1-0, example1-1])

```

日志条目通过分配过程中的`clientId`和`groupId`来标识消费者，该过程确定消费者组的成员将从哪个分区获取消息。在这种情况下，由于您只有一个使用者和两个分区，因此使用者将从两个分区获得消息。

```
[Consumer clientId=test, groupId=testGroup] Found no committed offset for partition example1-0
[Consumer clientId=test, groupId=testGroup] Found no committed offset for partition example1-1

```

上面的消息告诉您，没有为两个分区保存偏移读数。

```
[Consumer clientId=test, groupId=testGroup] Resetting offset for partition example1-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}.

[Consumer clientId=test, groupId=testGroup] Resetting offset for partition example1-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}.

```

这些条目告诉您将从哪个偏移量开始读取消息，在本例中为`offset=0`。它们还告诉给定分区的领导者是谁，在本例中是`localhost:9092 (id: 1001)`。

你现在可以开始制作了。在新终端中，运行以下命令:

```
camel-kafka-producer/ $ mvn quarkus:dev -Ddebug=5006

```

启动生成器后，您可以向它发送请求。发送以下请求:

```
$ curl  -X POST 'http://localhost:8080/kafka'   \
-H 'Content-Type: text/plain' -d 'Testing Kafka'

```

看看消费者记录。你会得到这样的东西:

```
2021-06-06 08:47:42,524 INFO  [consumer-route] (Camel (camel-1) thread #0 - KafkaConsumer[example1]) Headers : {kafka.HEADERS=RecordHeaders(headers = [], isReadOnly = false), kafka.OFFSET=0, kafka.PARTITION=1, kafka.TIMESTAMP=1622980062458, kafka.TOPIC=example1}

2021-06-06 08:47:42,528 INFO  [consumer-route] (Camel (camel-1) thread #0 - KafkaConsumer[example1]) Body : Testing Kafka

```

第一个日志条目是消息头的值。正如您所看到的，消费者将返回一些关于读取的信息，比如偏移读取、哪个分区、哪个主题和消息时间戳，这将告诉您消息何时进入主题。第二个值是实际的消息。

让我们用不同的信息再试一次:

```
$ curl  -X POST 'http://localhost:8080/kafka'\
 -H 'Content-Type: text/plain' -d 'Learning Camel'

```

再看看消费者日志。您将看到类似这样的条目:

```
2021-06-06 08:49:22,988 INFO  [consumer-route] (Camel (camel-1) thread #0 - KafkaConsumer[example1]) Headers : {kafka.HEADERS=RecordHeaders(headers = [], isReadOnly = false), kafka.OFFSET=0, kafka.PARTITION=0, kafka.TIMESTAMP=1622980162982, kafka.TOPIC=example1}

2021-06-06 08:49:22,989 INFO  [consumer-route] (Camel (camel-1) thread #0 - KafkaConsumer[example1]) Body : Learning Camel

```

该分区与之前的测试不同，但是消费者仍然可以从两个分区获得消息。让我们在同一个消费者组中添加一个新的消费者。

打开新的终端。导航到`camel-kafka-consumer`项目目录并运行以下命令:

```
camel-kafka-consumer/ $ mvn quarkus:dev -Dkafka.clientid=other  -Dkafka.groupid=testGroup -Ddebug=5007

```

一旦应用启动，查看它的日志。以下是我的例子:

```
[Consumer clientId=other, groupId=testGroup] Adding newly assigned partitions: example1-0

[Consumer clientId=other, groupId=testGroup] Setting offset for partition example1-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}

```

分区 0 是为我的新用户分配的，它将从`offset=1`开始读取。如果您查看第一个消费者的日志，您会看到现在只有一个分区被分配给它。

### 扩大消费者规模

我们讨论了 Kafka 架构的可伸缩性，但是在这种情况下，可伸缩性也意味着增加消费者端的处理能力。当考虑如何衡量消费者时，我们需要遵循一些规则。

如果我们在同一个组中添加一个新的消费者，会发生什么情况？让我们试试。在`camel-kafka-consumer`目录中打开一个新的终端，并运行以下命令:

```
camel-kafka-consumer/ $ mvn quarkus:dev -Dkafka.clientid=third  -Dkafka.groupid=testGroup -Ddebug=5008

```

应用启动后，我的新消费者就遇到了这种情况:

```
[Consumer clientId=third, groupId=testGroup] Notifying assignor about the new Assignment(partitions=[])

```

没有给它分配分区。让我们来看看当您向主题添加消息时会发生什么。运行下面的 bash 脚本，在主题中输入十条新消息。

```
$ i=0; while [ $i -lt 10 ]; do ((i++)); curl -w "\n" -X POST 'http://localhost:8080/kafka' -H 'Content-Type: text/plain'   -d "Message number: $i" ; done

```

如果您查看消费者的日志，您将看到没有分配分区的消费者没有接收消息。这被称为*饥饿的消费者。*

请记住，活动消费者的数量将取决于该主题当前可用的分区数量。在代理失败的情况下，我们可能会遇到某个特定分区没有领导者的情况。

如果您需要提高整体性能，请记住，您可以稍后向一个主题添加更多的分区。

您可以使用其他客户端配置来提高消费者处理能力，比如`consumersCount`和`consumerStreams`。

`consumerStreams`参数负责设置组件线程池的线程数量，而`consumersCount`负责设置应用中 Kafka 消费者的数量。每个偏移量读取都将在一个线程中完成，这意味着您可以进行的并发读取的数量将取决于您拥有的消费者数量，以及您是否有可供该消费者使用的线程。

为了演示这个配置，在您的 IDE 上打开`camel-kafka-consumer-v2`项目。让我们看看这个项目的路线，这样你就可以了解这个测试是如何工作的；看清单 [5-8](#PC35) 。

```
public class KafkaConsumerRoute extends RouteBuilder {

@Override
public void configure() throws Exception {

from("{{kafka.uri}}")
 .routeId("consumer-route")
 .log("Headers : ${headers}")
 .log("Body : ${body}")
 .process(new Processor() {
    @Override
 public void process(Exchange exchange) throws Exception {
  log.info("My thread is :"+Thread.currentThread().getName());
  log.info("Going to sleep...");
  Thread.sleep(10000);
    }
  });
}}

Listing 5-8KafkaConsumerRoute.java File

```

这条路线上唯一的新东西是，现在您有了一个处理器，它让正在执行的线程休眠十秒钟。这将有助于你想象执行过程。

让我们看看清单 [5-9](#PC36) 中的属性文件。

```
topic=example1
brokers=localhost:9092
kafka.uri=kafka:{{topic}}?brokers={{brokers}}&clientId=${kafka.clientid}&groupId=${kafka.groupid}&consumersCount=${kafka.consumers.count}&consumerStreams=${kafka.consumers.stream}

Listing 5-9camel-kafka-consumer-v2 properties File

```

这里您添加了`consumersCount`和`consumerStreams`参数，但是您也将从 JVM 属性中获得它们。

要开始测试此代码，请停止任何正在运行的使用者。在终端中，像这样启动应用:

```
camel-kafka-consumer-v2/ $ mvn clean quarkus:dev \
-Ddebug=5006 -Dkafka.clientid=test -Dkafka.groupid=testGroup \ -Dkafka.consumers.count=1 -Dkafka.consumers.stream=10

```

在这里，您可以使用默认值设置参数。要测试应用如何使用消息，请在另一个终端中运行以下命令:

```
$ i=0; while [ $i -lt 3 ]; do ((i++));  curl -w "\n"  -X POST 'http://localhost:8080/kafka' -H 'Content-Type: text/plain'   -d "Message number: $i" ; done

```

三条消息足以向您显示每十秒钟将处理一条消息，即使您在池中有十个线程。

现在尝试使用两个 Kafka 消费者和池中相同数量的线程。停止消费者，然后像这样重新启动它:

```
camel-kafka-consumer-v2/ $ mvn clean quarkus:dev \            -Ddebug=5006 -Dkafka.clientid=test -Dkafka.groupid=testGroup \
-Dkafka.consumers.count=2 -Dkafka.consumers.stream=10

```

现在，不是只发送三条信息，而是发送八条。

```
$ i=0; while [ $i -lt 8 ]; do ((i++));  curl -w "\n"  -X POST 'http://localhost:8080/kafka' -H 'Content-Type: text/plain'   -d "Message number: $i" ; done

```

您将看到应用每十秒钟消耗两条消息。但是如果你的消费者比线程多会怎么样呢？停止消费应用，并像这样启动它:

```
camel-kafka-consumer-v2/ $ mvn clean quarkus:dev \
-Ddebug=5006 -Dkafka.clientid=test -Dkafka.groupid=testGroup \          -Dkafka.consumers.count=2  -Dkafka.consumers.stream=1

```

再发三条信息。您将看到每十秒钟只处理一条消息。

您在这里所做的是通过允许消费者消耗更多资源来纵向扩展消费者，在本例中是分配给分区。当您纵向扩展应用时，您还需要调整应用消耗计算资源(如内存和 CPU)的方式。

您正在对应用采用微服务方法，因此您不希望它们变得太大，以至于可能会损害其他重要的微服务特性，如正常关闭的敏捷性或水平扩展的能力(通过添加新实例)。这完全是了解您的数据和您的应用，然后适当调整配置的问题。测试是必须的。

### 偏移复位

您可以为已经包含消息的现有主题添加新的消费者。在这种情况下，你需要为你的新消费者设定正确的行为。

在讨论当一个主题已经有消息时你能做什么之前，我需要你看一看一些东西。在代理运行的情况下，在终端上运行以下命令:

```
$ docker exec -it broker /opt/kafka/bin/kafka-topics.sh                  --bootstrap-server localhost:9092 --list

```

这个命令列出了代理中可用的主题。如果你没有删除任何主题，你的输出应该如图 [5-13](#Fig13) 所示。

![../images/514395_1_En_5_Chapter/514395_1_En_5_Fig13_HTML.jpg](../images/514395_1_En_5_Chapter/514395_1_En_5_Fig13_HTML.jpg)

图 5-13

主题列表

组 id 消耗的每个分区偏移量保存在`__consumer_offsets`主题中。您可以在应用日志中看到，在每次启动过程中，客户端都会检查给定分区的可用偏移量，总是寻找最新的引用。

在开始这个新例子之前，您需要一个新的主题。来清理一下你的老话题吧。停止任何正在运行的应用，并运行以下命令来执行此操作:

```
$ docker exec -it broker /opt/kafka/bin/kafka-topics.sh       --bootstrap-server localhost:9092 --delete --topic myTestTopic

$ docker exec -it broker /opt/kafka/bin/kafka-topics.sh       --bootstrap-server localhost:9092 --delete --topic example1

```

要开始您的测试，您将需要一个主题，但是这次不是您自己创建一个，而是让主题自动创建来完成。默认情况下，它将创建一个具有单个副本和单个分区的主题。这对你的测试来说足够了。

如果这不是理想的配置，您可以通过将 Kafka 的 config 目录中的`server.properties`文件中的`auto.create.topics.enable`属性设置为 false 来禁用自动创建。这将需要重新启动代理。

再次运行`camel-kafka-producer`应用。启动后，使用以下命令发送十条消息:

```
$ i=0; while [ $i -lt 10 ]; do ((i++));  curl -w "\n"  -X POST 'http://localhost:8080/kafka' -H 'Content-Type: text/plain'   -d "Message number: $i" ; done

```

您现在可以启动消费者，知道主题中有消息。像这样启动`camel-kafka-consumer`应用:

```
camel-kafka-consumer/ $ mvn clean quarkus:dev -Ddebug=5006     -Dkafka.clientid=test -Dkafka.groupid=testGroup

```

你没有收到任何信息，是吗？这是意料之中的行为。默认情况下，自动偏移重置的组件属性设置为采用分区中的最新偏移。查看消费者应用中的日志，如清单 [5-10](#PC46) 所示。

```
2021-06-06 20:52:09,669 INFO  [org.apa.kaf.cli.con.int.ConsumerCoordinator] (Camel (camel-1) thread #0 - KafkaConsumer[example1]) [Consumer clientId=test, groupId=testGroup] Found no committed offset for partition example1-0

2021-06-06 20:52:09,693 INFO  [org.apa.kaf.cli.con.int.SubscriptionState] (Camel (camel-1) thread #0 - KafkaConsumer[example1]) [Consumer clientId=test, groupId=testGroup] Resetting offset for partition example1-0 to position FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}.

Listing 5-10camel-kafka-consumer Application Log Snippet

```

第一个日志显示，对于所提供的组 id，没有找到分区`example1-0`的提交偏移量。第二个显示为`FetchPosition offset=10`重置了偏移，这将是下一个生成的偏移。

发送一条消息来检查消费者日志中的记录标题:

```
$ curl -w "\n"  -X POST 'http://localhost:8080/kafka'-H 'Content-Type: text/plain'   -d "Single message"

```

在日志中，您会发现如下条目:

```
2021-06-06 20:57:16,338 INFO  [consumer-route] (Camel (camel-1) thread #0 - KafkaConsumer[example1]) Headers : {kafka.HEADERS=RecordHeaders(headers = [], isReadOnly = false), kafka.OFFSET=10, kafka.PARTITION=0, kafka.TIMESTAMP=1623023836299, kafka.TOPIC=example1}

```

您可以看到消息偏移量是`10`，这是在消费者启动中标记的位置，但是您仍然没有获得之前的消息。这可能是所希望的情况，因为新的应用可能不想要旧的消息。如果您想要重放主题中的每条消息，您只需要一个新的组 id 和以下配置。

首先，停止消费者应用。将`kafka.uri`属性更改为如下所示:

```
kafka.uri=kafka:{{topic}}?brokers={{brokers}}&clientId=${kafka.clientid}&groupId=${kafka.groupid}&autoOffsetReset=earliest

```

现在，像这样启动应用:

```
camel-kafka-consumer/ $ mvn clean quarkus:dev-Ddebug=5006    -Dkafka.clientid=test -Dkafka.groupid=newGroup

```

这样，应用将获得主题中存在的所有消息，如果您使用相同的参数重新启动应用，它将不会获得相同的消息，因为提供的组 id 已经保存了一个偏移量，客户端不需要重置它。

### 单元测试应用

对于单元测试应用，保持代码质量并使维护更容易是很重要的。在处理集成时，您可能会遇到不容易模仿的应用，比如消息代理。Camel 提供的组件和功能可以帮助您完成这项任务。

对于这个新例子，有一个名为`camel-kafka-tests`的新项目。这个项目融合了`camel-kafka-producer`和`camel-kafka-consumer` plus 单元测试。

它有一个`RouteBuilder`来公开一个 REST 接口并将一条消息发布到一个主题中，还有一个`RouteBuilder`来为该主题创建一个消费者。先说清单 [5-11](#PC51) 中的生产商路线。

```
public class RestKafkaRoute extends RouteBuilder {

@Override
public void configure() throws Exception {

  rest("/kafka")
  .consumes(TEXT_PLAIN)
  .produces(TEXT_PLAIN)
  .post()
  .route()
    .routeId("rest-route")
    .log("sending message.")
    .removeHeaders("*")
    .to("{{kafka.uri.to}}")
    .removeHeaders("*")
    .setBody(constant("message sent."))
    .log("${body}")
  .endRest();

}
}

Listing 5-11RestKafkaRoute.java File

```

这条路线实际上就是您一直用来在主题中发布消息的路线。唯一的区别是现在属性名不那么通用了，因为现在有两条路由。让我们看看清单 [5-12](#PC52) 中的消费者。

```
public class KafkaConsumerRoute extends RouteBuilder {

    @Override
    public void configure() throws Exception {

        from("{{kafka.uri.from}}")
        .routeId("consumer-route")
        .log("Headers : ${headers}")
        .to("{{final.endpoint}}");

    }
}

Listing 5-12KafkaConsumerRoute.java File

```

唯一改变的是最后一步。您将使用日志端点，而不是使用`log()` DSL 进行日志记录。你马上就会明白为什么了。

为了测试这段代码，您需要首先创建主题。奔跑

```
$ docker exec -it broker /opt/kafka/bin/kafka-topics.sh  \     --create --bootstrap-server localhost:9092  \                 --replication-factor 1 --partitions 2 --topic example2

```

然后，您可以启动应用:

```
camel-kafka-tests/ $ mvn quarkus:dev

```

并发送消息进行测试:

```
$ curl -X POST 'http://localhost:8080/kafka' \
-H 'Content-Type: text/plain' -d "hi"

```

既然您已经看到了应用是如何工作的，那么您可以开始关注单元测试了。观察项目 pom 的新增内容，如清单 [5-13](#PC56) 所示。

```
...
<dependency>
<groupId>org.apache.camel.quarkus</groupId>
<artifactId>camel-quarkus-log</artifactId>
</dependency>
<dependency>
<groupId>org.apache.camel.quarkus</groupId>
<artifactId>camel-quarkus-direct</artifactId>
<scope>test</scope>
</dependency>
<dependency>
<groupId>org.apache.camel.quarkus</groupId>
<artifactId>camel-quarkus-mock</artifactId>
<scope>test</scope>
</dependency>
<dependency>
<groupId>io.quarkus</groupId>
<artifactId>quarkus-junit5</artifactId>
<scope>test</scope>
</dependency>
<dependency>
<groupId>io.rest-assured</groupId>
<artifactId>rest-assured</artifactId>
<scope>test</scope>
</dependency>
...

Listing 5-13camel-kafka-tests pom.xml File Snippet

```

我只强调这个例子中新增加的内容。

你已经知道`camel-quarkus-log`。您之所以使用它，是因为您也在使用组件进行日志记录。您将使用`camel-quarkus-direct`和`camel-quarkus-mock`来替代和模仿一些端点定义。这将为您提供在没有运行 Kafka 代理的情况下执行单元测试的灵活性。JUnit 5 的 Quarkus 实现是测试的基础。考虑到夸尔库斯建筑模型，它将正确地设置环境。最后，您可以放心，这是一个用于测试 REST 应用的流行库。

所以让我们来看看第一个单元测试类，如清单 [5-14](#PC57) 所示。

```
@QuarkusTest
public class RestKafkaRouteTest {

    @Test
    public void test()  {

        given()
            .contentType(ContentType.TEXT)
            .body("Hello")
        .when()
            .post("/kafka")
        .then()
            .statusCode(200)
            .body(is("message sent."));

    }
}

Listing 5-14RestKafkaRouteTest.java File

```

首先用`@QuarkusTest`注释测试类。这将允许 JUnit 实现启动应用和其中的 Camel 上下文。测试非常简单。您使用 REST Assured 向 REST 端点发送一条消息，然后断言响应状态代码是否为 200，响应消息是否为"`message sent.`"

你可能会问在路线中间的 Kafka 端点调用。这一呼吁遭到了嘲笑。看一下测试文件夹下的`application.properties`文件，如清单 [5-15](#PC58) 所示。

```
kafka.uri.to=mock:kafka-topic
kafka.uri.from=direct:topic
final.endpoint=mock:destination

Listing 5-15application.properties for Test

```

在本例中，您使用属性声明端点，因此可以在测试时替换属性值。这样，您仍然可以对路由逻辑进行单元测试，而不必在测试期间提供代理。在这个测试中，模拟组件用于传递交换，没有任何修改。然后路由结束，HTTP 客户端将得到一个响应。

现在让我们看看清单 [5-16](#PC59) 中的消费者路线。

```
@QuarkusTest
public class KafkaConsumerRouteTest {

    @Inject
    CamelContext camelContext;

    @Inject
    ProducerTemplate producerTemplate;

    @ConfigProperty(name = "kafka.uri.from")
    String direct;

    @ConfigProperty(name = "final.endpoint")
    String mock;

    private static final String MSG = "Hello";

    @Test
    public void test() throws InterruptedException {

        producerTemplate.sendBody(direct, MSG);

        MockEndpoint mockEndpoint =
           camelContext.getEndpoint(mock, MockEndpoint.class);
        mockEndpoint.expectedMessageCount(1);
        mockEndpoint.assertIsSatisfied();

        assertEquals(MSG,mockEndpoint.getExchanges().get(0)
                                 .getMessage().getBody())

    }

}

Listing 5-16KafkaConsumerRouteTest.java File

```

在这里，您使用不同的方法来测试路由，因为您的路由消费者必须被嘲笑。因为您没有运行代理，所以有必要用 Kafka 组件替换 direct 组件。这样，您可以使用`ProducerTemplate`来调用路由，这实际上将创建一个交换并将其发送到直接端点。从那里，路由逻辑将继续。这条路线的问题是它做的不多，这就是为什么你把最后一步改成使用`to()`。在单元测试中，您将替换模拟组件的日志定义，并使用它来检查路由状态。通过注入 Camel 上下文，可以获得端点引用。在这里，您可以获得对模拟端点的引用。这个端点将保留它收到的交换信息，使用这些信息，您可以断言路由是否按预期执行。您可以检查收到了多少条消息，以及消息正文是否与您发送的相同，因为不应该进行任何处理。

要执行这些测试，请运行以下命令:

```
camel-kafka-tests/ $ mvn clean test

```

预计会在日志中收到以下消息:

```
[INFO] Results:
[INFO]
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0
[INFO]
[INFO] -------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] -------------------------------------------------------

```

这里展示的技术可以用来设置许多不同的测试场景。例如，您可以用 bean 调用替换端点定义，并使用这些方法在交换中注入您可以模仿的任何对象。这样，您可以虚拟地模仿您需要做的每一个集成。只要记住保持路由逻辑的整洁，并使用属性来声明端点，单元测试 Camel 将会很容易。

## 摘要

本章致力于服务之间的异步通信，最常见的方式是使用面向消息的中间件。在本章中，您学习了以下主题:

*   面向消息的中间件的特征

*   异步通信对健壮架构的重要性

*   卡夫卡的概念和建筑

*   如何使用 Kafka 运行和执行基本配置

*   如何设置 Camel 访问 Kafka 主题

*   如何使用 Quarkus 和 Camel 执行单元测试

在下一章也是最后一章，我们将深入探讨如何在 Kubernetes 环境中运行这些所谓的云原生应用，以及这种方法对架构设计的影响。