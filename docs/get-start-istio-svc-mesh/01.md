# 1.忽必烈之旅

Kubernetes 源于希腊语κυβερνήτης，意思是“总督”、“舵手”或“领航员”这就是创始人乔·贝达、布伦丹·伯恩斯和克雷格·麦克卢奇的想法。他们希望“驾驶一艘集装箱船”,从而创建一个集装箱编排平台，如今该平台已成为在云中运行微服务的事实标准。

在 2013 年末，IaaS 的声明式配置开始超过用于云基础设施的 bash 脚本。尽管像网飞这样的公司正在普及不可变的基础设施，但这也带来了重量级虚拟机映像的成本。Docker 通过提供轻量级容器成为了救星。与重量级虚拟机映像相比，它提供了一种在机器上打包、分发和部署应用的简单方法。但是在一台机器上运行 Docker 容器并不是扩展应用的解决方案，因为扩展应用需要在多台机器上部署 Docker 容器。这就产生了对管弦乐队的需求。

Kubernetes 的开发从关注 orchestrator 的关键特性开始，例如具有负载均衡和服务发现的应用复制，然后是基本的健康检查和修复特性以确保可用性。Kubernetes 还作为 Borg 的开源版本发布，Borg 是谷歌的一个大规模集群管理器，跨集群为不同的应用运行数十万个作业，每个集群有数万台机器。2015 年年中，Kubernetes 致力于 GitHub，并开放给开发者开始投稿。很快，像微软、Red Hat、IBM、Docker、Mesosphere、CoreOS 和 SaltStack 这样的大玩家加入了这个社区并开始做出贡献。随着时间的推移，在 Kubernetes 上开发了多个模块，确保了基本的 orchestrator 是完整的，并随着时间的推移得到了优化。

随着 Kubernetes 在开发人员社区中越来越受欢迎，开发人员开始使部署过程变得更加简单。Helm 是 Kubernetes 的一个包管理器，于 2016 年初推出，旨在简化如何定义、安装和升级复杂的 Kubernetes 应用。2016 年年中的某个时候，Minikube 发布了；Minikube 将 Kubernetes 环境带到了开发人员的本地系统中。我们将在本章后面的示例 Kubernetes 应用中使用 Minikube。Kubernetes 在生产中最受欢迎的应用之一是 PokemonGo。当时，这是 Kubernetes 在 Google Container Engine 上最大的部署之一。他们发布了一个案例研究，解释当应用的流量远远超出预期时，Kubernetes 如何帮助公司扩大规模。

后来，在 2017 年和 2018 年初，像 AWS 和 DigitalOcean 这样的云玩家在他们的栈上为 Kubernetes 腾出了空间。今天的 Kubernetes 是一个用于管理容器化应用的可移植、可扩展的开源平台。它有微型组件，负责 orchestrator 的基本功能。我们先来看看 K8s，这个单词 *Kubernetes* 的缩写，是由什么组成的。

## K8s 架构/组件

Kubernetes 遵循客户端-服务器架构，其中主服务器安装在一台机器上，节点分布在多台机器上，可通过主服务器访问。图 [1-1](#Fig1) 显示了 Kubernetes 架构的构建模块。K8s master 和 K8s workers 是 Kubernetes 控制平面的一部分，而容器注册中心可能位于控制平面之外。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig1_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig1_HTML.jpg)

图 1-1

忽必烈体系结构概述

### 忽必烈大师

Kubernetes 主节点是负责管理整个集群的主要节点。K8s 工作者的编排由该节点处理。该节点是可复制的，以避免任何单点故障。控制面板访问主服务器只是为了对集群进行修改。母版由四个主要部分组成。

*   API 服务器:这是一个 Kubernetes 控制平面的前端。它维护 RESTful web 服务来定义和配置 Kubernetes 集群。

*   这是一个高度可用的组件，维护着系统中运行的所有对象的记录。Kubernetes 配置中的任何更改都存储在这里，并且允许查看这些更改以立即采取行动。

*   调度器(Scheduler):它以 pods 的形式调度 Kubernetes workers 上的工作负载。我们将在下一节介绍 pod。调度程序通读每个 pod 的资源要求，并根据可用性将 pod 分布在整个集群中。默认情况下，它还会尝试将 pod 副本分发到不同的节点，以保持高可用性。

*   **控制器管理器**:它在后台运行负责集群中不同重要任务的控制器。控制器监视 etcd 的配置变化，并将集群置于所需状态；另一方面，控制循环监视集群中的变化，并根据 etcd 努力维持所需的状态。让我们通过几个控制器示例来了解控制器在集群中的作用。
    *   **节点控制器**:它监控集群中的节点，并在节点出现或出现故障时做出响应。这一点很重要，这样调度程序就可以根据节点的可用性调整 pod，并根据 etcd 维护状态。

    *   **端点控制器**:它通过在 API 中创建端点记录来连接服务和 pod，并改变 DNS 配置以返回指向运行服务的 pod 之一的地址。

    *   **复制控制器**:复制是维护应用高可用性的一种常规做法。复制控制器确保所需数量的 pod 副本/拷贝正在集群中运行。

在本章的后面，我们将会看到这些控制器的作用。此外，还有一个云控制器管理器，它允许云提供商通过使用插件轻松地与 Kubernetes 集成。

### 不可思议的工人

现在可能很清楚，实际的应用运行在 worker 节点上。早先这些人也被称为*爪牙*。术语*的爪牙*和*的节点*在一些文档中仍然可以互换使用。每个节点有三个主要组件。

*   **Kubelet** : Kubelet 是主*节点代理*，运行在每个节点上，监视节点上的容器是否运行正常。Kubelet 接受一组 PodSpecs，这是一个描述 pod 的 YAML 或 JSON 对象，并且只监视那些 Specs 中描述的容器。注意，除了 PodSpecs 中列出的容器之外，还可以有其他容器在节点上运行，但是 Kubelet 并不监控这些容器。

*   Kube-proxy:Kubernetes 主调度程序通常在一个节点上运行多个服务。Kube-proxy 为这些服务创建了一个网络代理和负载均衡器。它可以跨一组后端执行简单的 TCP、UDP 和 SCTP 流转发或循环 TCP、UDP 和 SCTP 转发。如果进行了配置，它还允许将节点暴露给互联网。

*   **pod**:pod 是 Kubernetes 对象模型的最小单元，可以被创建、部署或销毁。Kubernetes pod 通常只有一个容器，但也允许包含一组紧密耦合的容器。pod 表示集群上正在运行的进程。它有两种广泛的用途。
    1.  **单容器 pod** :这是最常见的 Kubernetes 用例，也称为*每个 pod 一个容器*。pod 包装容器，并向 Kubernetes 提供一个抽象层来访问或修改容器。

    2.  多容器容器(multi-container pod):有些情况下，应用需要共享资源的多个紧密耦合的容器。在这样的场景中，一个 pod 在这些容器上构建一个包装器，并将它们作为一个单一的服务对待。一个例子是一个为最终用户提供 REST APIs 的容器，一个*侧柜*计算实现 API 限制的请求数量。pod 内的容器共享分配给 pod 的相同 IP，并共享相同的存储集。在接下来的章节中，我们将会看到 Istio 的边车。

如前所述，部署在每个 pod 内部的容器运行服务。容器的打包和存储依赖于容器的运行时和注册。

*   **容器运行时**:为了理解这一点，让我们试着理解一下什么是容器。容器是一个代码单元，它与依赖项打包在一起，创建一个可以在不同的计算环境中快速运行的工件。容器运行时通过提供一组基本的资源和库来让用户运行容器，这些资源和库与容器的包结合起来启动应用。容器中的应用可以自由使用自己的环境，包括存储、网络等。，限制每种资源的使用量。容器运行时还管理节点上的容器映像。有多种容器运行时可用，所以让我们来看看其中的几种。
    1.  **Rocket** : Rocket，也称为 *rkt* ，是 coreOS 提供的容器运行时。Rkt 使用了一些与 Kubernetes 类似的术语。pod 是 Rkt 的核心执行单元。但是请注意，这种豆荚不同于 Kubernetes 豆荚。Rocket 允许更细粒度的容器配置；换句话说，可以设置 pod 内部运行的应用的内存限制。Rocket 的容器遵循 app 容器规范，但也支持 Docker 图像。Rocket 带来的主要区别是它以无守护模式运行；启动的容器并不在守护进程的保护伞下运行，而是在基础机器上被赋予单独的进程 id。这允许它在同一个容器中运行多个进程，并在不终止父容器的情况下重启其中任何一个进程。

    2.  Docker 是目前最流行的容器运行时之一。如前所述，它提供轻量级容器的解决方案是需要编排的原因，这导致了对 Kubernetes 的需求。Docker 社区非常庞大，因为人们可以很容易地在注册表中获得任何作为 Docker 映像的常见包。

*   选择哪个容器运行时是个人喜好的问题，也取决于代码库的复杂程度和它所依赖的资源种类。使用 Rocket，您可以将文件描述符从一个进程传递到另一个进程，而文件描述仍然在监听。尽管这种场景并不常见，但在选择容器运行时之前，它们是需要考虑的重要场景。在本书中，我们将使用 Docker 作为我们的容器运行时。

*   **容器注册**:每一代容器都需要代码开发，从不同的包管理器添加库，并创建运行代码的基本环境。每次部署时都可以构建一个容器，但是每次获取最新的代码、获取新的库和准备环境都是非常耗时的。为了简化这一点，开发人员存储他们曾经创建的容器，并在需要时使用它。容器注册表是允许开发人员保存他们的容器图像并在需要时使用它们的地方。Azure、Docker 和 Google 等独立的提供商有自己的容器注册中心，这些注册中心在具有访问级别限制的高可用性环境中托管图像。

Kubernetes 使用容器运行时接口(CRI)与容器运行时进行交互。从 Kubernetes 1.5 开始，容器运行时被期望实现 CRI，它充当 Kubernetes Kubelet 和容器运行时之间的桥梁。CRI 提供了 Kubernetes 和容器运行时之间的抽象，使 Kubernetes 能够独立于容器运行时运行。

现在您已经理解了 Kubernetes 的架构，让我们试着理解 Kubernetes 中使用的几个重要术语。

## 库柏术语

有几个术语我们可能会在本书中经常用到。让我们来看一下其中的几个，以避免在将来的参考中出现任何混淆。

*   部署:部署是建立在 pod 上的抽象单元。要部署应用或微服务，需要在 pod 中运行它。为此，创建一个部署配置，其中规定需要部署什么以及应用的副本数量。在将这个配置提交给 Kubernetes 时，部署控制器会生成一组 pods，用配置好的副本部署应用。

*   **映像**:映像是将要部署在集群上的软件/容器。在本书中，我们将交替使用*图像*和*图像*。

*   Kubectl :这是一个与 Kubernetes 集群交互的 CLI。我们将使用它来部署集群，检查它们的状态，并更新我们的集群。

*   **Namespace** :顾名思义，这是用来对同一个 Kubernetes 实例上的多个虚拟集群进行分组，或者组织同一个集群内的资源。它允许唯一地标识每个资源。

*   **Replicaset** :这与复制控制器相同，它额外支持基于集合的选择器，而不是基于等式的选择器。这在本章后面的例子中会更清楚。

*   **Service** :这是对部署在一个或多个 pod 上的应用如何被内部或外部访问的描述。由于 pod 不是永久性的，Kubernetes 可能会根据可用性不时地重新部署 pod，因此不建议依赖直接访问 pod。该服务发现 pods 中运行的应用，并通过端口、负载均衡器或其他机制提供对它们的访问。

*   **StatefulSet** :这类似于管理 pod 的排序和唯一性的部署。换句话说，如果一个单元死了，StatefulSet 控制器会产生一个新的单元，它具有与死单元相同的身份和资源。

这些并不是本书中使用的所有术语，但是这个列表应该足以让我们开始创建我们的第一个 Kubernetes 集群。在此之前，我们需要设置 Kubernetes 环境。

## 建立一个坚不可摧的群集

如前所述，Minikube 是一个在本地运行 Kubernetes 集群的工具。因为它是本地的，所以它提供了一个单节点 Kubernetes 集群。Minikube 在虚拟机管理程序上启动自己的服务器。为简单起见，我们将使用 VirtualBox 作为管理程序，它可用于 Windows、Linux 和 macOS。

### 安装 VirtualBox

开始之前，请确保在系统 BIOS 中启用了 AMD-v 或 VT-x 虚拟化。这允许您在机器上运行 VirtualBox 实例。按照 [`https://www.virtualbox.org/wiki/Downloads`](https://www.virtualbox.org/wiki/Downloads) 的步骤下载并安装 VirtualBox。安装完成后，让我们安装 Kubectl。

### install kubectl 安装 kubectl

如前所述，Kubectl 是与 Kubernetes 集群交互的 CLI。在不同的平台上设置 Kubectl 会有所不同。让我们一个一个地看。

#### Linux 安装

Kubectl 的最新版本可以通过以下网址下载:

```
scurl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl

```

将下载的文件制作成可执行文件，并将其移动到您的`PATH`中。

```
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl

```

#### macOS 安装

macOS 上的安装类似于 Linux 设置。

```
curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl

```

将下载的文件制作成可执行文件，并将其移动到您的`PATH`中。

```
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl

```

#### Windows 安装

使用以下网址下载最新版本:

```
curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.14.0/bin/windows/amd64/kubectl.exe

```

将二进制 EXE 文件添加到 Windows 中的`PATH`中。

### 设置迷你库

在不同的操作系统上安装 Minikube 需要不同的步骤。

#### Linux 安装

Kubectl 的最新版本可以通过以下网址下载:

```
curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64

```

将下载的文件制作成可执行文件，并将其移动到您的`PATH`中。

```
chmod +x minikube
sudo mv ./minikube /usr/local/bin/minikube

```

#### macOS 安装

macOS 上的安装类似于 Linux 设置。

```
curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64

```

将下载的文件制作成可执行文件，并将其移动到您的`PATH`中。

```
chmod +x minikube
sudo mv ./minikube /usr/local/bin/minikube

```

#### Windows 安装

对于 Windows，最好使用包管理器来处理安装开销。一个流行的 Windows 包管理器是 Chocolatey ( [`https://chocolatey.org`](https://chocolatey.org) )。它允许快速安装 Minikube。安装完 Chocolatey 后，以管理员身份运行`choco`。

```
choco install minikube kubernetes-cli

```

就这样。

### 设置 Docker

在您的本地系统上安装 Docker 允许 Minikube 从您的本地系统访问图像。与 Minikube 类似，Docker 的设置对于不同的操作系统也有所不同。

#### Linux 安装

我们将使用 Ubuntu 库安装 Docker。其他 Linux 安装请访问 [`https://docs.docker.com/install/linux/docker-ce/centos/`](https://docs.docker.com/install/linux/docker-ce/centos/) 。

1.  更新本地存储库。

    ```
    sudo apt-get update

    ```

2.  安装依赖包。

    ```
    > sudo apt-get install \
        apt-transport-https \
        ca-certificates \
        curl \
        gnupg-agent \
        software-properties-common

    ```

3.  添加Docker工人的 GPG 键。

    ```
    > curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

    ```

4.  将存储库添加到`apt`。

    ```
    > sudo add-apt-repository \
       "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
       $(lsb_release -cs) \
       stable"

    ```

5.  更新本地存储库以提取 Docker 包。

    ```
    > sudo apt-get update

    ```

6.  使用以下命令安装 Docker:

    ```
    > sudo apt-get update

    ```

7.  安装`docker-ce`和`cli`。

    ```
    > sudo apt-get install docker-ce docker-ce-cli containerd.io

    ```

#### macOS 安装

在 macOS 上安装的最简单方法是下载并安装 DMG 文件，可从以下网址获得:

```
https://hub.docker.com/editions/community/docker-ce-desktop-mac

```

#### Windows 安装

与 macOS 类似，Docker 提供了一个安装程序，可从以下网址获得:

```
https://hub.docker.com/editions/community/docker-ce-desktop-windows

```

我们将用 Java 和 Python 开发和部署一些应用。因此，我们将需要这两种语言的 SDK。

### 设置 Python

按照 [`https://www.python.org/downloads/`](https://www.python.org/downloads/) 的步骤，可以轻松完成 Python 的设置。

### 设置 Java

与 Python 类似，按照 [`https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html`](https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) 的步骤就可以轻松完成 Java 的设置。

## 我们的第一个 Kubernetes 集群

设置完成后，让我们启动第一个 Kubernetes 服务器。为了简单起见，我们将展示 Ubuntu 终端的输出。

```
> minikube start
Starting local Kubernetes v1.13.2 cluster...
Starting VM...
Getting VM IP address...
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Stopping extra container runtimes...
Starting cluster components...
Verifying kubelet health ...
Verifying apiserver health ...
Kubectl is now configured to use the cluster.
Loading cached images from config file.
Everything looks great. Please enjoy minikube!

```

这将在 VirtualBox 上生成一个新的虚拟机，只需一些网络设置，允许基本系统访问它。Kubernetes 集群将被限制在这个虚拟机上。在开发和部署期间的任何时候，如果集群看起来很慢或者您的本地系统开始消耗超过预期的资源，您可以使用以下命令关闭虚拟机:

```
> minikube stop

```

此外，您可以从 VirtualBox UI 调整该虚拟机使用的资源。请注意，就本书的范围而言，建议允许该虚拟机至少使用两个 CPU 内核和 4gb RAM。

您可以通过运行以下命令来查看 Kubernetes 集群的简介:

```
> minikube dashboard
Enabling dashboard ...
Verifying dashboard health ...
Launching proxy ...
Verifying proxy health ...
Opening http://127.0.0.1:58969/api/v1/namespaces/kube-system/services/http:kubernetes-dashboard:/proxy/ in your default browser...

```

图 [1-2](#Fig2) 显示了 Minikube 仪表盘。如果您能够看到控制面板，那么您的集群已经启动并运行，可以部署应用了。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig2_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig2_HTML.jpg)

图 1-2

Minikube 仪表板

## 在 Kubernetes 上运行应用

我们已经准备好了 Kubernetes 集群，所以让我们尝试在其上部署一个应用，并了解它是如何发生的。

### 申请详情

让我们从使用 Flask 在 Python 中创建一个简单的 web 应用开始。`pip`是 Python 的一个包管理器。它可以通过以下方式安装:

```
> curl https://bootstrap.pypa.io/get-pip.py | python

```

一旦`pip`安装好，烧瓶就可以这样安装:

```
> pip install flask

```

让我们创建一个名为`WebApp`的项目，里面有`app.py`来处理 web 请求。应用结构应该是这样的:

```
.
|____WebApp
| |____app.py
| |____requirement.txt
| |____Dockerfile

```

编辑`app.py`创建一个简单的监听器。文件见清单 [1-1](#PC26) 。

```
from flask import Flask
app = Flask(__name__)

@app.route("/")
def main():
    return "Welcome!"

if __name__ == "__main__":
    app.run(host='0.0.0.0')

Listing 1-1Web Requests Handler: app.py

```

让我们创建一个 Dockerfile 文件来封装应用。清单 [1-2](#PC27) 解释了容器的创建。

```
FROM ubuntu:18.04
RUN apt-get update -y && apt-get install -y python-pip python-dev
COPY ./requirement.txt /app/requirement.txt
WORKDIR /app
RUN pip install -r requirement.txt
COPY . /app
ENTRYPOINT [ "python" ]
CMD [ "app.py" ]

Listing 1-2Dockerfile to Containerize the Application

```

Minikube 的 Docker 环境和存储的图像是不同的。我们将把容器映像直接存储在 Minikube 实例上，而不是将映像存储到我们的本地环境中，发送到注册表，然后再将它们放回 Minikube 上。

```
> eval $(minikube docker-env)

```

构建名为`web-app`的`WebApp`应用容器，并分配版本 1.0。

```
> docker build -t web-app:1.0 .

```

图 [1-3](#Fig3) 显示了创建的新容器图像。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig3_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig3_HTML.jpg)

图 1-3

创建 web 应用后，Minikube 服务器上的图像可用

### 部署应用

让我们创建我们的第一个部署配置。这告诉 Kubernetes 为我们的应用创建一个容器。清单 [1-3](#PC30) 显示了我们的 webapp 的`webapp-deployment.yaml`文件。

```
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: webapp-deployment
  labels:
    app: webapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - name: webapp
        image: web-app:1.0
        imagePullPolicy: Never
        ports:
        - containerPort: 5000

Listing 1-3webapp-deployment.yaml File for Web App

```

让我们试着理解 YAML 文件。

*   `apiVersion`:这是用于创建该对象的 API 版本。

*   这说明我们正在创建一个 Kubernetes 部署。

*   `metadata`:这指定了部署的名称(一个必需的键)和可能想要放在部署上的可选标签。

*   `replicas`:指定要为此部署创建的单元数量。

*   这就是部署如何设法定位 pod 的方法。

*   `template.metadata`:从该部署创建的 pod 将从这些标签中命名。

*   `containers`:指定需要在这个 pod 中部署的容器。在我们的例子中，我们使用在上一节中创建的映像部署一个容器。由于我们在上一节中确保了该映像对于 Kubernetes 集群是可用的，所以我们没有将该映像上传到任何注册表，因此`imagePullPolicy`被设置为`Never`。

*   `ports`:这是暴露给集群的容器的端口。

让我们使用以下代码在集群上部署应用:

```
> kubectl apply -f webapp-deployment.yaml

```

前面的命令在 Kubernetes 集群上应用了 YAML 定义的配置。换句话说，它创建了一个名为`webapp-deployment`的部署。图 [1-4](#Fig4) 显示了集群上的所有部署及其状态以及运行和活动副本的数量。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig4_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig4_HTML.jpg)

图 1-4

在 Kubernetes 集群上运行的部署

该图显示有一个 pod 正在运行`WebApp`应用。部署产生了一个复制集，它试图保持一个 pod 一直运行的状态。图 [1-5](#Fig5) 和图 [1-6](#Fig6) 显示了集群上正在运行的副本集和 pod。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig6_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig6_HTML.jpg)

图 1-6

在集群上运行的 pod

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig5_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig5_HTML.jpg)

图 1-5

副本集从部署开始

pod 详细信息包括 IP 地址。内部网络可以使用该 IP 地址访问 pod，但是如前所述，不鼓励通过 IP 地址直接访问 pod，因为 pod 是消耗品，新的 pod 可能具有不同的 IP 地址。从 IP 地址可以清楚地看出，虽然可以通过 Kubernetes 网络内部的 IP 地址访问 pod，但是可能无法从主机访问它。Kubectl 提供了一种为 pod 使用代理并从主机访问应用的方法。

```
> kubectl port-forward webapp-deployment-7946f7db77-gtsbg 5000:5000

```

`webapp-deployment-7946f7db77-gtsbg`是我们的 pod 名称(参见图 [1-6](#Fig6) )，5000 是 pod 上暴露的用于访问应用的端口。图 [1-7](#Fig7) 显示端口转发的输出。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig7_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig7_HTML.jpg)

图 1-7

端口将主机端口转发到 pod 端口

现在可以从主机上访问应用了。图 [1-8](#Fig8) 显示了在主机浏览器上运行的应用。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig8_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig8_HTML.jpg)

图 1-8

转发到主机并可在浏览器中访问的应用端口

可以使用以下命令从 pod 中访问应用日志:

```
> kubectl log -f webapp-deployment-7946f7db77-gtsbg 5000:5000

```

图 [1-9](#Fig9) 显示了 pod 日志的输出。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig9_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig9_HTML.jpg)

图 1-9

通过注销可以看到 Pod 日志

### 库比涅斯的服务，库比涅斯的服务，库比涅斯的服务，库比涅斯的服务，库比涅斯的服务，库比涅斯的服务，库比涅斯的服务，库比涅斯的服务

库伯内特豆荚是可牺牲的。ReplicaSet 在放大和缩小的过程中创建和破坏豆荚；因此，通过 IP 地址访问 pod 不是一个可靠的解决方案。那 Kubernetes 内部的微服务是怎么和其他微服务沟通的呢？答案是 *Kubernetes 服务*。让我们试着理解服务的概念。

Kubernetes 服务提供了一个虚拟的基于 IP 的桥梁来访问 pod。用户可以访问单个 pod，也可以同时访问一组 pod。可以有两种类型的交互。

*   Pods 访问服务

*   公开的服务

在解释这一点之前，让我们通过服务公开我们的 web 应用。清单 [1-4](#PC34) 显示了一个简单的服务，选择器指向我们的 webapp。

```
apiVersion: v1
kind: Service
metadata:
  name: webservice
spec:
  selector:
    app: webapp
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5000

Listing 1-4webapp-service.yaml File for Our Web App

```

该服务被命名为`webservice`，并通过选择器`app:webapp`指向部署。该服务在端口 80 上公开，并将请求代理到结果窗格的端口 5000。使用以下方式应用服务:

```
> kubectl apply -f webapp-service.yaml

```

使用以下命令验证服务是否已成功创建:

```
> kubectl describe service webservice

```

图 [1-10](#Fig10) 显示了创建的服务的描述。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig10_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig10_HTML.jpg)

图 1-10

使用选择器应用创建的指向窗格的服务:webapp

该服务被分配一个群集 IP 地址 10.107.243.100。集群中的任何微服务都可以通过端口 80 使用这个 IP 地址访问服务。

现在，让我们试着理解 Kubernetes 集群中可能存在的两种服务交互。

#### Pods 访问服务

任何微服务架构都需要一个服务来访问私有网络内的多个微服务。通过其他服务的 IP 地址或通过 DNS 请求，可以访问其他服务。Kubernetes 支持他们两个。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig11_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig11_HTML.jpg)

图 1-11

定义了服务端点的环境变量

*   DNS :虽然这不是默认设置，但它是可选的，但推荐 Kubernetes 使用。顾名思义，每个服务一创建就为自己注册一个 DNS 记录。DNS 记录遵循模式 *<服务名>。<命名空间>* 。同一名称空间内的任何 pod 都可以通过 *<服务名>* 直接访问服务，而名称空间外的 pod 必须包含*。<命名空间>* 来访问服务。

*   **环境变量**:当一个 pod 在一个节点中启动时，Kubectl 声明所有正在运行的服务作为 pod 的环境变量被访问。但这迫使人们遵循一个顺序；如果新服务是在第一个服务启动后定义的，则第一个服务不能访问新服务。尝试登录到`webapp` pod 的 Docker 容器并检查环境变量。新服务不可见。如果开发人员删除现有部署并重新创建部署，则服务在环境变量中可见。图 [1-11](#Fig11) 显示了第二种情况的环境变量。

#### 公开的服务

向外部世界公开服务有多种方式。Kubernetes 提供了多种方法来实现这一点。

##### ClusterIP(群集 IP)

这允许通过集群的内部 IP 公开服务。如前所述，集群的内部 IP 地址是公开的，可以被集群内部的 pod 访问。

##### 节点端口

这允许在特定端口的节点 IP 地址上公开服务。这允许通过 *<节点 IP > : <端口>* 地址访问服务。Kubernetes 在内部创建一个 ClusterIP 服务，作为节点 IP 和实际服务之间的连接。端口号可以在 30000 和 32767 之间。每个节点将选定的端口代理到服务箱。

##### LoadBalancer(负载均衡器)

这将在节点端口上创建一个公共 IP。因此，可以通过公共 IP 访问该服务，该服务被路由到 NodePort，然后被进一步路由到 ClusterIP。它的实现因云提供商而异。对配置的一个小的添加创建了一个`LoadBalancer`类型。清单 [1-5](#PC37) 展示了在服务中添加一个`LoadBalancer`类型。

```
apiVersion: v1
kind: Service
metadata:
  name: webservice
spec:
  type: LoadBalancer
  selector:
    app: webapp
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5000

Listing 1-5webapp-service-loadbalancer.yaml File for Our Web App

```

使用此配置创建服务后，开发人员可以使用以下命令检查服务的外部 IP 地址:

```
> kubectl get service webservice

```

图 [1-12](#Fig12) 显示了我们的例子。我们没有获得外部 IP 地址，因为我们是在 Minikube 上运行我们的应用。在云上，外部 IP 由一个值填充。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig12_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig12_HTML.jpg)

图 1-12

已部署负载均衡器类型服务

##### 外部名

这只是使用 CNAME 记录将服务映射到一个地址。这些通常在从集群内部使用外部服务并抽象出外部服务的实际链接时使用。清单 [1-6](#PC39) 显示了一个类型为`ExternalName`的简单服务。

```
apiVersion: v1
kind: Service
metadata:
  name: db1
spec:
  type: ExternalName
  externalName: mysql01.database.test.com

Listing 1-6database-external-name.yaml Showing ExternalName Configuration

```

当内部 pod 寻找服务`db1`时，它们接收到一个`mysql01.database.text.com` *的 CNAME 记录。*不涉及转发；在 DNS 级别只发生一次重定向。

`ExternalName`还允许开发者向服务添加自定义 IP 地址，客户端可以通过该地址访问服务。IP 分配是集群管理器的唯一职责；它不是来自库伯内特斯。清单 [1-7](#PC40) 展示了一个服务的外部 IP 分配的例子。

```
apiVersion: v1
kind: Service
metadata:
  name: externalIpAssignedService
spec:
  selector:
    app: externalIpService
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 9000
  externalIPs:
  - 70.34.1.23

Listing 1-7External IP Assigned to a Service

```

如前所述，Kubernetes 是一个自我修复的平台。让我们试着在集群上玩一玩，看看 Kubernetes 服务在其中的作用。

### Kubernetes 是自愈的

在任何应用中，很难保证单个节点 100%的正常运行时间或可用性。Kubernetes 提供了一种创建服务副本的方法，并确保副本的数量保持不变。让我们修改我们的部署并增加副本的数量。

```
> kubectl scale --replicas=2 deployment webapp-deployment
> kubectl get deployments

```

图 [1-13](#Fig13) 显示了展开的结果

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig13_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig13_HTML.jpg)

图 1-13

增加副本后的部署状态

```
> kubectl get pods

```

图 [1-14](#Fig14) 显示了运行吊舱。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig14_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig14_HTML.jpg)

图 1-14

增加副本后的部署状态

如果有人试图杀死任何一个 pod，复制控制器会尝试恢复状态并产生一个新的 pod。让我们试着终止其中一个 pod 来查看应用的状态。图 [1-15](#Fig15) 显示了一个 pod 的删除。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig15_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig15_HTML.jpg)

图 1-15

从集群中强制删除一个 pod

图 [1-16](#Fig16) 显示了一个新的 pod 如何自动衍生以匹配复制号。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig16_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig16_HTML.jpg)

图 1-16

删除的 pod 终止时，会产生新的 pod

通过这一点，Kubernetes 试图保持服务在任何时候都可用。

## 添加微服务

现在你已经看到了如何在 Kubernetes 上部署和运行一个微服务，也看到了微服务如何相互交互的理论。让我们创建一个新的微服务，它使用来自 webapp 的响应并将其呈现给 UI。我们姑且称这个 app 为`istio-frontend`。我们已经创建了一个 Docker 文件。

### 应用设置

`istio-frontend`是一个 Java 应用，它向`webapp`服务发出请求，并用接收到的数据填充它的 web 页面。如果没有收到数据或者`web-app`服务不可用，它填充`ERROR RECEIVED`作为响应。我们已经创建了一个标签为`frontend-app:1.0`的 Docker 文件。让我们遵循与前面的应用相同的方法，为应用创建一个部署和服务。清单 [1-8](#PC43) 和清单 [1-9](#PC44) 显示了部署和服务文件。

```
apiVersion: v1
kind: Service
metadata:
  name: frontendservice
spec:
  selector:
    app: frontend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080

Listing 1-9frontend-service.yaml Configuration

```

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend-deployment
  labels:
    app: frontend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: frontend:1.0
        imagePullPolicy: Never
        ports:
        - containerPort: 8080

Listing 1-8frontend-deployment.yaml Configuration

```

图 [1-17](#Fig17) 显示了可用的新服务。让我们尝试代理新服务，让应用运行起来。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig17_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig17_HTML.jpg)

图 1-17

新的前端服务可用

图 [1-18](#Fig18) 显示了输出页面。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig18_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig18_HTML.jpg)

图 1-18

代理端口到前端 pod 的输出

将`webapp`服务的副本计数减少到 0 给出了如图 [1-19](#Fig19) 和图 [1-20](#Fig20) 所示的状态。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig20_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig20_HTML.jpg)

图 1-20

如果无法与后端服务通信，前端会显示错误

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig19_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig19_HTML.jpg)

图 1-19

webapp 的副本减少到 0 个

### 发布和部署

在大型组织中，任何投入生产的应用都需要定期开发和维护。随着像敏捷这样的新方法的出现，发布频率已经增加到一天发布多个版本，发布回滚也是如此。关闭应用、重新部署和重新启动的传统过程会导致停机。在 99.99%可用性的世界里，停机时间的范围意味着在七天的时间里不超过一分钟，所以一周一次的发布违反了敏捷方法。

为了最大限度地减少停机时间，使用了多种部署技术，例如蓝绿色、淡黄色和滚动部署。我们将在后面的章节中讨论这些技术。默认情况下，Kubernetes 遵循滚动部署。换句话说，它创建了两个完全相同的环境，一旦新环境启动，流量将被路由到新环境，而旧环境将被终止。

让我们将我们的 webapp 升级到 2.0，看看 Kubernetes 上的部署是如何运行的。清单 [1-10](#PC45) 显示了文件中的变化。我们将简单地在欢迎消息中添加时间。

```
from flask import Flask
import datetime

app = Flask(__name__)

@app.route("/")
def main():
    currentDT = datetime.datetime.now()
    return "Welcome user! current time is " + str(currentDT)

if __name__ == "__main__":
    app.run(host='0.0.0.0')

Listing 1-10Updated Web Requests Handler: app.py

```

按照前面所述的相同过程创建一个新容器。清单 [1-11](#PC46) 显示了修改后的部署文件和升级后的容器细节。

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-deployment
  labels:
    app: webapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - name: webapp
        image: web-app:2.0
        imagePullPolicy: Never
        ports:
        - containerPort: 5000

Listing 1-11Updated webapp-deployment-v2.yaml for webapp 2.0

```

让我们使用以下代码在集群上部署应用:

```
> kubectl apply -f webapp-deployment-v2.yaml

```

一个新的圆荚体产生了，一旦新的圆荚体准备好了，先前的圆荚体就终止了。图 [1-21](#Fig21) 显示了新部署的应用的输出。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig21_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig21_HTML.jpg)

图 1-21

前端显示来自后端服务的新响应

在后台发生的是一个新的环境，有一台机器和 2.0 版本，而`webapp`服务仍然指向旧的环境。一旦新产生的 pods 返回了`running`状态，`webapp`服务将流量指向新的环境，早期的 pods 被终止。

这里有一个问题:当一个新的 pod 产生了，但是里面的应用还在部署，还没有启动，会发生什么呢？此时，pod 返回一个*运行*状态，但是应用仍然关闭，同时服务开始将流量定向到新环境。这增加了服务的停机时间，直到应用启动并运行。为了解决这个问题，Kubernetes 使用了一个就绪探测器。

## 就绪探测

用新部署更新部署会导致停机，因为旧部署会被新部署取代。如果由于某种原因，新部署配置错误或有一些错误，停机时间将继续，直到检测到错误。当使用就绪探测时，服务不会将流量转发到新的 pod，直到探测成功。它还确保在新的部署单元准备好之前旧的单元不会被终止。这确保了出现错误的部署根本不会收到任何流量。

为了整合就绪性调查，我们需要向我们的 webapp 添加一个健康链接。清单 [1-12](#PC48) 显示了`app.py`代码的变化。添加了一个`/health`链接，该链接将在应用启动并运行后可用。代码中添加了 60 秒的延迟，这将有助于演示 Kubernates 的这种行为。

```
from flask import Flask
import datetime
import time

time.sleep(60)
app = Flask(__name__)

@app.route("/")
def main():
    currentDT = datetime.datetime.now()
    return "Welcome user! current time in v3 is " + str(currentDT)

@app.route("/health")
def health():
    return "OK"

if __name__ == "__main__":
    app.run(host='0.0.0.0')

Listing 1-12Addition of Health Link to app.py

```

创建一个带有标签`web-app:3.0`的新容器，并将其添加到部署文件中，如清单 [1-13](#PC49) 所示。

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-deployment
  labels:
    app: webapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - name: webapp
        image: web-app:3.0
        imagePullPolicy: Never
        ports:
        - containerPort: 5000
        readinessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 40

Listing 1-13Updated webapp-deployment-v3.yaml for web-app 3.0

```

就绪探测器初始化的初始延迟为 40 秒。如果已经知道应用部署需要一些时间，可以在`initialDelaySeconds`中说明，以避免对应用进行不必要的检查。在最初的延迟之后，Kubelet 会定期检查`/health`链路，当链路启动时，pod 会进入就绪状态以接受流量。图 [1-22](#Fig22) 显示了不同时间的展开状态。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig22_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig22_HTML.jpg)

图 1-22

带就绪状态检查的部署

我们来看看后台发生了什么。

1.  已检查可用的部署。A `frontend-deployment`和 a `webapp-deployment`正在工作，每个都有一个可用的 pod 处于就绪状态。

2.  应用了新的版本 3 配置。

3.  准备舱的数量保持不变。

4.  在获取 pod 的详细信息时，我们可以看到两个`webapp-deployment`pod。旧的已经准备好了，最新的是*运行*但是仍然没有准备好接受流量。

5.  在 40 秒时，Kubernetes 没有触发对准备就绪探测器的请求；因此，pod 仍处于就绪-待定状态。默认情况下，运行状况检查每 10 秒进行一次。

6.  部署 60 秒后，新的吊舱升级到*就绪*状态，旧的吊舱转移到*终止*状态。

这确保了在新部署准备就绪之前，先前的部署不会被丢弃，并且流量会被路由到较旧的部署。这在升级应用或部署新应用时很有帮助。但是在部署完成并且旧的部署单元终止之后，这就没有用了。如果在此之后，部署单元由于已知/未知的原因而失败，则就绪性探测失败，并且流量不会被发送到单元。一方面，这确保了应用不会停机，但是可用于服务流量的 pod 数量会减少。一种极端情况是，部署中的所有单元都出现了同样的问题；你的完整申请可能会被否决。

没有理想的方法来处理这样的问题，但是 Kubernetes 提供了一个常见的解决方案，如果应用变得不负责任，就重启应用。活跃度探测与就绪性探测类似，对应用进行检查，如果应用停止响应，它会重新启动 pod。

让我们在应用中做一个小小的改动，在 60 秒内终止应用，并观察活跃度探测器的行为。清单 [1-14](#PC50) 显示了变化。

```
from flask import Flask
import datetime
import time
import threading
import os

time.sleep(60)
app = Flask(__name__)

@app.route("/")
def main():
    currentDT = datetime.datetime.now()
    return "Welcome user! current time is " + str(currentDT)

@app.route("/health")
def health():
    return "OK"

def exit_after():
    time.sleep(60)
    os._exit(1)

exit_thread = threading.Thread(target=exit_after)
exit_thread.start()

if __name__ == "__main__":
    app.run(host='0.0.0.0')

Listing 1-14Autostopping

the Application After Some Time in app.py

```

创建一个标签为`web-app:4.0`的新容器，并将其添加到部署文件中，如清单 [1-15](#PC51) 所示。

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-deployment
  labels:
    app: webapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - name: webapp
        image: web-app:4.0
        imagePullPolicy: Never
        ports:
        - containerPort: 5000
        readinessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 40
        livenessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 120

Listing 1-15Updated webapp-deployment-v4.yaml for web-app 4.0

```

活性探测器初始化有 120 秒的延迟。因为我们已经知道应用的启动时间需要 60 秒，所以在应用启动之前重启它是没有用的。遵循与`redinessProbe`相同的过程来检查应用的健康状况。让我们看看图 [1-23](#Fig23) 中的动作变化。

![../images/483921_1_En_1_Chapter/483921_1_En_1_Fig23_HTML.jpg](../images/483921_1_En_1_Chapter/483921_1_En_1_Fig23_HTML.jpg)

图 1-23

准备就绪和活动状态检查部署

假设我们的应用在部署后的某个时候失败了，Kubernetes 尝试这样恢复它:

1.  当应用停止运行时，就绪探测会失败。

2.  Kubernetes 停止了那个 pod 上的通信，并将自己限制在其余的复制品上。在我们的例子中，由于我们只有一个副本，应用必然会停机。

3.  活性探测器停止工作，因为它位于同一健康链路上。

4.  Kubernetes 尝试重启 pod 并恢复应用状态。

5.  重启后，应用启动，就绪探测成功。

6.  这个舱的通信恢复了。

## 摘要

在这一章中，我们回顾了 Kubernetes 的简史。现在，您已经了解了它的基本组件，并学习了其中使用的术语。我们用 Minikube 和 Docker 容器运行时在本地设置 Kubernetes。我们还创建了一个示例应用，并展示了集群中的应用部署以及 Kubernetes 应用如何自我修复。

在下一章中，我们将介绍微服务架构、其面临的挑战，以及如何使用服务网格解决这些挑战。