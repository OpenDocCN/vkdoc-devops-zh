# 七、应用指标

在前一章中，我们介绍了 Istio 提供的弹性，通过将代码中的复杂性抽象到 Envoy 代理来提高服务的可用性和持久性。在生产环境中，总有失败的时候。这可以通过从系统收集的数据来确定，然后可以相应地准备这些数据。度量收集是任何系统的重要部分，但是在分布式系统中，很难简单地读取数据并快速理解数据。开源工具有助于数据的收集和可视化。我们将在这一章中讨论其中的几个。

## 应用监控

对于应用的不同用例，监控是主观的。对于一个静态网站，仅仅检查网站是否在运行就足够了。这可以通过 Pingdom 等流行的服务提供商来实现，因为网站是公开的。而对于使用微服务架构运行的 web 应用，包括数据库在内的许多服务可能不是公共的。对于这样的场景，外部检查可能会说 web 应用没有运行，但是不能确定故障点。在这种情况下，对哪个服务失败进行内部检查可能会更有帮助。这就是为什么我们需要在运行应用的私有网络中使用监控工具。我们在本书中一直使用的 K8s 提供了失败服务的自动恢复。图 [7-1](#Fig1) 显示了不同类型应用中的监控机制。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig1_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig1_HTML.jpg)

图 7-1

静态网站的监控和分布式系统的监控

识别和修复故障组件是好的，但是这个过程会造成一些停机时间。如今，所有应用都以 99.9%的可用性为目标，这可以通过采取预防措施而不是事后补救系统故障来实现。在任何应用进入生产环境之前，我们都要处理负载能力，并确定系统可能出现故障的阈值。尽管如此，仍然存在系统可能由于未知情况而失败的情况。记住这一点，开发人员获取服务的基本指标，如请求数量、响应时间、响应状态等。，以及运行服务的节点的基本指标，如 CPU 利用率和内存消耗。负载能力有助于确定与请求和响应相关的阈值，当节点过载或内存不足时，会有一些标准。一旦我们有了这些指标和阈值细节，我们就可以通过收集和分析这些指标来监控应用。基于分析，我们可以确定应用何时会失败。

当应用即将失败时，给开发人员或 DevOps 或各自的利益相关者的消息可能有助于他们做好准备，或者在应用崩溃之前拯救系统。这就是警报发挥作用的地方。根据警报的严重性和应用的使用情况，警报可以使用不同的渠道，从简单的电子邮件到电话。

图 [7-2](#Fig2) 展示了一对参数的阈值以及超过阈值时的动作。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig2_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig2_HTML.jpg)

图 7-2

达到阈值后向风险承担者发送警报

如图 [7-2](#Fig2) 所示，整个监控过程可分为三大步骤。

1.  应用度量收集

2.  度量分析

3.  需要时提醒利益相关方

让我们看看 Istio 如何在三步流程中提供帮助。

## Istio Mixer

在前几章中，我们看到了 Mixer 如何从 Istio 数据平面获取遥测数据。收集的数据是关于服务如何相互交互以及实例的 CPU 和内存消耗。图 [7-3](#Fig3) 显示了从 Mixer 到后端服务的数据流程；在这种情况下，我们使用普罗米修斯。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig3_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig3_HTML.jpg)

图 7-3

指标从数据平面流向普罗米修斯

指标从数据平面流向 Mixer，Mixer 提取*属性*并通过配置模型传递它们，配置模型确定需要传递什么以及以什么形式传递给适配器。适配器将数据传递给后端服务，在本例中是 Prometheus。在我们深入探讨这个问题之前，让我们先来看看普罗米修斯是如何工作的。

## 普罗米修斯

Prometheus 是一款开源监控和警报工具。它基本上将所有数据存储为一个时间序列，根据指标名称和称为标签的键值对进行分组。普罗米修斯公司提供以下产品:

*   不同指标的时间序列数据

*   分析数据的查询语言

*   警报系统根据第二步中完成的分析发送通知

Prometheus 通过 HTTP 上的拉模型收集指标。换句话说，需要向 Prometheus 配置提供端点来收集指标数据。它在本地存储所有数据，并对数据运行规则，以得出新的时间序列数据或生成警报。图 [7-4](#Fig4) 显示了所有利益相关者之间的数据流。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig4_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig4_HTML.jpg)

图 7-4

普罗米修斯度量流

让我们从在 K8s 集群上设置普罗米修斯开始。

### 装置

Prometheus 预配置了 Istio。Mixer 有一个内置的 Prometheus 适配器，公开为生成的指标值提供服务的端点。Prometheus 服务器作为附件出现在安装的 Istio 集群中。它也可以安装使用Helm图表在一个单一的步骤。

```
helm install --name prometheus stable/prometheus

```

这可以进一步配置，以提供不同的存储、进入规则等，但我们不在这里讨论这些。有关更多配置信息，请参考 Prometheus 文档。

Istio 的 Prometheus 附加组件预配置为收集混合器端点以收集公开的指标。可用的端点如下:

*   `istio-telemetry.istio-system:42422/metrics`:返回所有混合器生成的指标。

*   `istio-telemetry.istio-system:15014/metrics`:这将返回所有特定于混音器的指标。这将从 Mixer 返回指标。

*   返回特使生成的原始数据。普罗米修斯被配置为寻找`envoy-prom`端点暴露的吊舱。附加组件配置在收集期间过滤掉大量特使度量，以试图限制附加组件进程的数据规模。

*   `istio-pilot.istio-system:15014/metrics`:返回导频生成的指标。

*   `istio-galley.istio-system:15014/metrics`这将返回厨房生成的指标。

*   `istio-policy.istio-system:15014/metrics`:这将返回所有与策略相关的度量。

*   `istio-citadel.istio-system:15014/metrics`:返回所有 Citadel 生成的指标。

该插件将时间序列数据保存在其文件系统中。这对我们很有用。对于生产环境，单独设置 Prometheus 或为其定义不同的数据存储可能更好。

如图 [7-3](#Fig3) 所示，指标通过配置模型到达 Prometheus，配置模型具有通过规则连接的实例和处理程序。Istio Prometheus 配置提供的预定义实例如下:

*   `accesslog`:捕获请求源和目的地详细信息的日志条目

*   `attributes`:捕获源和目标 pod、工作负载和命名空间的详细信息

*   `requestcount`:捕获从源到目的地的请求数量

*   `requestduration`:捕捉网格中所有调用的响应时间

*   `requestsize`:捕获从源发送到目的地的有效载荷的请求大小

*   `responsesize`:捕获从源发送到目的地的有效载荷的响应大小

*   `tcpaccesslog`:捕获 TCP 请求的度量

*   `tcpbytereceived`:捕获 TCP 请求中目的地接收的字节

*   `tcpbytesent`:捕获 TCP 请求中源发送的字节

*   `tcpconnectionsclosed`:捕获 TCP 连接关闭的次数

*   `tcpconnectionsopened`:捕获 TCP 连接打开的次数

每个实例数据通过其处理程序被推入 Prometheus。让我们访问网格中的普罗米修斯节点，并在进一步移动之前查看仪表板。

### 普罗米修斯仪表板

Prometheus 节点驻留在`istio-system`名称空间中，如前所述，它将时间序列数据保存在本地文件系统中。通过端口转发请求来访问 pod 很简单，如图 [7-5](#Fig5) 和图 [7-6](#Fig6) 所示。您可以配置一个网关和访问它的规则，但是我们在这里不描述这些步骤。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig5_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig5_HTML.jpg)

图 7-5

端口转发到 Istio 网格中的 Prometheus 实例

图 [7-6](#Fig6) 显示了如何访问`localhost:9090`上的仪表板。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig6_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig6_HTML.jpg)

图 7-6

普罗米修斯仪表盘在 Istio 网格内运行

仪表板允许我们查询从网格中收集的不同指标。让我们看一个请求计数指标的简单示例。为此，让我们将一些请求放入我们的服务中，如图 [7-7](#Fig7) 所示。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig7_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig7_HTML.jpg)

图 7-7

对前端服务的围攻请求

这些请求的指标由 Mixer 收集，并传递给 Prometheus 后端服务。收集的指标现在可以在仪表板中看到，如图 [7-8](#Fig8) 所示。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig8_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig8_HTML.jpg)

图 7-8

普罗米修斯公司记录的所有请求指标

我们只发出了四个请求，但是控制台中提供了许多请求指标。这是因为 Prometheus 已经跟踪了所有请求，包括发送给`istio-system`的记录遥测数据的请求。让我们尝试使用 Prometheus 查询语言(也称为 PromQL)将请求限制到我们的名称空间。图 [7-9](#Fig9) 显示了过滤结果。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig9_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig9_HTML.jpg)

图 7-9

将指标限制到默认名称空间

这可能看起来不可读，但是图表部分给出了对网格请求数量正在增加的合理估计。我们正在用更多的请求轰炸服务，以使更改在图上可见，如图 [7-10](#Fig10) 所示。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig10_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig10_HTML.jpg)

图 7-10

网格请求数量的图形视图

可以使用如下查询来过滤对单个服务的请求:

```
istio_requests_total{destination_service_namespace="default", destination_service_name="webservice"}

```

这些都是预定义的指标，对于大多数监控情况应该足够了，但是 Istio 还允许添加定制的指标。

### 自定义指标

Istio Mixer 收集所有属性并将它们注入到 Prometheus 中，但是有些情况下需要重新计算指标才有意义。Mixer 允许添加配置来做到这一点。如本章前面所述，用户可以配置实例和处理程序，并添加规则以向 Prometheus 添加指标。

让我们创建一个场景，将对 webapp 服务的所有请求加倍。实例配置可以在清单 [7-1](#PC3) 中找到。

```
apiVersion: config.istio.io/v1alpha2
kind: instance
metadata:
  name: requestdouble
  namespace: istio-system
spec:
  compiledTemplate: metric
  params:
    value: "2"
    dimensions:
      source: source.workload.name | "unknown"
      destination: destination.workload.name | "unknown"

Listing 7-1Requestdouble-instance.yaml Configuration

```

这种配置只是从网格中获取指标，并报告每个指标`value`次，在本例中为 2 次。清单 [7-2](#PC4) 中的处理程序引入了两个特定于该实例的新维度。

```
apiVersion: config.istio.io/v1alpha2
kind: handler
metadata:
  name: doublehandler
  namespace: istio-system
spec:
  compiledAdapter: prometheus
  params:
    metrics:
    - name: doublerequest_count # Prometheus metric name
      instance_name: requestdouble.instance.istio-system
      kind: COUNTER
      label_names:
      - source
      - destination

Listing 7-2Requestdouble-handler.yaml Configuration

```

前面的配置只是将指标从声明的`instance_name`推送到 Prometheus。它还容纳了两个新的维度，并将它们作为标签在 Prometheus 中传播。清单 [7-3](#PC5) 中显示的规则定义了处理程序与实例的连接。

```
apiVersion: config.istio.io/v1alpha2
kind: rule
metadata:
  name: requestdouble-prometheus
  namespace: istio-system
spec:
  actions:
  - handler: doublehandler
    instances: [ requestdouble ]

Listing 7-3Requestdouble-rule.yaml Configuration

```

这在普罗米修斯中记录了两次所有的请求。Prometheus 中的公制输出如图 [7-11](#Fig11) 所示。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig11_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig11_HTML.jpg)

图 7-11

所有请求在 istio_doublerequest_count 度量中计数两次

让我们调整规则，只为 web 服务连接一个实例和处理程序。清单 [7-4](#PC6) 显示了`match`的添加。

```
apiVersion: config.istio.io/v1alpha2
kind: rule
metadata:
  name: requestdouble-prometheus
  namespace: istio-system
spec:
  match: match(destination.service.name, "webservice")
  actions:
  - handler: doublehandler
    instances: [ requestdouble ]

Listing 7-4Requestdouble-rule.yaml Configuration

```

现在，只有一个服务的请求计数增加，如图 [7-12](#Fig12) 所示。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig12_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig12_HTML.jpg)

图 7-12

仅 web 服务的请求数增加了两倍

现在我们已经收集了我们这边的指标。尽管我们能够看到指标，但同时可视化不同的指标变得很困难。普罗米修斯支持 Grafana 允许可视化部分。让我们来看看 Grafana 的行动。

## 格拉凡娜

Grafana 是一个可视化、分析和监控指标的开源平台。它支持从多个来源导入数据，并允许在单一平台上进行分析。在我们的例子中，我们将局限于从普罗米修斯号上获取的数据。

Grafana 可以被视为一个 UI 可视化工具，它使用来自 Prometheus 的数据，并在需要时发送警报。图 [7-13](#Fig13) 显示了从 Istio 流向 Grafana 的指标。让我们从设置 Grafana 使用我们的 Prometheus 服务器开始。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig13_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig13_HTML.jpg)

图 7-13

数据从 Istio 流向 Grafana

### 装置

与普罗米修斯类似，Grafana 已经预配置了 Istio 设置。我们在第 [3](03.html) 章中看到 Grafana 附带了一个演示设置，我们还查看了 Grafana 仪表盘。在这里，我们将通过设置新的仪表板和警报来使用 Grafana。

Istio Grafana 预先配置为从网格中运行的 Prometheus 服务获取数据。通过更改配置，可以将 Grafana 的数据存储配置为从 SQLite 切换到 MySQL、Redis 或 Postgres。

Grafana 可以使用定制配置的Helm图表进行安装。让我们建立一个单独的 Grafana 配置与Helm图表。

```
helm install --name grafana --tiller-namespace kube-system stable/grafana

```

可以在这里进行定制配置，提供单独的数据库连接、凭证、警报管理等。一旦 Grafana 建立起来，我们就可以在 Grafana 中建立一个数据源。

让我们尝试访问网格中可用的默认 Grafana 仪表板，如图 [7-14](#Fig14) 所示。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig14_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig14_HTML.jpg)

图 7-14

在网格中访问 Grafana 仪表板

Grafana 可供我们使用，随时可用。让我们看看仪表板。

### Grafana 控制板

Grafana 有一套预配置的仪表盘，可以开箱即用。图 [7-15](#Fig15) 显示了直接访问 Istio 预配置仪表板以查看 Istio 网格的性能。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig15_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig15_HTML.jpg)

图 7-15

预配置的 Istio 网格仪表板

如上所述，该 Grafana 配置预先配置为从预先配置的 Prometheus 数据源读取指标，如图 [7-16](#Fig16) 所示。还可以在 Grafana 中添加额外的数据源来创建新的仪表板。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig16_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig16_HTML.jpg)

图 7-16

Grafana 预配置的 Prometheus 数据源

让我们创建一个新的仪表板来监控最近配置的 RequestDouble 指标。我们将创建一个显示对`webapp-deployment-8`的请求率的视图，如图 [7-17](#Fig17) 所示。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig17_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig17_HTML.jpg)

图 7-17

带有图表的新仪表板，用于监控请求率

保存仪表板将创建该特定目的地的请求率视图。让我们假设，如果这个服务超过了三个请求的阈值，它可能会受到影响。为了准备好基础设施和团队，我们将在达到阈值之前设置外出警报。

### 格拉凡娜警报

Grafana 提供了一个简单的机制，当指标超过一个特定的阈值时，提醒涉众。让我们在对`webapp-deployment-v8`的请求速率超过阈值 2.5 时设置一个警报。在我们开始之前，让我们设置警报通道。Grafana 允许一组公平的渠道来发送通知。它们包括以下内容:

*   HipChat

*   OpsGenie

*   扇子

*   三码网关

*   普罗米修斯 Alertmanager

*   不和，电子邮件

*   维克托罗普斯

*   谷歌视频聊天

*   卡夫卡休息代理

*   线条

*   容易做的事情

*   web 手册

*   丁丁

*   寻呼机杜蒂

*   松弛的

*   微软团队

*   电报

让我们建立一个 webhook 作为例子。我们将向该链接推送一条提醒:

```
https://jsonblob.com/api/jsonBlob/0d0ef717-d0a0-11e9-8538-43dbd386b327

```

参见图 [7-18](#Fig18) 了解如何在 Grafana 上添加网钩。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig18_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig18_HTML.jpg)

图 7-18

添加新的 webhook 频道

发送的任何通知都可以通过之前共享的链接看到。现在我们来设置一个警报。编辑我们在上一步中创建的面板，如图 [7-19](#Fig19) 所示。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig19_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig19_HTML.jpg)

图 7-19

编辑请求双倍费率面板

访问 Alert 选项卡，设置当请求阈值超过 2.5 个请求时发出警报，如图 [7-20](#Fig20) 所示。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig20_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig20_HTML.jpg)

图 7-20

基于带有自定义消息的条件创建警报

让我们用`siege`向前端服务发出多个请求。

```
siege -c40 -r10 "http://192.168.99.160:31380"

```

几秒钟内，Grafana 开始显示警报，如图 [7-21](#Fig21) 所示。

![../images/483921_1_En_7_Chapter/483921_1_En_7_Fig21_HTML.jpg](../images/483921_1_En_7_Chapter/483921_1_En_7_Fig21_HTML.jpg)

图 7-21

请求显示超出阈值的双仪表板

webhook 接收带有细节的数据，如清单 [7-5](#PC10) 所示。

```
{
    "evalMatches": [{
        "value": 107.19741952834556,
        "metric": "{destination=\"webapp-deployment-8\", instance=\"172.17.0.6:42422\", job=\"istio-mesh\", source=\"frontend-deployment\"}",
        "tags": {
            "destination": "webapp-deployment-8",
            "instance": "172.17.0.6:42422",
            "job": "istio-mesh",
            "source": "frontend-deployment"
        }
    }],
    "message": "Requests threshold of web-deployment-8 reaching threshold, action required",
    "ruleId": 1,
    "ruleName": "RequestDouble Rate alert",
    "ruleUrl": "http://localhost:3000/d/hpc70ncWk/requestdouble-dashboard?fullscreen\u0026edit\u0026tab=alert\u0026panelId=2\u0026orgId=1",
    "state": "alerting",
    "title": "[Alerting] RequestDouble Rate alert"
}

Listing 7-5Response Received on the Webhook

```

## 摘要

在本章中，我们介绍了使用 Prometheus 进行监控以及如何设置自定义指标。我们向您展示了 PromQL 如何帮助数据过滤，但它仍然是一次显示一个指标。我们将 Grafana 与 Prometheus 进行了整合，并创建了一个新的显示多个指标的仪表板。我们致力于在 Grafana 中配置警报，并集成了一个发送这些警报的通道。在下一章中，我们将致力于从分布式服务中收集日志，并跟踪调用以分析系统中的任何挑战。