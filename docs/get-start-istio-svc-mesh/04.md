# 4\. Istio VirtualService

在前一章中，我们详细讨论了 Istio 架构。我们使用控制平面来配置数据平面。这两个组件之间的解耦允许它们独立运行，从而提高了故障处理能力。该架构使集中式操作团队能够使用通用规则来配置基础架构。Istio 针对不同的目的制定了不同类型的规则。在本章中，我们将展示如何使用 Istio 的流量管理规则。具体来说，我们将采用现有的 Kubernetes 服务，并通过它路由流量。

## 请求路由

在本章中，我们将从第 [1](01.html) 章开始逐步开发我们的应用，所以让我们回顾一下到目前为止已经完成的工作。在第 [1](01.html) 章中，我们开发了一个多语言应用，并将其部署到 Kubernetes 集群中。该应用有一个基于 Java 的前端和一个基于 Python 的后端。这两个应用都部署在同一个 Kubernetes 名称空间中。webapp 是使用以下配置部署的:

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-deployment
  labels:
    app: webapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - name: webapp
        image: web-app:4.0
        imagePullPolicy: Never
        ports:
        - containerPort: 5000
-------
apiVersion: v1
kind: Service
metadata:
  name: webservice
spec:
  selector:
    app: webapp
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5000

```

这个配置在 Kubernetes 集群中创建了一个 pod 和一个服务。类似的配置用于部署前端 Java 应用。这两个应用可以通过使用 DNS 名称相互引用，因为它们属于同一个名称空间。类似地，不同名称空间中的服务可以通过使用完全限定的服务名来相互引用。

到目前为止，我们总是用新版本更新我们的 Kubernetes 部署。因此，我们的应用只有一个版本。但是这是一个边缘用例，不符合常规的 Kubernetes 部署。实际上，一个 Kubernetes 集群会运行同一个应用的多个版本。这将有助于我们满足不同的用例，如应用部署、A/B 测试等等。但是一旦我们有了部署的应用的许多版本，我们就会遇到各种各样的请求处理问题。

在扩展我们的示例时，我们需要向应用响应添加一个版本标识符。这可以通过在响应头中添加版本信息或在响应中添加版本前缀来实现。让我们修改我们的 Python 应用，将其版本作为欢迎消息的前缀(因为这很容易识别)。

```
app = Flask(__name__)
@app.route("/")
def main():
    currentDT = datetime.datetime.now()
    return "[{}]Welcome user! current time is {} ".format(os.environ['VERSION'],str(currentDT))
## removed for Brevity

```

我们现在需要通过 Dockerfile 设置`VERSION`环境变量。

```
FROM python:3.7-alpine
COPY ./requirement.txt /app/requirement.txt
WORKDIR /app
RUN pip install -r requirement.txt
COPY . /app
ENTRYPOINT [ "python" ]
ARG ver=NA
ENV VERSION=$ver
CMD [ "app.py" ]

```

为了验证前面的行为，我们需要将这个应用的几个版本部署到我们的集群中。因此，首先使用以下命令行为不同版本构建一些 Docker 映像:

```
$docker build . -t web-app:6.0 --build-arg ver=6.0
$docker build . -t web-app:6.1 --build-arg ver=6.1
$docker build . -t web-app:6.2 --build-arg ver=6.2

```

现在将所有以前的版本部署到 Kubernetes 集群。这是通过使用前面讨论过的`webapp-deployment`命令和不同的 Docker 图像来完成的。而且，webapp Kubernetes 服务配置了选择器`app: webapp`。这将选择所有匹配这些属性的 pod，并将请求路由到其中一个。如果我们请求 webapp 服务，我们会得到来自该服务所有版本的响应。

图 [4-1](#Fig1) 显示了在 Kubernetes 上运行的 webapp 的多个版本。我们来做一个`http://10.152.183.146/`的查找，它是前端服务。

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig1_HTML.jpg](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig1_HTML.jpg)

图 4-1

Kubernetes 部署服务

图 [4-2](#Fig2) ，图 [4-3](#Fig3) ，图 [4-4](#Fig4) 显示了响应。

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig4_HTML.jpg](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig4_HTML.jpg)

图 4-4

来自 6.0 的响应

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig3_HTML.jpg](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig3_HTML.jpg)

图 4-3

对 6.2 的回应

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig2_HTML.jpg](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig2_HTML.jpg)

图 4-2

对 6.1 的回应

在本章的其余部分，我们将为所需的版本配置 Istio 请求路由规则。Istio 可以相当好地处理 TCP 和 HTTP 服务。Istio 还支持请求路由的 L4 和 L7 属性查找。

## 不可分割的做法

在我们能够配置 Istio 请求路由之前，我们需要确保我们的 Kubernetes 集群遵循下面列出的实践。如果有不满足这些要求的服务，那么对这些服务的调用将不受 Istio 控制。此类请求将由 Kubernetes 组件解决。

### 命名服务端口

Istio 路由需要在 Kubernetes 服务中以`<protocol>[<-suffix>]`格式定义的端口名称。以下是 Istio 支持的协议:

*   `http`

*   `http2`

*   `https`

*   `grpc`

*   `mysql`

*   `mongo`

*   `redis`

*   `tcp`

*   `tls`

*   `udp`

在我们的例子中，我们必须将 web 服务的端口命名为`http-webapp`或`http`。不同服务的端口可以有相同的名称，但是同一服务的不同端口不能有相同的名称。值得注意的是，这是 Istio 遵循的一个命名约定，并没有给 Kubernetes 规范增加任何额外的协议值。因此，让我们用以下配置更新我们的 web 服务:

```
apiVersion: v1
kind: Service
metadata:
  name: webservice
spec:
  selector:
    app: webapp
  ports:
  - name: http-webservice
    protocol: TCP
    port: 80
    targetPort: 5000

```

在前面的配置中，我们添加了一个值为`http-webservice`的`name`属性。使用以下命令应用以前的配置:

```
$kubectl apply -f ../config/webservice.yaml

```

### 带有版本标签的窗格

Istio 将根据应用版本进行路由。要选择某个版本的节点，必须对它们进行相应的标记。因此，我们所有的部署和 pod 都必须应用应用和版本标签。Istio 还在度量和遥测数据收集中使用这些标签。现在让我们标记我们的 web 服务。

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-deployment-6.2
  labels:
    app: webapp
    version: v6.2
spec:
  replicas: 1
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
        version: v6.2
    spec:
      containers:

 # REMOVED FOR BREVITY

```

在前面的配置中，我们已经将`version: v6.2`添加到部署和模板中。Kubernetes 标签只支持字符串值；因此，我们的应用版本被定义为 v6.2。最后，使用以下命令应用之前的配置:

```
$kubectl apply -f ../config/webapp-deployent.yaml

```

### 声明的 Pod 端口

只有在部署模板中声明了 pod 公开的端口时，才能应用 Istio 路由。可以将端口声明为部署模板中`containerPort`字段的列表。根据 Kubernetes 文档,`containerPort`字段用于提供信息。容器可以运行监听 0.0.0.0 和端口的服务。集群中的所有容器都可以访问该端口。如果 Istio 路由适用于不属于部署模板的端口，则它将被绕过。

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-deployment-6.2

# Removed FOR BREVITY
      containers:
      - name: webapp
        image: web-app:6.0
        imagePullPolicy: Never
        ports:
        - containerPort: 5000
        readinessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 40

```

在前面的配置中，我们将 5000 声明为容器公开的端口。使用以下命令应用以前的配置:

```
$kubectl apply -f ../config/webapp-deployent.yaml

```

到目前为止，我们已经了解了 Istio 路由的先决条件。在配置它之前，让我们先了解一下它是如何工作的。使用`VirtualService`和`DestinationRule`组件在服务网格中配置请求路由。图 [4-5](#Fig5) 描述了各种相关组件之间的相互作用。

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig5_HTML.jpg](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig5_HTML.jpg)

图 4-5

目的地分辨率

涉及以下交互，如图 [4-5](#Fig5) 所示:

1.  服务 X 尝试使用完全限定的域名连接到服务 Y。

2.  虚拟服务查找服务 Y FQDN 以确定它是否需要被处理。

3.  如果是，那么匹配`DestinationRule`以确定最终的 Kubernetes 服务。

4.  最后，呼叫被转发到所需的服务 y。

## 目的地规则

`DestinationRule`将请求目标位置解析为 Kubernetes 集群中的网络地址。在上一节中，您了解到 Istio 规定版本号是 pod 标签的一部分。然后，这些标签可以在`DestinationRule`中进行匹配，从而为请求处理定义基于版本的服务子集。现在让我们为 web 服务配置一些目的地规则。

```
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: webapp-destination
spec:
  host: webservice
  subsets:
  - name: v1
    labels:
      version: v6.2

```

前面定义的规则配置了一个简单的目标规则 v1。`host: webservice`用于选择配置了 web 服务 Kubernetes 服务的 pod。然后，它从这些节点集中选择匹配`version: v6.2`标签的节点来定义子集 v1。我们可以通过以下方式创建规则:

```
$kubectl create -f ../config/webapp-destinationrules.yaml

```

之后，使用以下命令验证创建的目的地规则，如图 [4-6](#Fig6) 所示:

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig6_HTML.jpg](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig6_HTML.jpg)

图 4-6

目的地规则

```
$istioctl get destinationrules:

```

在前面的配置中，子集部分可用于定义多个命名子集。每个子集都可以配置不同的`VirtualService`组件。

```
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: webapp-destination
spec:
  host: webservice
  subsets:
  - name: v1
    labels:
      version: v6.2
  - name: v0
    labels:
      version: v6.0

```

使用以下命令更新规则，然后使用`istioctl`进行验证(参见图 [4-7](#Fig7) ):

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig7_HTML.png](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig7_HTML.png)

图 4-7

多个目的地规则

```
$kubectl apply -f ../config/webapp-destinationrules.yaml

```

`DestinationRule`组件应该由服务所有者来配置。服务所有者不仅可以创建不同的子集，还可以为每个子集定义`connectionPool`、负载平衡和异常值检测属性。这些设置决定了使用者服务如何连接到各个节点。

### 连接池

不用说，共享连接有好处。在我们启用了 TLS 握手的服务网格中，每个新连接的成本相对较高。传统上，我们在消费者应用中添加了各种连接池驱动程序。但是 Istio 为连接池提供了开箱即用的支持。`connectionPool`配置决定了消费者服务如何连接到提供者服务。这些设置必须由服务所有者进行微调。连接池设置适用于消费者服务的每个主机。

Istio 连接池支持`keepAlive` TCP 方法。因此，我们不仅可以使用池，还可以重用未使用的连接。这些设置有一组单独的属性来配置 HTTP 和 TCP 连接池。这些属性使我们能够微调 HTTP 连接重用。以下是最重要的属性。我们不会涵盖所有的属性；请参考 Istio 文档了解更多信息。

*   `maxConnections`:该设置定义了服务连接数的上限。默认值设置为 1024。此设置适用于 TCP 和 HTTPv1.0 服务。

*   `connectionTimeout`:该设置定义了 TCP 连接超时。

*   `Http2MaxRequets`:该设置适用于 HTTPv2.0，在 HTTP 2.0 中我们建立一个连接，并在多个请求中重复使用。这些设置定义了可以通过连接执行的请求数量的上限。

*   `Http1MaxPendingRequests`:该设置定义了通过连接挂起的 HTTP 请求数量的上限。这也适用于 HTTPv2.0/GRPC 服务。

我们可以为每个定义的子集配置`connectionPool`属性。

```
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: webapp-destination
spec:
  host: webservice
  subsets:
  - name: v0
    labels:
      version: v6.0
    trafficPolicy:
      connectionPool:
        tcp:
          maxConnections: 100
          connectTimeout: 30ms
          tcpKeepalive:
            time: 7200s
            interval: 75s

```

在前面的代码中，我们已经为 6.0 版本的服务配置了`connectionPool`。这些设置配置池化资源的最大数量以及连接和保持活动超时。

### 注意

值得注意的是，连接池是由特使代理监控的。如果违反了配置的限制，Envoy 将启动以下断路器:

*   `upstream_cx_overflow`:当集群中的一个服务超过最大连接数时，抛出这个断路器。这通常适用于 TCP 和 HTTP/1 服务。由于 HTTP/2 重用相同的连接，因此该限制不适用于它。

*   `upstream_rq_pending_overflow`:当集群中的服务发出的 HTTP 请求超过配置的限制时，抛出此断路器。这通常适用于 HTTP/2。

*   `upstream_rq_retry_overflow`:当集群中的服务发出的 HTTP 请求超过配置的限制时，抛出此断路器。

### 负载平衡

负载平衡是在选定目的地的不同主机之间分配请求的过程。有各种机制可以实现这一点。可以通过`loadBalancer`设置进行配置。Istio 支持以下类型的负载平衡器:

*   **循环**:随机选择一个主机。如果没有为选定的 pod 启用运行状况检查，这样会更好。

*   **最小连接**:该方法执行 O(1)查找来确定两个健康的主机。它会选择连接数量最少的一个。

*   **随机**:随机选择一个主机。如果没有为选定的 pod 启用运行状况检查，它的性能会更好。

*   **一致散列**:该方法基于请求头或 cookies 配置散列。

因为我们正在运行 web 服务的单个实例，所以我们不会为它配置负载平衡。

### 离群点检测

异常值检测是确定负载平衡集群中不健康主机的过程。该过程之后是从负载平衡集中删除主机。在 Istio 中，Envoy 断路器用于跟踪由目的主机引起的错误。这些错误可能是由服务或相应的边车引起的。在这两种情况下，主机都将被标记为不健康。

Istio 只记录服务抛出的连续错误。默认值设置为五个连续错误。对于基于 TCP 的服务，连接超时被视为错误。而基于 HTTP 的服务，5xx HTTP 响应也被记录为错误。在记录这些错误时，缺省情况下，Istio 从负载平衡集中驱逐一个服务 30 秒。经过该时间间隔后，主机将回到负载平衡集中，并以 10 秒的间隔重新评估(默认情况下)。可以通过配置各种可用的属性来改变这些计时。

总之，我们已经在`DestinationRule`中配置了子集。子集通过匹配配置的选择器来选择节点。Istio 然后对它们应用`connectionPool`、负载平衡和异常值检测设置。这些设置可以在`DestinationRule`级别进行配置。然后，这些设置将应用于在它下面创建的每个子集。但是如果在子集级别有任何配置，那么它将覆盖`DestinationRule`级别的配置。

```
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: webapp-destination
spec:
  host: webservice l
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
        connectTimeout: 30ms
  subsets:
  - name: v1
    labels:
      version: v6.2
  - name: v0
    labels:
      version: v6.0

```

在前面的代码中，我们已经为在`webapp-destination DestinationRule`组件中定义的所有子集(v0 和 v1)配置了`connectionPool`。这些设置配置池化资源的最大数量和连接超时。如前所述，`DestinationRule`组件只有在`virtualService`向其发送请求时才有效。在下一节中，我们将介绍如何定义一个`virtualService`并使用它的不同配置。

## 虚拟服务

Istio `VirtualService`组件的行为类似于 Kubernetes 中的`Service`组件。基本上，`VirtualService`是一种抽象，它将请求映射到服务网格中定义的服务。该服务可以是 Kubernetes 服务，也可以是 Istio 定义的服务。使用`DestinationRule`执行`VirtualService`组件的目的地解析。一个`VirtualService`组件可以执行目的地解析来处理以下用例:

*   服务的单一版本

*   基于 HTTP 头的查找以选择服务

*   一组选定服务版本之间的加权比较

`VirtualService`抽象将请求路由与应用部署分离开来。因此，在一个集群中，我们可以部署同一服务的许多版本，并以精细控制的方式在它们之间分配负载。

### 促进

在前面的例子中，我们定义了 v0 和 v1 子集。以下配置将所有请求发送到 v1 子集:

```
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: webservice-vs
spec:
  hosts:
    - webservice
  http:
  - route:
    - destination:
        host: webservice
        subset: v1

```

前面的配置是`VirtualService`最简单的形式之一。它将所有来自虚拟服务的请求只路由到目标服务的特定版本。见图 [4-8](#Fig8) 。

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig8_HTML.jpg](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig8_HTML.jpg)

图 4-8

单个服务

使用以下属性配置`VirtualService`行为:

*   `hosts`属性定义了请求必须匹配的主机名或主机和端口的列表。主机地址可以是使用 DNS 解析成 FQDN 的服务名(在我们的例子中是 Kubernetes DNS)。它也可以是主机 IP 和端口。

*   请求匹配后，再转发给目的主机的`subset` v1。

我们可以使用下面的代码创建如图 [4-8](#Fig8) 所示的虚拟服务:

```
$kubectl create -f ../config/webapp-simple-vs.yaml

```

之后，通过使用以下命令验证创建的虚拟服务(参见图 [4-9](#Fig9) ):

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig9_HTML.jpg](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig9_HTML.jpg)

图 4-9

v1 虚拟服务

```
$istioctl get virtualservices

```

前面的配置将所有请求发送到 web 服务的 v6.2。让我们通过多次加载前端 web 服务(`http://10.152.183.146/`)来验证这一点。我们可以看到我们所有的响应都来自于 webapp 的 6.2 版本(见图 [4-10](#Fig10) )。

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig10_HTML.jpg](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig10_HTML.jpg)

图 4-10

请求路由到 6.2 版本

### 重写

在前面的示例中，我们创建了请求转发，但是虚拟服务也能够执行请求重写。此行为使用以下属性进行配置:

*   `match`属性定义了哪些请求将执行重写。匹配可以基于 URI、HTTP 报头、查询参数、HTTP 方法、方案等。为了执行重写，我们必须指定 URI 以及其他选择器(如果需要的话)。

*   `rewrite`属性定义了请求需要发送到的新 URI 补丁。根据匹配的类型，重写将只替换匹配的 URI 部分。这意味着如果我们匹配 URI 前缀，那么重写只会改变前缀。如果完整的 URI 匹配，那么重写将改变完整的 URI。

*   `subset`属性定义了被重写的请求被转发到的目的主机。

以下配置匹配`/hello`请求，并将其发送到我们的 web 服务版本 6.2 的`/`路径:

```
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: webservice-rewrite-vs
spec:
  hosts:
    - webservice
  http:
  - match:
    - uri:
        prefix: /hello
    rewrite:
      uri: /
    route:
    - destination:
        host: webservice
        subset: v1

```

我们可以通过以下方式创建虚拟服务:

```
$kubectl create -f ../config/webapp-rewrite-vs.yaml

```

现在有两个虚拟服务在处理`webservice`主机。这将会产生问题，所以让我们首先使用以下命令删除之前创建的虚拟服务:

```
$kubectl delete -f ../config/webapp-simple-vs.yaml

```

但是我们如何验证我们的改变呢？我们每次都可以更换我们的前端容器。或者，我们可以使用 Kubernetes 提供的`exec`命令。`exec`命令允许我们在一个容器中执行命令。因此，我们可以执行`wget`命令来验证请求路由。

```
$kubectl exec pod/frontend-deployment-c9c975b4-p8z2t -- wget -O - http://webservice/hello
Defaulting container name to frontend.
Use 'kubectl describe pod/frontend-deployment-c9c975b4-p8z2t -n default' to see all of the containers in this pod.
[6.0]Welcome user! current time is 2019-07-21 07:15:59.395367 Connecting to webservice (10.152.183.230:80)
-               100% |********************************|  62  0:00:00 ETA

```

### HTTP 属性查找

Istio 能够执行 HTTP 属性查找。如前一节所述，`match`属性支持 URIs、HTTP 头、查询参数、HTTP 方法、方案等。我们可以匹配前面提到的任何属性，并将请求转发给匹配的主机。

```
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: webservice-httplookup-vs
spec:
  hosts:
    - webservice
  http:
  - match:
    - headers:
        x-upgrade:
          exact: "TRUE"
    route:
    - destination:
        host: webservice
        subset: v1
  - route :
    - destination:
        host: webservice
        subset: v0

```

在前面的配置中，我们已经配置了`match`属性来寻找一个`x-upgrade`头。如果报头可用，那么它被转发到服务的较新版本。我们还添加了一个默认路由，所有不匹配的请求都会转发到该路由。

### 注意

Istio 配置为`match`属性的所有配置部分获取一个字符串。字符串喜欢`true`、`TRUE`、25 等。被转换为适当的数据类型，因此不能直接传递。这些值可以通过用双引号括起来转换成字符串，就像我们在前面的配置中所做的那样。

让我们应用配置。

```
$kubectl create -f code/config/webservice-httplookup-vs.yaml

```

之后，通过使用以下内容验证创建的虚拟服务(参见图 [4-11](#Fig11) ):

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig11_HTML.jpg](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig11_HTML.jpg)

图 4-11

基于 HTTP 的虚拟服务

```
$istioctl get virtualservices

```

让我们确保没有任何之前创建的虚拟服务。

让我们首先在不设置标题的情况下发出一个请求。

```
$kubectl exec pod/frontend-deployment-c9c975b4-p8z2t -- wget -O - http://webservice/
Defaulting container name to frontend.
Use 'kubectl describe pod/ frontend-deployment-c9c975b4-p8z2 -n default' to see all of the containers in this pod.
[6.0]Welcome user! current time is 2019-07-21 11:19:35.349452 Connecting to webservice (10.152.183.230:80)

```

现在在`wget`命令行中传递适当的头。

```
$kubectl exec frontend-deployment-c9c975b4-p8z2t -- wget -O - --header='x-upgrade: TRUE' http://webservice/
Defaulting container name to frontend.
Use 'kubectl describe pod/frontend-deployment-c9c975b4-p8z2t -n default' to see all of the containers in this pod.
[6.2]Welcome user! current time is 2019-07-21 11:19:28.565401 Connecting to webservice (10.152.183.230:80)

```

### 加权分布

Istio 能够按照配置的比例在不同版本的服务中分发请求。该比率由目的地的`weight`属性决定。见图 [4-12](#Fig12) 。

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig12_HTML.jpg](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig12_HTML.jpg)

图 4-12

重量分布服务

以下配置在 v0 和 v1 子集之间分配流量。对于每四个请求，我们希望将其中三个发送到旧版本，一个发送到新版本。

```
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: webservice-wtdist-vs
spec:
  hosts:
    - webservice
  http:
  - route:
    - destination:
        host: webservice
        subset: v1
      weight: 25
    - destination:
        host: webservice
        subset: v0
      weight: 75

```

使用以下内容应用配置:

```
$kubectl create -f code/config/webservice-wtdist-vs.yaml

```

之后，使用以下命令验证创建的虚拟服务:

```
$istioctl get virtualservices

```

让我们确保没有任何之前创建的虚拟服务。参见图 [4-13](#Fig13) 。

![../images/483921_1_En_4_Chapter/483921_1_En_4_Fig13_HTML.jpg](../images/483921_1_En_4_Chapter/483921_1_En_4_Fig13_HTML.jpg)

图 4-13

加权分布式虚拟服务

现在做几次`wget`请求。我们可以看到，每四个请求中就有一个被路由到 v6.2，而剩下的请求由 v6.0 提供服务。

```
     $kubectl exec pod/frontend-deployment-c9c975b4-p8z2t -it -- sh -il
Defaulting container name to frontend.
Use 'kubectl describe pod/frontend-deployment-c9c975b4-p8z2t -n default' to see all of the containers in this pod.
frontend-deployment-c9c975b4-p8z2t:/#  wget -qO - http://webservice
[6.0]Welcome user! current time is 2019-07-22 17:52:24.164478 frontend-deployment-c9c975b4-p8z2t:/#
frontend-deployment-c9c975b4-p8z2t:/#  wget -qO - http://webservice
[6.0]Welcome user! current time is 2019-07-22 17:52:28.977615 frontend-deployment-c9c975b4-p8z2t:/#
frontend-deployment-c9c975b4-p8z2t:/#  wget -qO - http://webservice
[6.0]Welcome user! current time is 2019-07-22 17:52:33.068721 frontend-deployment-c9c975b4-p8z2t:/#
frontend-deployment-c9c975b4-p8z2t:/#  wget -qO - http://webservice
[6.2]Welcome user! current time is 2019-07-22 17:52:41.291074 frontend-deployment-c9c975b4-p8z2t:/#
frontend-deployment-c9c975b4-p8z2t:/#

```

在这个例子中，我们有一个交互式会话，不像前面的例子，我们在容器中执行命令。交互式会话允许我们一个接一个地执行多个命令。

### 注意

到目前为止，我们已经将目的地配置为 Kubernetes 服务和基于版本的子集。但是我们也可以在不同的 Kubernetes 服务之间分配请求，而不需要子集定义。在我们的例子中，`host`属性可以引用 Kubernetes 服务`prod.webservice`和`test.webservice`。

## 金丝雀释放

canary 发布是向一部分用户发布软件的过程。该流程允许开发人员在向整个用户群推广新版本之前，先向一部分用户验证新版本。如果在新版本中发现问题，可以回滚到较小的一组服务器。这有助于减轻影响并提高服务正常运行时间。Kubernetes 还通过管理应用的实例/复制计数来支持 canary 测试。但是这个管理 pod 实例的过程很快变得复杂并且难以支持。另一方面，Istio 对选择请求有丰富的支持，因此可以很容易地完成这项工作。

金丝雀发布是对第一章中讨论的蓝绿色部署的补充。作为一般过程，采取以下步骤:

1.  使用蓝绿色部署流程，我们在少量容器上部署新版本。

2.  当服务被标记为健康时，我们不是路由所有请求，而是从一定百分比的请求开始。

3.  我们继续测试新版本，直到我们对结果满意为止。

4.  最后，这一变化被部署在为所有用户服务的整个车队上。

在前面的小节中，我们讨论了简单的请求匹配。`match`方法验证一个简单的属性并请求转发。但是对于 canary release 这样相当高级的用例来说，这还不够好。匹配需要处理用 AND/OR 等操作连接在一起的多个子句。Istio `match`属性以下列方式支持这两种操作:

*   AND 操作通过在单个`match`属性下嵌套多个条件来执行。

*   OR 运算是通过在单个`match`属性下设置不同的条件来执行的。

### 注意

在 YAML 语法中，列表的值是通过在每个值前加一个连字符(-)来创建的。这意味着带有前缀连字符的条件是不同的值。

```
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: webservice-and-or-vs
spec:
  hosts:
    - webservice
  http:
  - match:
    - headers:
        x-upgrade:
          exact: "TRUE"
    - queryParams:
        ver:
          exact: v1
       method:
         exact: GET
    route:
    - destination:
        host: webservice
        subset: v1
  - route :
    - destination:
        host: webservice
        subset: v0

```

之前的配置会尝试匹配以下两个条件中的任何一个(或操作):

*   HTTP 头具有正确的值`x-upgrade`。

*   `queryString`有`ver=v1` *和*HTTP 方法是 GET。

部署并验证之前的配置。

```
$kubectl exec frontend-deployment-c9c975b4-p8z2t -- wget -O - --header='x-upgrade: TRUE' http://webservice/
Defaulting container name to frontend.
Use 'kubectl describe pod/frontend-deployment-c9c975b4-p8z2t -n default' to see all of the containers in this pod.
[6.2]Welcome user! current time is 2019-07-21 18:09:25.296747 Connecting to webservice (10.152.183.230:80)

$kubectl exec frontend-deployment-c9c975b4-p8z2t -- wget -O – http://webservice/?ver=v1
Defaulting container name to frontend.
Use 'kubectl describe pod/frontend-deployment-c9c975b4-p8z2t -n default' to see all of the containers in this pod.
[6.2]Welcome user! current time is 2019-07-21 18:10:03.728678 Connecting to webservice (10.152.183.230:80)

```

因为我们正在制定新的多重规则，所以了解 Istio 如何评估它们是很重要的。Istio 根据规则的声明顺序评估所有匹配规则。首先评估第一个声明的匹配条件。如果条件失败，Istio 将评估下一个条件。在以下配置中，我们在第一个位置添加了默认路由:

```
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: webservice-httplookup-vs
spec:
  hosts:
    - webservice
  http:
  - route :
    - destination:
        host: webservice
        subset: v0
  - match:
    - headers:
        x-upgrade:
          exact: "TRUE"
    route:
    - destination:
        host: webservice
        subset: v1

```

让我们部署并验证之前的配置。

```
$ kubectl exec frontend-deployment-c9c975b4-p8z2t -- wget -O - --header='x-upgrade: TRUE' http://webservice/
Defaulting container name to frontend.
Use 'kubectl describe pod/frontend-deployment-c9c975b4-p8z2t -n default' to see all of the containers in this pod.
[6.0]Welcome user! current time is 2019-07-21 18:19:55.581391 Connecting to webservice (10.152.183.230:80)

```

这意味着服务所有者必须始终确保首先声明最具体的规则。所有匹配规则都应该从最具体的到一般的进行声明。

生产就绪的 Istio 配置将具有匹配条件、规则优先级和请求的加权分布。因此，对于我们的示例 web 服务，以下配置包括所有这些方面:

```
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: webservice-canary-vs
spec:
  hosts:
    - webservice
  http:
  - match:
    - headers:
        host:
          exact: "user1.com"
    route:
    - destination:
        host: webservice
        subset: v1
      weight: 10
    - destination:
        host: webservice
        subset: v0
      weight: 90
  - route :
    - destination:
        host: webservice
        subset: v0

```

按照之前的配置，除了来自`user1.com`的请求之外，所有请求都由 v0 服务提供服务。此外，来自`user1.com`的 10%的请求由 v1 web 服务提供服务；所有剩余的都被路由到 v0 版本。

## 摘要

在本章中，我们使用了`VirtualService`和`DestinationRule`来执行请求路由。我们通过将多个版本的 webapp 部署到 Kubernetes 集群来开始讨论。接下来，我们确保我们遵循了 Istio 为端口和 pod 规定的命名约定。之后，我们使用目的地规则定义了版本子集。当通过虚拟服务连接时，评估定义的目的地规则。因此，我们为单一服务路由、HTTP 属性路由和加权路由构建了不同的虚拟服务配置。最后，我们看了金丝雀部署。我们发现了该流程如何帮助减少应用停机时间并提高应用稳定性。我们使用多个匹配条件、目的地优先级和加权请求分布构建了 canary 部署示例。本章的重点是服务请求路由。在下一章中，我们将研究如何配置`Ingress`、`Egress`和`ServiceEntry`组件，以便与 Kubernetes 集群之外的世界进行交互。